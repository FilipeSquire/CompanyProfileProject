{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af914165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k is not a known attribute of class <class 'azure.search.documents._generated.models._models_py3.VectorizableTextQuery'> and will be ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 495\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# =========== GENERATE BUSINESS OVERVIEW\u001b[39;00m\n\u001b[1;32m    494\u001b[0m stakeholders_pairs_flat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(stakeholders_pairs[\u001b[38;5;241m1\u001b[39m], stakeholders_pairs[\u001b[38;5;241m0\u001b[39m]))  \u001b[38;5;66;03m# [(r, q), (r, q), ...]\u001b[39;00m\n\u001b[0;32m--> 495\u001b[0m section_built \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstakeholders_pairs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m#getting web search sections\u001b[39;00m\n\u001b[1;32m    498\u001b[0m new_section \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAll instructions applies to the company: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent\u001b[38;5;241m.\u001b[39mcompany_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mstakeholders_web\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Mention in the Beggining of the answer that this is WEBSEARCH SOURCE\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "Cell \u001b[0;32mIn[4], line 333\u001b[0m, in \u001b[0;36mprofileAgent._sections\u001b[0;34m(self, pairs)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;66;03m# small incremental delay before re-trying\u001b[39;00m\n\u001b[1;32m    331\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(base_delay_seconds \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m tries)\n\u001b[0;32m--> 333\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rag_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrag_nl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m answer_text \u001b[38;5;241m=\u001b[39m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# stop if good answer OR we've exhausted retries\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 247\u001b[0m, in \u001b[0;36mprofileAgent._rag_answer\u001b[0;34m(self, rag_nl, question, k, temperature)\u001b[0m\n\u001b[1;32m    240\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    241\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_msg},\n\u001b[1;32m    242\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_msg},\n\u001b[1;32m    243\u001b[0m ]\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# Try streaming first (SSE). Some networks/proxies block streaming; if so, fall back.\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAOAI_DEPLOYMENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhigh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    251\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m answer \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    253\u001b[0m mode_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-streaming (fallback)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1145\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, textwrap\n",
    "import io\n",
    "\n",
    "from typing import List, Dict, Optional\n",
    "from xml.sax.saxutils import escape\n",
    "\n",
    "from gpts.gpt_assistants import general_assistant\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.search.documents.models import HybridSearch\n",
    "\n",
    "\n",
    "from openai import AzureOpenAI, APIConnectionError, OpenAI\n",
    "from prompts import new_system_finance_prompt\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "\n",
    "from prompts4 import finance_calculations, finance_pairs, capital_pairs, stakeholders_pairs, biz_overview_pairs, revenue_pairs, default_gpt_prompt, section4a, section4b, section5, section3, biz_overview_web, stakeholders_web\n",
    "from pages.design.func_tools import *\n",
    "from pages.design.formatting import *\n",
    "from pages.design.func_tools import docx_bytes_to_pdf_bytes\n",
    "import re, time\n",
    " \n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# ---- Config (expects the same envs you already used) ----\n",
    "SEARCH_ENDPOINT = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "SEARCH_INDEX    = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "SEARCH_KEY      = os.getenv(\"AZURE_SEARCH_API_KEY\")  # omit if using AAD/RBAC\n",
    "VECTOR_FIELD    = os.getenv(\"VECTOR_FIELD\")\n",
    "TEXT_FIELD      = os.getenv(\"TEXT_FIELD\")\n",
    "\n",
    "AOAI_ENDPOINT   = os.environ[\"AZURE_OPENAI_ENDPOINT\"]            # https://<resource>.openai.azure.com\n",
    "AOAI_API_VER    = os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\")\n",
    "AOAI_DEPLOYMENT = os.environ[\"AZURE_OPENAI_DEPLOYMENT\"]          # e.g., gpt-4o-mini / o3-mini / gpt-5 preview\n",
    "AOAI_KEY        = os.getenv(\"AZURE_OPENAI_API_KEY\")              # omit if using AAD\n",
    "OPENAI_API_KEY  = os.getenv(\"OPENAI_API_KEY\")        # required\n",
    "\n",
    "# ------------------ CODE\n",
    "\n",
    "class profileAgent():\n",
    "\n",
    "    \"\"\"Hybrid (dense+sparse) RAG over Vector Store\n",
    "\n",
    "    This Agent is responsible for creating Company Profiles. \n",
    "    It operates with gpt5.\n",
    "    It is activated by a call on main rag when it is typed 'Create company profile'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, company_name, k, max_text_recall_size, max_chars, model, profile_prompt = new_system_finance_prompt, finance_calculations = finance_calculations):\n",
    "        \n",
    "        self.company_name = company_name\n",
    "\n",
    "        self.k = k\n",
    "        self.max_text_recall_size = max_text_recall_size\n",
    "        self.model = model\n",
    "        self.max_chars = max_chars\n",
    "\n",
    "        self.azure_credentials = AzureKeyCredential(SEARCH_KEY) if SEARCH_KEY else DefaultAzureCredential()\n",
    "        self.search_client = SearchClient(SEARCH_ENDPOINT, SEARCH_INDEX, credential=self.azure_credentials)\n",
    "\n",
    "        self.az_openai = AzureOpenAI(azure_endpoint=AOAI_ENDPOINT, api_key=AOAI_KEY, api_version=AOAI_API_VER)\n",
    "        self.profile_prompt = profile_prompt\n",
    "        self.web_openai = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "        self.reasoning_effort = \"medium\"\n",
    "        self.verbosity = \"medium\"\n",
    "\n",
    "        self.finance_calculations = finance_calculations\n",
    "\n",
    "    def _company_filter(self) -> str:\n",
    "        v = (self.company_name or \"\").replace(\"'\", \"''\").strip()\n",
    "        return f\"company_name eq '{v}'\" if v else None\n",
    "    \n",
    "    def assemble_bm25_from_llm(self, slots: dict) -> str:\n",
    "        def q(s: str) -> str:\n",
    "            # sanitize: remove internal quotes and trim\n",
    "            s = (s or \"\").strip().replace('\"', ' ')\n",
    "            return f\"\\\"{s}\\\"\" if s else \"\"\n",
    "        groups = []\n",
    "\n",
    "        # must-have phrases (ANDed)\n",
    "        for p in slots.get(\"must_have_phrases\", []):\n",
    "            qp = q(p)\n",
    "            if qp:\n",
    "                groups.append(qp)\n",
    "\n",
    "        # metric / statement synonym groups (ORed within each group)\n",
    "        for key in [\"metric\", \"statement\"]:\n",
    "            syns = slots.get(\"synonyms\", {}).get(key, []) or slots.get(key, [])\n",
    "            syns = [q(s) for s in syns if s]\n",
    "            if syns:\n",
    "                groups.append(\"(\" + \" OR \".join(syns) + \")\")\n",
    "\n",
    "        return \" AND \".join(groups) if groups else \"\\\"financial statements\\\"\"\n",
    "\n",
    "\n",
    "    def bm25_creator(self, prompt):\n",
    "\n",
    "        instruction = (\n",
    "            \"Extract finance search slots for Azure AI Search. \"\n",
    "            \"Return strict JSON: {\\\"metric\\\":[], \\\"statement\\\":[], \\\"synonyms\\\":{}, \\\"must_have_phrases\\\":[]} \"\n",
    "            \"(include IFRS/US GAAP variants).\"\n",
    "        )\n",
    "        resp = general_assistant(instruction, prompt, OPENAI_API_KEY, 'gpt-4o')\n",
    "\n",
    "        try:\n",
    "            slots = getattr(resp, \"output_json\", None)\n",
    "            if slots is None:\n",
    "                import json\n",
    "                slots = json.loads(resp.output_text)\n",
    "        except Exception:\n",
    "            # fallback: minimal anchors from prompt\n",
    "            slots = {\"must_have_phrases\": [prompt], \"metric\": [], \"statement\": [], \"synonyms\": {}}\n",
    "        return self.assemble_bm25_from_llm(slots)\n",
    "\n",
    "    def _retrieve_hybrid_enhanced(self, query_nl, k: int = 50, top_n = 30, fields=VECTOR_FIELD, max_text_recall_size:int = 800):\n",
    "        sc = self.search_client\n",
    "        flt = self._company_filter()\n",
    "        \n",
    "        try:\n",
    "            vq = VectorizableTextQuery(text=query_nl, k=k, fields=VECTOR_FIELD)\n",
    "            # Prefer vector-only search (integrated vectorization). If your index isn't set up for it, this raises.\n",
    "            results = sc.search(\n",
    "                search_text=self.bm25_creator(query_nl), \n",
    "                vector_queries=[vq], \n",
    "                top=top_n, \n",
    "                query_type=\"semantic\",\n",
    "                query_caption=\"extractive\", \n",
    "                hybrid_search=HybridSearch(max_text_recall_size=self.max_text_recall_size),\n",
    "                query_caption_highlight_enabled=True,\n",
    "                filter=flt\n",
    "                )\n",
    "            mode = \"hybrid + semantic\"\n",
    "        except HttpResponseError as e:\n",
    "            # Fall back to lexical so you still get results while fixing vector config\n",
    "            results = sc.search(search_text=self.bm25_creator(query_nl), top=k)\n",
    "            mode = f\"lexical (fallback due to: {e.__class__.__name__})\"\n",
    "\n",
    "        hits: List[Dict] = []\n",
    "        for r in results:\n",
    "            d = r.copy() if hasattr(r, \"copy\") else {k2: r[k2] for k2 in r}\n",
    "            d[\"score\"] = d.get(\"@search.reranker_score\") or d.get(\"@search.score\") or 0.0\n",
    "            caps = d.get(\"@search.captions\")\n",
    "            if isinstance(caps, list) and caps:\n",
    "                d[\"caption\"] = getattr(caps[0], \"text\", None)\n",
    "            hits.append(d)\n",
    "\n",
    "        return mode, hits\n",
    "\n",
    "\n",
    "    def _build_context(self, hits: List[Dict], text_field: str = TEXT_FIELD, max_chars: int = 20000):\n",
    "        \"\"\"Build a compact, numbered context block and also return the selected chunk metadata.\"\"\"\n",
    "        lines = []\n",
    "        total = 0\n",
    "        selected = []  # <- we'll return this\n",
    "\n",
    "        for i, h in enumerate(hits, 1):\n",
    "            title     = h.get(\"title\")\n",
    "            chunk_id  = h.get(\"chunk_id\")\n",
    "            full_text = (h.get(text_field) or \"\")\n",
    "            if not full_text:\n",
    "                continue\n",
    "\n",
    "            preview = textwrap.shorten(full_text, width=700, placeholder=\" ...\")\n",
    "            block = f\"[{i}] title={title!r} | chunk_id={chunk_id} | score={h.get('score'):.4f}\\n{full_text}\"\n",
    "\n",
    "            if total + len(block) > self.max_chars:\n",
    "                break\n",
    "\n",
    "            total += len(block)\n",
    "            lines.append(block)\n",
    "\n",
    "            # keep rich metadata so you can show or log it later\n",
    "            selected.append({\n",
    "                \"i\": i,\n",
    "                \"title\": title,\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"score\": h.get(\"score\"),\n",
    "                \"caption\": h.get(\"caption\"),\n",
    "                \"preview\": preview,\n",
    "                \"text\": full_text,  # full chunk text (not shortened)\n",
    "                # include any other fields you index, if available:\n",
    "                \"metadata_storage_path\": h.get(\"metadata_storage_path\"),\n",
    "                \"page_number\": h.get(\"page_number\"),\n",
    "                \"doc_type\": h.get(\"doc_type\"),\n",
    "            })\n",
    "\n",
    "        return \"\\n\\n---\\n\\n\".join(lines), selected\n",
    "\n",
    "        \n",
    "    def _generate_pdf(self, text: str) -> bytes:\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        doc = SimpleDocTemplate(buf, pagesize=letter)\n",
    "        styles = getSampleStyleSheet()\n",
    "        body = styles[\"BodyText\"]\n",
    "\n",
    "        story = []\n",
    "        # Treat double newlines as paragraph breaks; keep single newlines as <br/>\n",
    "        for para in (text or \"\").split(\"\\n\\n\"):\n",
    "            safe = escape(para).replace(\"\\n\", \"<br/>\")\n",
    "            story.append(Paragraph(safe if safe.strip() else \"&nbsp;\", body))\n",
    "            story.append(Spacer(1, 8))\n",
    "\n",
    "        doc.build(story)\n",
    "        buf.seek(0)\n",
    "        return buf.getvalue()\n",
    "    \n",
    "    def _extract_cited_idxs(self, answer: str) -> list[int]:\n",
    "        # Matches [#1], [#12], etc. (also tolerates stray [1])\n",
    "        nums = set(int(n) for n in re.findall(r\"\\[#?(\\d+)\\]\", answer))\n",
    "        return sorted(nums)\n",
    "\n",
    "    def _rag_answer(self, rag_nl, question, k: int = 5, temperature: float = 0.2):\n",
    "\n",
    "        # question = f'CREATE A SECTION OF COMPANY PROFILE USING LAST YEARS OF ANNUAL REPORT PRESENT IN THE CONTEXT FOR {self.company_name}. IF ANY INFORMATION IS NOT FOUND STATE AS n.a. .\\n\\n THIS IS THE SECTION TO BE BUILT: \\n {section7}  \\n USE THIS TO GUIDE YOURSELF ON SEMANTIC TERMS AND HOW TO CALCULATE: \\n {finance_calculations}'\n",
    "        \n",
    "        mode, hits = self._retrieve_hybrid_enhanced(\n",
    "            # query=rag_q, \n",
    "            query_nl=rag_nl,\n",
    "            k=25\n",
    "            )\n",
    "        ctx_text, ctx_items = self._build_context(hits)\n",
    "\n",
    "        system_msg = self.profile_prompt + (\n",
    "            \"\\nWhen you use a fact from the context, add citations like [#1], [#2].\"\n",
    "            \"\\nOnly rely on the numbered context; if a value is missing, say 'n.a.'.\"\n",
    "            f\"\\nIF ANY INFORMATION IS NOT FOUND STATE AS n.a. .\\n\\n USE THIS TO GUIDE YOURSELF ON SEMANTIC TERMS AND HOW TO CALCULATE: \\n {finance_calculations}\"\n",
    "        )\n",
    "        user_msg = f\"Question:\\n{question}\\n\\nContext snippets (numbered):\\n{ctx_text}\"\n",
    "\n",
    "        client = self.az_openai\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\",   \"content\": user_msg},\n",
    "        ]\n",
    "\n",
    "        # Try streaming first (SSE). Some networks/proxies block streaming; if so, fall back.\n",
    "        \n",
    "        resp = client.chat.completions.create(\n",
    "            model=AOAI_DEPLOYMENT,\n",
    "            messages=messages,\n",
    "            reasoning_effort=\"high\"\n",
    "        )\n",
    "        answer = resp.choices[0].message.content\n",
    "        mode_model = \"non-streaming (fallback)\"\n",
    "\n",
    "        cited = self._extract_cited_idxs(answer)\n",
    "        used_chunks = [c for c in ctx_items if c[\"i\"] in cited]\n",
    "\n",
    "        # return self._generate_pdf(answer)\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"citations\": cited,          # [1, 3, 7]\n",
    "            \"used_chunks\": used_chunks,  # detailed dicts for each cited snippet\n",
    "            \"all_chunks\": ctx_items,     # everything you sent (optional)\n",
    "            \"mode\": mode                 # retrieval mode info (optional)\n",
    "        }\n",
    "\n",
    "    def _web_search(self, messages):\n",
    "        resp = self.web_openai.responses.create(\n",
    "            model='gpt-5',\n",
    "            input=messages,\n",
    "            tools=[{\"type\": \"web_search\"}],\n",
    "            tool_choice=\"auto\",\n",
    "            # max_output_tokens=self.max_output_tokens,\n",
    "            reasoning={\"effort\": self.reasoning_effort},\n",
    "            text={\"verbosity\": self.verbosity},\n",
    "        )\n",
    "        \n",
    "        return resp.output_text\n",
    "    \n",
    "    def _answer(self, question, ctx_text, k: int = 5, temperature: float = 0.2):\n",
    "\n",
    "        system_msg = self.profile_prompt + (\n",
    "            \"\\nWhen you use a fact from the context, preserve any existing citations like [#1], [#2], [#5, p.41] that are already in the context text.\"\n",
    "            \"\\nOnly rely on the provided context; if a value is missing, say 'n.a.'.\"\n",
    "            \"\\nIMPORTANT: If the formatting instructions request a Sources section, you MUST include it at the end.\"\n",
    "            \"\\nFor the Sources section, list all citation numbers/references that appear in your answer, and describe what document/source each refers to based on information in the context.\"\n",
    "        )\n",
    "        user_msg = f\"Question:\\n{question}\\n\\nContext snippets:\\n{ctx_text}\"\n",
    "\n",
    "        client = self.az_openai\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\",   \"content\": user_msg},\n",
    "        ]\n",
    "\n",
    "        # Try streaming first (SSE). Some networks/proxies block streaming; if so, fall back.\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=AOAI_DEPLOYMENT,\n",
    "            messages=messages,\n",
    "            reasoning_effort=\"high\"\n",
    "        )\n",
    "        answer = resp.choices[0].message.content\n",
    "\n",
    "        cited = self._extract_cited_idxs(answer)\n",
    "\n",
    "        # return self._generate_pdf(answer)\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"citations\": cited,          # [1, 3, 7]\n",
    "        }   \n",
    "    \n",
    "    @staticmethod\n",
    "    def has_na(text: str) -> bool:\n",
    "        # match \"n.a.\" or \"n/a\" (case-insensitive)\n",
    "        return bool(re.search(r\"\\b(n\\.a\\.|n/a)\\b\", text, flags=re.I))\n",
    "\n",
    "    def _sections(self, pairs):\n",
    "\n",
    "        answers = []\n",
    "\n",
    "        max_extra_na_retries = 1        # try again at most 2 times (total <= 3 calls per item)\n",
    "        base_delay_seconds = 3.0        # polite delay between attempts\n",
    "\n",
    "\n",
    "        for q, r in pairs:\n",
    "            tries = 0\n",
    "            while True:\n",
    "                if tries > 0:\n",
    "                    # small incremental delay before re-trying\n",
    "                    time.sleep(base_delay_seconds + 0.5 * tries)\n",
    "\n",
    "                resp = self._rag_answer(rag_nl=r[0], question=q[0])\n",
    "                answer_text = resp[\"answer\"]\n",
    "\n",
    "                # stop if good answer OR we've exhausted retries\n",
    "                if not profileAgent.has_na(answer_text) or tries >= max_extra_na_retries:\n",
    "                    answers.append(answer_text)\n",
    "                    break\n",
    "\n",
    "                # otherwise, try again\n",
    "                tries += 1\n",
    "\n",
    "            # optional small gap between different (r,q) items\n",
    "            time.sleep(5.0)\n",
    "        \n",
    "        return answers\n",
    "    \n",
    "    def _generate_section(self, section):\n",
    "\n",
    "        if section == 'GENERATE BUSINESS OVERVIEW':\n",
    "            # =========== GENERATE BUSINESS OVERVIEW\n",
    "            biz_overview_pairs_flat = list(zip(biz_overview_pairs[1], biz_overview_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "            section_built = self._sections(pairs = biz_overview_pairs_flat)\n",
    "\n",
    "            #getting web search sections\n",
    "            new_section = f'All instructions applies to the company: {self.company_name}\\n\\n{biz_overview_web} \\n\\n Mention in the Beggining of the answer that this is WEBSEARCH SOURCE'\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": default_gpt_prompt},\n",
    "                {\"role\": \"user\",   \"content\": new_section},\n",
    "            ]\n",
    "            resp_web = self._web_search(messages)\n",
    "\n",
    "            section_built.append(resp_web)\n",
    "\n",
    "            # Join all context sections - they already contain their own citations\n",
    "            # Just concatenate them so the model can synthesize\n",
    "            ctx_text_formatted = \"\\n\\n\".join(section_built)\n",
    "\n",
    "            resp = self._answer(question=biz_overview_mix_formatting, ctx_text=ctx_text_formatted)\n",
    "            return resp['answer']\n",
    "        elif section == 'GENERATE KEY STAKEHOLDERS':\n",
    "        # =========== GENERATE KEY STAKEHOLDERS\n",
    "            stakeholders_pairs_flat = list(zip(stakeholders_pairs[1], stakeholders_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "            section_built = self._sections(pairs= stakeholders_pairs_flat)\n",
    "\n",
    "            #getting web search sections\n",
    "            new_section = f'All instructions applies to the company: {self.company_name}\\n\\n{stakeholders_web} \\n\\n Mention in the Beggining of the answer that this is WEBSEARCH SOURCE'\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": default_gpt_prompt},\n",
    "                {\"role\": \"user\",   \"content\": new_section},\n",
    "            ]\n",
    "            resp_web = self._web_search(messages)\n",
    "\n",
    "            section_built.append(resp_web)\n",
    "\n",
    "            # Join all context sections - they already contain their own citations\n",
    "            # Just concatenate them so the model can synthesize\n",
    "            ctx_text_formatted = \"\\n\\n\".join(section_built)\n",
    "\n",
    "            resp = self._answer(question=stakeholders_web_mix, ctx_text=section_built)\n",
    "            return resp['answer']\n",
    "        elif section == 'GENERATE FINANCIAL HIGHLIGHTS':\n",
    "            # =========== GENERATE FINANCIAL HIGHLIGHTS\n",
    "            finance_pairs_flat = list(zip(finance_pairs[1], finance_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "            section_built = self._sections(pairs=finance_pairs_flat)\n",
    "            resp = self._answer(question=finance_formatting_2, ctx_text=section_built)\n",
    "            return resp['answer']\n",
    "        elif section == 'GENERATE CAPITAL STRUCTURE':\n",
    "            # =========== GENERATE CAPITAL STRUCTURE\n",
    "            capital_pairs_flat = list(zip(capital_pairs[1], capital_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "            section_built = self._sections(pairs= capital_pairs_flat)\n",
    "            resp = self._answer(question=capital_structure_formatting_2, ctx_text=section_built)\n",
    "            return resp['answer']\n",
    "        elif section == 'GENERATE REVENUE SPLIT':\n",
    "            # =========== GENERATE CAPITAL STRUCTURE\n",
    "            revenue_pairs_flat = list(zip(revenue_pairs[1], revenue_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "            section_built = self._sections(pairs= revenue_pairs_flat)\n",
    "            resp = self._answer(question=section3, ctx_text=section_built)\n",
    "            return resp['answer']\n",
    "        elif section == 'GENERATE PRODUCTS SERVICES OVERVIEW':\n",
    "            # =========== GENERATE CAPITAL STRUCTURE\n",
    "            new_section = f'All instructions applies to the company: {self.company_name}\\n\\n{section4a}'\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": default_gpt_prompt},\n",
    "                {\"role\": \"user\",   \"content\": new_section},\n",
    "            ]\n",
    "            resp = self._web_search(messages)\n",
    "            return resp \n",
    "        elif section == 'GENERATE GEO FOOTPRINT':\n",
    "            # =========== GENERATE CAPITAL STRUCTURE\n",
    "            new_section = f'All instructions applies to the company: {self.company_name}\\n\\n{section4b}'\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": default_gpt_prompt},\n",
    "                {\"role\": \"user\",   \"content\": new_section},\n",
    "            ]\n",
    "            resp = self._web_search(messages)\n",
    "            return resp\n",
    "        elif section == 'GENERATE DEVELOPMENTS HIGHLIGHTS':\n",
    "            # =========== GENERATE CAPITAL STRUCTURE\n",
    "            new_section = f'All instructions applies to the company: {self.company_name}\\n\\n{section5}'\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": default_gpt_prompt},\n",
    "                {\"role\": \"user\",   \"content\": new_section},\n",
    "            ]\n",
    "            resp = self._web_search(messages)\n",
    "            return resp\n",
    "\n",
    "\n",
    "    def generate_company_profile(self):\n",
    "\n",
    "        # =========== GENERATE BUSINESS OVERVIEW\n",
    "        biz_overview_pairs_flat = list(zip(biz_overview_pairs[1], biz_overview_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "        section1 = self._sections(pairs = biz_overview_pairs_flat)\n",
    "        resp = self._answer(question=business_overview_formatting, ctx_text=section1)\n",
    "        doc = insert_biz_overview(resp['answer'])\n",
    "\n",
    "        time.sleep(60)\n",
    "        # =========== GENERATE KEY STAKEHOLDERS\n",
    "        stakeholders_pairs_flat = list(zip(stakeholders_pairs[1], stakeholders_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "        section2 = self._sections(pairs= stakeholders_pairs_flat)\n",
    "        resp = self._answer(question=stakeholders_formatting, ctx_text=section2)\n",
    "        doc = insert_stakeholders(resp['answer'], doc=doc)\n",
    "        \n",
    "        time.sleep(60)\n",
    "        # =========== GENERATE FINANCIAL HIGHLIGHTS\n",
    "        finance_pairs_flat = list(zip(finance_pairs[1], finance_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "        section3 = self._sections(pairs=finance_pairs_flat)\n",
    "        resp = self._answer(question=finance_formatting, ctx_text=section3)\n",
    "        doc = insert_finance(resp['answer'], doc=doc)\n",
    "\n",
    "        time.sleep(60)\n",
    "        # =========== GENERATE CAPITAL STRUCTURE\n",
    "        capital_pairs_flat = list(zip(capital_pairs[1], capital_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "        section4 = self._sections(pairs= capital_pairs_flat)\n",
    "        resp = self._answer(question=capital_structure_formatting_2, ctx_text=section4)\n",
    "        doc = insert_capital_structure(resp['answer'], doc=doc)\n",
    "\n",
    "        pdf_bytes = docx_bytes_to_pdf_bytes(doc)\n",
    "\n",
    "        return pdf_bytes\n",
    "        # =========== UNION\n",
    "\n",
    "from prompts4 import section7, finance_calculations, system_mod\n",
    "import time\n",
    "import re, time\n",
    "\n",
    "company = 'SEAPORT_TOPCO_LIMITED'\n",
    "sys = system_mod\n",
    "calc = finance_calculations\n",
    "\n",
    "agent = profileAgent(\n",
    "    company_name = company,\n",
    "    k=50, \n",
    "    max_text_recall_size=35, \n",
    "    max_chars=10000,\n",
    "    model='gpt-5', \n",
    "    profile_prompt= sys,\n",
    "    finance_calculations= calc\n",
    ")\n",
    "\n",
    "\n",
    "# =========== GENERATE BUSINESS OVERVIEW\n",
    "stakeholders_pairs_flat = list(zip(stakeholders_pairs[1], stakeholders_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "section_built = agent._sections(pairs = stakeholders_pairs_flat)\n",
    "\n",
    "#getting web search sections\n",
    "new_section = f'All instructions applies to the company: {agent.company_name}\\n\\n{stakeholders_web} \\n\\n Mention in the Beggining of the answer that this is WEBSEARCH SOURCE'\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": default_gpt_prompt},\n",
    "    {\"role\": \"user\",   \"content\": new_section},\n",
    "]\n",
    "resp_web = agent._web_search(messages)\n",
    "\n",
    "section_built.append(resp_web)\n",
    "\n",
    "# Join all context sections - they already contain their own citations\n",
    "# Just concatenate them so the model can synthesize\n",
    "ctx_text_formatted = \"\\n\\n\".join(section_built)\n",
    "\n",
    "# resp = agent._answer(question=biz_overview_mix_formatting, ctx_text=ctx_text_formatted)\n",
    "ctx_text_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b498d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seaport Topco Limited is a private company.\n",
      "\n",
      "- Immediate parent company: EQT Jupiter Luxco S.A.R.L (Luxembourg) [2024 Annual Report, Note 32 Controlling party, p.52; 2023 Annual Report, Note 30 Controlling party, p.46] [#1] [#3]\n",
      "- Ultimate parent company: n.a. (not disclosed in the available filings). The filings note that the smallest and largest Group in which the results of the Company are consolidated is that headed by Seaport Topco Limited, but do not identify an ultimate controlling parent above EQT Jupiter Luxco S.A.R.L [2024 Annual Report, Note 32, p.52; 2023 Annual Report, Note 30, p.46] [#1] [#3]\n",
      "\n",
      "Sources:\n",
      "- Seaport Topco Limited Annual Report FY23 (approved Apr-24): Note 32 Controlling party, p.52  https://aiprojec.../14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_1.pdf [#1]\n",
      "- Seaport Topco Limited Annual Report FY22 (published Oct-23): Note 30 Controlling party, p.46  https://aiprojec.../14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2023-10-15_2.pdf [#3]\n",
      "\n",
      "Management\n",
      "\n",
      "- Chairman: n.a.\n",
      "- Chief Executive Officer (CEO): n.a.\n",
      "- Chief Financial Officer (CFO): n.a.\n",
      "- Directors: n.a.\n",
      "\n",
      "Notes and sources:\n",
      "- The provided excerpts from Seaport Topco Limiteds annual reports (Directors Responsibilities Statement and Independent Auditors Report) for the years ended Dec-24 and Dec-23 do not list the names of the Chairman, CEO, CFO, or Directors. The sections shown only describe responsibilities and audit opinions without naming individuals. See:\n",
      "  - Seaport Topco Limited Annual Report for year ended Dec-24: Directors Responsibilities Statement (page 8) and Independent Auditors Report (page 21) [#1] [#4]\n",
      "  - Seaport Topco Limited Annual Report for year ended Dec-23: Directors Responsibilities Statement (page 8) and Auditors Report section (pages cited) [#3] [#2]\n",
      "\n",
      "Please provide the Company Information, Directors Report, or Board of Directors pages from the latest three annual reports (FY22FY24), or allow a web search, so I can extract and verify the names precisely.\n",
      "\n",
      "Lenders\n",
      "\n",
      "External debt facilities reported, with lender names if disclosed:\n",
      "- USD term loan facility  Lenders: n.a. (lenders are not named in the companys annual reports) [#4]\n",
      "- Revolving Credit Facility (30.0m)  Lenders: n.a. (lenders are not named in the companys annual reports) [#4]\n",
      "- Delayed Draw Down facility (75.0m; access removed in Mar-25)  Lenders: n.a. (lenders are not named in the companys annual reports) [#2]\n",
      "\n",
      "Notes:\n",
      "- The FY24 annual report describes the term loan and RCF facilities (including interest and outstanding balances) but does not disclose the lending banks or institutions. It also states all facilities are secured by cross-company guarantees, without naming lenders [#4].\n",
      "- The FY24 annual reports subsequent events note confirms management removed access to the 75.0m delayed drawdown facility in Mar-25 but does not identify lenders [#2].\n",
      "- Internal loans from shareholders/related parties (e.g., EQT Jupiter Luxco S.A.R.L. and Battery Ventures funds) are excluded per the instruction; those relationships are recorded in subsequent events and other notes but are not part of external bank debt [#2], [#4].\n",
      "- The creditors and net debt notes detail bank loans positions (current and non-current) and movements but do not name lenders [#1], [#2].\n",
      "\n",
      "Sources:\n",
      "- Seaport Topco Limited Annual Report, FY24 (year ended 31 Dec-24), Notes to the Financial Statements  Borrowings and facilities (including term loan and RCF details), p. 43 [#4]\n",
      "- Seaport Topco Limited Annual Report, FY24 (year ended 31 Dec-24), Notes  Analysis of net debt and subsequent events (DDTL removal in Mar-25; internal loans), pages_76; Subsequent events section [#2]\n",
      "- Seaport Topco Limited Annual Report, FY24 (year ended 31 Dec-24), Notes  Creditors (amounts falling due within one year and after more than one year), p. 41 [#1]\n",
      "- Seaport Topco Limited Annual Report, FY22 (period ended 31 Dec-22), Notes  Interest payable (bank loans), p. 29 (does not disclose lender names) [#3]\n",
      "\n",
      "Auditor: n.a.\n",
      "\n",
      "Reason: The provided excerpts include the Independent Auditors Report sections but do not show the auditors signature block or firm name. See:\n",
      "- 2023 report contents indicating Independent Auditors Report on pages 912 [1]\n",
      "- 2023 report audit section text (no auditor name shown in the excerpt) [4]\n",
      "- 2024 report audit section text (no auditor name shown in the excerpts) [2][3]\n",
      "\n",
      "Sources:\n",
      "- Seaport Topco Limited Annual Report (published Sep-24): contents page showing Independent Auditors Report on pp. 912 [1]\n",
      "- Seaport Topco Limited Annual Report (published Sep-24): Independent Auditors Report excerpt [4]\n",
      "- Seaport Topco Limited Annual Report (published Sep-25): Independent Auditors Report excerpts [2][3]\n",
      "\n",
      "Advisors (financial/legal advisors, solicitors, bankers, facility agent) disclosed: n.a.\n",
      "\n",
      "Notes:\n",
      "- The available FY24 and FY23 annual report sections reviewed do not list any named financial advisors, legal advisors/solicitors, bankers, facility agent, or auditors. If you can share the Company Information and Independent auditors report pages or the full loan agreement notes, I can extract advisor names precisely.\n",
      "\n",
      "Sources:\n",
      "- Seaport Topco Limited Annual Report (FY24, published Sep-25): Notes and cash flow sections reviewed; no advisor disclosures found (p. 18; p. 41; Notes 3032) [#1], [#2], [#4]\n",
      "- Seaport Topco Limited Annual Report (FY23/FY22, published Sep-24): Financial instruments note reviewed; no advisor disclosures found (p. 75) [#5]\n",
      "\n",
      "WEBSEARCH SOURCE\n",
      "\n",
      "6. Key Stakeholders  SEAPORT TOPCO LIMITED (as of 02-Dec-25)\n",
      "\n",
      "Shareholders\n",
      "| Item | Name | Role / Notes | Date reference |\n",
      "|---|---|---|---|\n",
      "| Immediate parent company | EQT Jupiter Luxco S.A.R.L. | Immediate parent; incorporated in Luxembourg. | FY24 accounts filed Sep-25. ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf)) |\n",
      "| Ultimate parent company | n/a | Not disclosed in the FY24 annual report. The accounts state Seaport Topco Limited is the smallest and largest group in which the results are consolidated, with no ultimate controlling party named. | FY24 accounts filed Sep-25. ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf)) |\n",
      "| Other registered shareholders (context) | EQT Jupiter Luxco S.A.R.L.; Battery Ventures Select Fund II (AIV I Cayman), L.P.; Battery Investment Partners Select Fund II (AIV I Cayman), L.P.; various managers/employees (B/B1/C share classes) | Per latest Confirmation Statement, EQT Jupiter Luxco S.A.R.L. holds the A Ordinary and A Preference shares; Battery funds hold minority A Ordinary and A Preference shares; management/employees hold B/B1/C share classes. | CS01 dated Jun-25. ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ3MTYxNzE3MmFkaXF6a2N4/document?download=0&format=pdf))\n",
      "\n",
      "Management (Board and Executive)\n",
      "| Position | Name | Notes | Date reference |\n",
      "|---|---|---|---|\n",
      "| Chairperson | Kieran Murphy | Chair of SPT Labtech Board (group operating company). Listed as director of Seaport Topco Limited at Companies House. | Website accessed Dec-25; CH officers page updated 2025. ([sptlabtech.com](https://www.sptlabtech.com/board-of-directors)) |\n",
      "| Chief Executive Officer | Rob Walton | CEO, appointed 22-Jul-24 as director of Seaport Topco Limited; CEO role shown on SPT site. | Jul-24 (appointment), site accessed Dec-25. ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/officers?utm_source=openai)) ([sptlabtech.com](https://www.sptlabtech.com/executive-leadership)) |\n",
      "| Chief Financial Officer | Andrew Holford | Group CFO, joined Dec-24 (SPT site). | Dec-24; site accessed Dec-25. ([sptlabtech.com](https://www.sptlabtech.com/executive-leadership)) |\n",
      "| Other current Topco directors (FY24 report) | Anne Thorburn; Michael Bauer; Jesse Feldman; Rob Walton | Listed in FY24 Company Information. | FY24 accounts filed Sep-25. ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf)) |\n",
      "\n",
      "Lenders (per annual report and subsequent events)\n",
      "| Facility | Lender(s) | Key terms / size | Date reference |\n",
      "|---|---|---|---|\n",
      "| Revolving Credit Facility (RCF) | n/a (banks not disclosed) | Group has a 30.0m RCF; 25.2m drawn at Dec-24 and 0.6m drawn at signing; used for working capital. | FY24 Directors Report. ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf)) |\n",
      "| Shareholder loan | EQT Jupiter Luxco S.A.R.L. (immediate parent) | 22.4m loan issued to the Company; repayable Mar-30. | Subsequent events note (Mar-25). ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf)) |\n",
      "| Shareholder loan (minority) | Battery Ventures Select Fund II (AIV I Cayman), L.P. | 2.5m loan; repayable Mar-30. | Subsequent events note (Mar-25). ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf)) |\n",
      "| Shareholder loan (minority) | Battery Investment Partners Select Fund II (AIV I Cayman), L.P. | 0.1m loan; repayable Mar-30. | Subsequent events note (Mar-25). ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf)) |\n",
      "\n",
      "Advisors (auditors and transaction advisors)\n",
      "| Type | Advisor | Mandate / Deal context | Date reference |\n",
      "|---|---|---|---|\n",
      "| Independent auditor | RSM UK Audit LLP | Auditor to Seaport Topco Limited group. | FY24 accounts. ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf)) |\n",
      "| Financial advisor to EQT | Evercore | Advisor to EQT on acquisition of SPT Labtech (groups operating business) from Battery Ventures. | Jun-22 press release. ([eqtgroup.com](https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22)) |\n",
      "| Legal advisor to EQT | Kirkland & Ellis | Legal counsel to EQT on SPT Labtech acquisition. | Jun-22 press release. ([eqtgroup.com](https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22)) |\n",
      "| Financial & tax diligence (EQT) | Deloitte | Financial & tax advisor to EQT on acquisition. | Jun-22 press release. ([eqtgroup.com](https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22)) |\n",
      "| Commercial diligence (EQT) | Boston Consulting Group (BCG) | Commercial advisor to EQT. | Jun-22 press release. ([eqtgroup.com](https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22)) |\n",
      "| Technology diligence (EQT) | Ringstone | Tech advisor to EQT. | Jun-22 press release. ([eqtgroup.com](https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22)) |\n",
      "| ESG advisor (EQT) | The Footprint Firm | ESG advisor to EQT. | Jun-22 press release. ([eqtgroup.com](https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22)) |\n",
      "| Financial advisor to Battery/SPT | J.P. Morgan | Exclusive financial advisor to Battery Ventures and SPT Labtech (seller/company). | Jun-22 press release. ([eqtgroup.com](https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22)) |\n",
      "| Legal advisors to Battery/SPT | Charles Russell Speechlys; SecondSight Law | Legal counsel to Battery Ventures and SPT Labtech. | Jun-22 press release. ([eqtgroup.com](https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22)) |\n",
      "\n",
      "Charges (Companies House  Outstanding only)\n",
      "| Charge number | Issue date | Persons entitled | Status |\n",
      "|---|---|---|---|\n",
      "| n/a | n/a | n/a | No outstanding charges identified for Seaport Topco Limited on the public Companies House pages reviewed; secured borrowings may be registered at subsidiary entities instead (e.g., Seaport Midco Limited / SPT Labtech Limited). | Page reviewed Dec-25. ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962?utm_source=openai))\n",
      "\n",
      "Notes and sourcing\n",
      "- Registered office, directors and filings are on Companies House. Officers list confirms current directors and CEO appointment. ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/officers?utm_source=openai))\n",
      "- FY24 Annual Report (filed Sep-25) provides: directors listing, auditor (RSM UK Audit LLP), going concern disclosure including the 30.0m RCF, and the Controlling party note naming the immediate parent (EQT Jupiter Luxco S.A.R.L.). It also discloses Mar-25 shareholder loans from EQT Jupiter Luxco and Battery funds (repayable Mar-30). ([find-and-update.company-information.service.gov.uk](https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf))\n",
      "- Management roles (Chairperson, CEO, CFO) are taken from SPT Labtechs official website (Board of Directors and Executive Leadership pages), which is the operating company of the Seaport group and aligns with the directors disclosed at Companies House. ([sptlabtech.com](https://www.sptlabtech.com/board-of-directors))\n",
      "- M&A advisors listed above come from EQTs official press release announcing the acquisition of SPT Labtech from Battery Ventures. ([eqtgroup.com](https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22))\n",
      "\n",
      "If you would like, I can also:\n",
      "- Pull the most recent Seaport Midco Limited and SPT Labtech Limited Companies House entries to capture any banking charges lodged at borrower level (often where RCF security is filed).\n"
     ]
    }
   ],
   "source": [
    "print(ctx_text_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f18c034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'SECTION ONE  Key Stakeholders\\n\\nShareholders (private company)\\n| Item | Name | Details |\\n|---|---|---|\\n| Immediate parent company | EQT Jupiter Luxco S.A.R.L. | Immediate parent; incorporated in Luxembourg. [#1, p.52]; [#3, p.46] |\\n| Ultimate parent company | n.a. | Not disclosed in the available filings. The accounts state Seaport Topco Limited is the smallest and largest group in which the results are consolidated; no ultimate controlling party named above EQT Jupiter Luxco S.A.R.L. [#1, p.52]; [#3, p.46] |\\n| Other registered shareholders (context) | Battery Ventures Select Fund II (AIV I Cayman), L.P.; Battery Investment Partners Select Fund II (AIV I Cayman), L.P.; various managers/employees (B/B1/C share classes) | Per latest Confirmation Statement (CS01, Jun-25), EQT Jupiter Luxco S.A.R.L. holds A Ordinary and A Preference shares; Battery funds hold minority A Ordinary and A Preference shares; management/employees hold B/B1/C classes. (Companies House CS01 link in Sources) |\\n\\nManagement (Board and Executive)\\n| Position | Name | Notes |\\n|---|---|---|\\n| Chairman | Kieran Murphy | Chair of SPT Labtech Board; listed as director of Seaport Topco Limited on Companies House. (SPT Labtech site; Companies House Officers page) |\\n| Chief Executive Officer | Rob Walton | CEO; appointed director of Seaport Topco Limited on 22-Jul-24. (SPT Labtech site; Companies House Officers page) |\\n| Chief Financial Officer | Andrew Holford | Group CFO; joined Dec-24. (SPT Labtech site) |\\n| Other current Topco directors | Anne Thorburn; Michael Bauer; Jesse Feldman; Rob Walton | Listed in FY24 Company Information section. (FY24 accounts link in Sources) |\\n\\nLenders (bank facilities; names not disclosed)\\n| Facility | Lender(s) | Notes |\\n|---|---|---|\\n| USD term loan facility | n.a. | Term loan disclosed in FY24 annual report; lenders not named; facilities secured by cross-company guarantees. [#4, p.43] |\\n| Revolving Credit Facility (RCF) | n.a. | 30.0m RCF; 25.2m drawn at Dec-24 and 0.6m drawn at signing; lender banks not disclosed. [#4, p.43] |\\n| Delayed Draw Down Term Loan (DDTL) | n.a. | 75.0m DDTL access removed in Mar-25 (subsequent events); lender banks not disclosed. [#2, p.76] |\\n\\nAuditors\\n| Auditor | Engagement | Notes |\\n|---|---|---|\\n| RSM UK Audit LLP | Independent auditor | Named as the group auditor in FY24 accounts filed Sep-25. (Companies House filing link in Sources) |\\n\\nAdvisors (transaction and diligence advisors)\\n| Type | Advisor | Mandate / Deal context |\\n|---|---|---|\\n| Financial advisor to EQT | Evercore | Advisor to EQT on acquisition of SPT Labtech from Battery Ventures. (EQT press release, Jun-22) |\\n| Legal advisor to EQT | Kirkland & Ellis | Legal counsel to EQT on SPT Labtech acquisition. (EQT press release, Jun-22) |\\n| Financial & tax diligence (EQT) | Deloitte | Financial and tax advisor to EQT. (EQT press release, Jun-22) |\\n| Commercial diligence (EQT) | Boston Consulting Group (BCG) | Commercial advisor to EQT. (EQT press release, Jun-22) |\\n| Technology diligence (EQT) | Ringstone | Technology diligence advisor to EQT. (EQT press release, Jun-22) |\\n| ESG advisor (EQT) | The Footprint Firm | ESG advisor to EQT. (EQT press release, Jun-22) |\\n| Financial advisor to Battery/SPT | J.P. Morgan | Exclusive financial advisor to Battery Ventures and SPT Labtech. (EQT press release, Jun-22) |\\n| Legal advisors to Battery/SPT | Charles Russell Speechlys; SecondSight Law | Legal counsel to Battery Ventures and SPT Labtech. (EQT press release, Jun-22) |\\n\\nCharges (Companies House  Outstanding only)\\n| Charge number | Issue date | Persons entitled | Status |\\n|---|---|---|---|\\n| n.a. | n.a. | n.a. | No outstanding charges identified for Seaport Topco Limited on Companies House as of Dec-25; secured borrowings may be registered at subsidiary entities (e.g., Seaport Midco Limited / SPT Labtech Limited). (Companies House company page link in Sources) |\\n\\n\\nSECTION TWO  SOURCES\\n\\n[#1] Seaport Topco Limited Annual Report FY24 (filed Sep-25): Note 32 Controlling party and Creditors note  immediate parent EQT Jupiter Luxco S.A.R.L; creditors amounts; page references p.52 (controlling party), p.41 (creditors). Companies House filing PDF link (find-and-update.company-information.service.gov.uk company 14171962 filing history).\\n\\n[#2] Seaport Topco Limited Annual Report FY24 (filed Sep-25): Subsequent events note  removal of 75.0m DDTL access in Mar-25; shareholder loans context; p.76.\\n\\n[#3] Seaport Topco Limited Annual Report FY22 (filed Oct-23): Note 30 Controlling party  immediate parent EQT Jupiter Luxco S.A.R.L; ultimate parent not disclosed; p.46.\\n\\n[#4] Seaport Topco Limited Annual Report FY24 (filed Sep-25): Notes to the Financial Statements  Borrowings and facilities (term loan and 30.0m RCF; secured by cross-company guarantees; lender names not disclosed), p.43.\\n\\nCompanies House  Seaport Topco Limited (company number 14171962): company page (charges reviewed; none outstanding), officers page (directors/CEO appointment), filing history (FY24 accounts; CS01 confirmation statement listing share classes and Battery funds).\\n- Company page: https://find-and-update.company-information.service.gov.uk/company/14171962\\n- Officers: https://find-and-update.company-information.service.gov.uk/company/14171962/officers\\n- FY24 accounts PDF: https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf\\n- CS01 (Jun-25) PDF: https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ3MTYxNzE3MmFkaXF6a2N4/document?download=0&format=pdf\\n\\nSPT Labtech official website (management):\\n- Board of Directors: https://www.sptlabtech.com/board-of-directors\\n- Executive Leadership (CEO, CFO): https://www.sptlabtech.com/executive-leadership\\n\\nEQT official press release (advisors for SPT Labtech acquisition, Jun-22):\\n- https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22\\n\\nNotes:\\n- Where exact page numbers are not visible in the Companies House PDFs, n.a. is indicated; all links provided point to the specific filings referenced.\\n- Lender names for bank facilities are not disclosed in the annual reports; therefore shown as n.a. in the Lenders table.', 'citations': [1, 2, 3, 4]}\n"
     ]
    }
   ],
   "source": [
    "resp = agent._answer(question=stakeholders_web_mix, ctx_text=ctx_text_formatted)\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad3400f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SECTION ONE  Key Stakeholders\n",
      "\n",
      "Shareholders (private company)\n",
      "| Item | Name | Details |\n",
      "|---|---|---|\n",
      "| Immediate parent company | EQT Jupiter Luxco S.A.R.L. | Immediate parent; incorporated in Luxembourg. [#1, p.52]; [#3, p.46] |\n",
      "| Ultimate parent company | n.a. | Not disclosed in the available filings. The accounts state Seaport Topco Limited is the smallest and largest group in which the results are consolidated; no ultimate controlling party named above EQT Jupiter Luxco S.A.R.L. [#1, p.52]; [#3, p.46] |\n",
      "| Other registered shareholders (context) | Battery Ventures Select Fund II (AIV I Cayman), L.P.; Battery Investment Partners Select Fund II (AIV I Cayman), L.P.; various managers/employees (B/B1/C share classes) | Per latest Confirmation Statement (CS01, Jun-25), EQT Jupiter Luxco S.A.R.L. holds A Ordinary and A Preference shares; Battery funds hold minority A Ordinary and A Preference shares; management/employees hold B/B1/C classes. (Companies House CS01 link in Sources) |\n",
      "\n",
      "Management (Board and Executive)\n",
      "| Position | Name | Notes |\n",
      "|---|---|---|\n",
      "| Chairman | Kieran Murphy | Chair of SPT Labtech Board; listed as director of Seaport Topco Limited on Companies House. (SPT Labtech site; Companies House Officers page) |\n",
      "| Chief Executive Officer | Rob Walton | CEO; appointed director of Seaport Topco Limited on 22-Jul-24. (SPT Labtech site; Companies House Officers page) |\n",
      "| Chief Financial Officer | Andrew Holford | Group CFO; joined Dec-24. (SPT Labtech site) |\n",
      "| Other current Topco directors | Anne Thorburn; Michael Bauer; Jesse Feldman; Rob Walton | Listed in FY24 Company Information section. (FY24 accounts link in Sources) |\n",
      "\n",
      "Lenders (bank facilities; names not disclosed)\n",
      "| Facility | Lender(s) | Notes |\n",
      "|---|---|---|\n",
      "| USD term loan facility | n.a. | Term loan disclosed in FY24 annual report; lenders not named; facilities secured by cross-company guarantees. [#4, p.43] |\n",
      "| Revolving Credit Facility (RCF) | n.a. | 30.0m RCF; 25.2m drawn at Dec-24 and 0.6m drawn at signing; lender banks not disclosed. [#4, p.43] |\n",
      "| Delayed Draw Down Term Loan (DDTL) | n.a. | 75.0m DDTL access removed in Mar-25 (subsequent events); lender banks not disclosed. [#2, p.76] |\n",
      "\n",
      "Auditors\n",
      "| Auditor | Engagement | Notes |\n",
      "|---|---|---|\n",
      "| RSM UK Audit LLP | Independent auditor | Named as the group auditor in FY24 accounts filed Sep-25. (Companies House filing link in Sources) |\n",
      "\n",
      "Advisors (transaction and diligence advisors)\n",
      "| Type | Advisor | Mandate / Deal context |\n",
      "|---|---|---|\n",
      "| Financial advisor to EQT | Evercore | Advisor to EQT on acquisition of SPT Labtech from Battery Ventures. (EQT press release, Jun-22) |\n",
      "| Legal advisor to EQT | Kirkland & Ellis | Legal counsel to EQT on SPT Labtech acquisition. (EQT press release, Jun-22) |\n",
      "| Financial & tax diligence (EQT) | Deloitte | Financial and tax advisor to EQT. (EQT press release, Jun-22) |\n",
      "| Commercial diligence (EQT) | Boston Consulting Group (BCG) | Commercial advisor to EQT. (EQT press release, Jun-22) |\n",
      "| Technology diligence (EQT) | Ringstone | Technology diligence advisor to EQT. (EQT press release, Jun-22) |\n",
      "| ESG advisor (EQT) | The Footprint Firm | ESG advisor to EQT. (EQT press release, Jun-22) |\n",
      "| Financial advisor to Battery/SPT | J.P. Morgan | Exclusive financial advisor to Battery Ventures and SPT Labtech. (EQT press release, Jun-22) |\n",
      "| Legal advisors to Battery/SPT | Charles Russell Speechlys; SecondSight Law | Legal counsel to Battery Ventures and SPT Labtech. (EQT press release, Jun-22) |\n",
      "\n",
      "Charges (Companies House  Outstanding only)\n",
      "| Charge number | Issue date | Persons entitled | Status |\n",
      "|---|---|---|---|\n",
      "| n.a. | n.a. | n.a. | No outstanding charges identified for Seaport Topco Limited on Companies House as of Dec-25; secured borrowings may be registered at subsidiary entities (e.g., Seaport Midco Limited / SPT Labtech Limited). (Companies House company page link in Sources) |\n",
      "\n",
      "\n",
      "SECTION TWO  SOURCES\n",
      "\n",
      "[#1] Seaport Topco Limited Annual Report FY24 (filed Sep-25): Note 32 Controlling party and Creditors note  immediate parent EQT Jupiter Luxco S.A.R.L; creditors amounts; page references p.52 (controlling party), p.41 (creditors). Companies House filing PDF link (find-and-update.company-information.service.gov.uk company 14171962 filing history).\n",
      "\n",
      "[#2] Seaport Topco Limited Annual Report FY24 (filed Sep-25): Subsequent events note  removal of 75.0m DDTL access in Mar-25; shareholder loans context; p.76.\n",
      "\n",
      "[#3] Seaport Topco Limited Annual Report FY22 (filed Oct-23): Note 30 Controlling party  immediate parent EQT Jupiter Luxco S.A.R.L; ultimate parent not disclosed; p.46.\n",
      "\n",
      "[#4] Seaport Topco Limited Annual Report FY24 (filed Sep-25): Notes to the Financial Statements  Borrowings and facilities (term loan and 30.0m RCF; secured by cross-company guarantees; lender names not disclosed), p.43.\n",
      "\n",
      "Companies House  Seaport Topco Limited (company number 14171962): company page (charges reviewed; none outstanding), officers page (directors/CEO appointment), filing history (FY24 accounts; CS01 confirmation statement listing share classes and Battery funds).\n",
      "- Company page: https://find-and-update.company-information.service.gov.uk/company/14171962\n",
      "- Officers: https://find-and-update.company-information.service.gov.uk/company/14171962/officers\n",
      "- FY24 accounts PDF: https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ4MjkwMzE0OWFkaXF6a2N4/document?download=0&format=pdf\n",
      "- CS01 (Jun-25) PDF: https://find-and-update.company-information.service.gov.uk/company/14171962/filing-history/MzQ3MTYxNzE3MmFkaXF6a2N4/document?download=0&format=pdf\n",
      "\n",
      "SPT Labtech official website (management):\n",
      "- Board of Directors: https://www.sptlabtech.com/board-of-directors\n",
      "- Executive Leadership (CEO, CFO): https://www.sptlabtech.com/executive-leadership\n",
      "\n",
      "EQT official press release (advisors for SPT Labtech acquisition, Jun-22):\n",
      "- https://eqtgroup.com/news/eqt-private-equity-to-acquire-spt-labtech-a-fast-growing-laboratory-automation-player-focused-on-low-volume-liquid-handling-technology-for-gbp-650-million-from-battery-ventures-2022-06-22\n",
      "\n",
      "Notes:\n",
      "- Where exact page numbers are not visible in the Companies House PDFs, n.a. is indicated; all links provided point to the specific filings referenced.\n",
      "- Lender names for bank facilities are not disclosed in the annual reports; therefore shown as n.a. in the Lenders table.\n"
     ]
    }
   ],
   "source": [
    "print(resp['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d078c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, textwrap\n",
    "import io\n",
    "\n",
    "from typing import List, Dict, Optional\n",
    "from xml.sax.saxutils import escape\n",
    "\n",
    "from gpts.gpt_assistants import general_assistant\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.search.documents.models import HybridSearch\n",
    "\n",
    "\n",
    "from openai import AzureOpenAI, APIConnectionError, OpenAI\n",
    "from prompts import new_system_finance_prompt\n",
    "\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
    "\n",
    "from prompts4 import finance_calculations, finance_pairs, capital_pairs, stakeholders_pairs, biz_overview_pairs, revenue_pairs, default_gpt_prompt, section4a, section4b, section5, section3, biz_overview_web\n",
    "from pages.design.func_tools import *\n",
    "from pages.design.formatting import *\n",
    "from pages.design.func_tools import docx_bytes_to_pdf_bytes\n",
    "import re, time\n",
    " \n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# ---- Config (expects the same envs you already used) ----\n",
    "SEARCH_ENDPOINT = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "SEARCH_INDEX    = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "SEARCH_KEY      = os.getenv(\"AZURE_SEARCH_API_KEY\")  # omit if using AAD/RBAC\n",
    "VECTOR_FIELD    = os.getenv(\"VECTOR_FIELD\")\n",
    "TEXT_FIELD      = os.getenv(\"TEXT_FIELD\")\n",
    "\n",
    "AOAI_ENDPOINT   = os.environ[\"AZURE_OPENAI_ENDPOINT\"]            # https://<resource>.openai.azure.com\n",
    "AOAI_API_VER    = os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-10-21\")\n",
    "AOAI_DEPLOYMENT = os.environ[\"AZURE_OPENAI_DEPLOYMENT\"]          # e.g., gpt-4o-mini / o3-mini / gpt-5 preview\n",
    "AOAI_KEY        = os.getenv(\"AZURE_OPENAI_API_KEY\")              # omit if using AAD\n",
    "OPENAI_API_KEY  = os.getenv(\"OPENAI_API_KEY\")        # required\n",
    "\n",
    "# ------------------ CODE\n",
    "\n",
    "class profileAgent():\n",
    "\n",
    "    \"\"\"Hybrid (dense+sparse) RAG over Vector Store\n",
    "\n",
    "    This Agent is responsible for creating Company Profiles. \n",
    "    It operates with gpt5.\n",
    "    It is activated by a call on main rag when it is typed 'Create company profile'\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, company_name, k, max_text_recall_size, max_chars, model, profile_prompt = new_system_finance_prompt, finance_calculations = finance_calculations):\n",
    "        \n",
    "        self.company_name = company_name\n",
    "\n",
    "        self.k = k\n",
    "        self.max_text_recall_size = max_text_recall_size\n",
    "        self.model = model\n",
    "        self.max_chars = max_chars\n",
    "\n",
    "        self.azure_credentials = AzureKeyCredential(SEARCH_KEY) if SEARCH_KEY else DefaultAzureCredential()\n",
    "        self.search_client = SearchClient(SEARCH_ENDPOINT, SEARCH_INDEX, credential=self.azure_credentials)\n",
    "\n",
    "        self.az_openai = AzureOpenAI(azure_endpoint=AOAI_ENDPOINT, api_key=AOAI_KEY, api_version=AOAI_API_VER)\n",
    "        self.profile_prompt = profile_prompt\n",
    "        self.web_openai = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "        self.reasoning_effort = \"medium\"\n",
    "        self.verbosity = \"medium\"\n",
    "\n",
    "        self.finance_calculations = finance_calculations\n",
    "\n",
    "    def _company_filter(self) -> str:\n",
    "        v = (self.company_name or \"\").replace(\"'\", \"''\").strip()\n",
    "        return f\"company_name eq '{v}'\" if v else None\n",
    "    \n",
    "    def assemble_bm25_from_llm(self, slots: dict) -> str:\n",
    "        def q(s: str) -> str:\n",
    "            # sanitize: remove internal quotes and trim\n",
    "            s = (s or \"\").strip().replace('\"', ' ')\n",
    "            return f\"\\\"{s}\\\"\" if s else \"\"\n",
    "        groups = []\n",
    "\n",
    "        # must-have phrases (ANDed)\n",
    "        for p in slots.get(\"must_have_phrases\", []):\n",
    "            qp = q(p)\n",
    "            if qp:\n",
    "                groups.append(qp)\n",
    "\n",
    "        # metric / statement synonym groups (ORed within each group)\n",
    "        for key in [\"metric\", \"statement\"]:\n",
    "            syns = slots.get(\"synonyms\", {}).get(key, []) or slots.get(key, [])\n",
    "            syns = [q(s) for s in syns if s]\n",
    "            if syns:\n",
    "                groups.append(\"(\" + \" OR \".join(syns) + \")\")\n",
    "\n",
    "        return \" AND \".join(groups) if groups else \"\\\"financial statements\\\"\"\n",
    "\n",
    "\n",
    "    def bm25_creator(self, prompt):\n",
    "\n",
    "        instruction = (\n",
    "            \"Extract finance search slots for Azure AI Search. \"\n",
    "            \"Return strict JSON: {\\\"metric\\\":[], \\\"statement\\\":[], \\\"synonyms\\\":{}, \\\"must_have_phrases\\\":[]} \"\n",
    "            \"(include IFRS/US GAAP variants).\"\n",
    "        )\n",
    "        resp = general_assistant(instruction, prompt, OPENAI_API_KEY, 'gpt-4o')\n",
    "\n",
    "        try:\n",
    "            slots = getattr(resp, \"output_json\", None)\n",
    "            if slots is None:\n",
    "                import json\n",
    "                slots = json.loads(resp.output_text)\n",
    "        except Exception:\n",
    "            # fallback: minimal anchors from prompt\n",
    "            slots = {\"must_have_phrases\": [prompt], \"metric\": [], \"statement\": [], \"synonyms\": {}}\n",
    "        return self.assemble_bm25_from_llm(slots)\n",
    "\n",
    "    def _retrieve_hybrid_enhanced(self, query_nl, k: int = 50, top_n = 30, fields=VECTOR_FIELD, max_text_recall_size:int = 800):\n",
    "        sc = self.search_client\n",
    "        flt = self._company_filter()\n",
    "        \n",
    "        try:\n",
    "            vq = VectorizableTextQuery(text=query_nl, k=k, fields=VECTOR_FIELD)\n",
    "            # Prefer vector-only search (integrated vectorization). If your index isn't set up for it, this raises.\n",
    "            results = sc.search(\n",
    "                search_text=self.bm25_creator(query_nl), \n",
    "                vector_queries=[vq], \n",
    "                top=top_n, \n",
    "                query_type=\"semantic\",\n",
    "                query_caption=\"extractive\", \n",
    "                hybrid_search=HybridSearch(max_text_recall_size=self.max_text_recall_size),\n",
    "                query_caption_highlight_enabled=True,\n",
    "                filter=flt\n",
    "                )\n",
    "            mode = \"hybrid + semantic\"\n",
    "        except HttpResponseError as e:\n",
    "            # Fall back to lexical so you still get results while fixing vector config\n",
    "            results = sc.search(search_text=self.bm25_creator(query_nl), top=k)\n",
    "            mode = f\"lexical (fallback due to: {e.__class__.__name__})\"\n",
    "\n",
    "        hits: List[Dict] = []\n",
    "        for r in results:\n",
    "            d = r.copy() if hasattr(r, \"copy\") else {k2: r[k2] for k2 in r}\n",
    "            d[\"score\"] = d.get(\"@search.reranker_score\") or d.get(\"@search.score\") or 0.0\n",
    "            caps = d.get(\"@search.captions\")\n",
    "            if isinstance(caps, list) and caps:\n",
    "                d[\"caption\"] = getattr(caps[0], \"text\", None)\n",
    "            hits.append(d)\n",
    "\n",
    "        return mode, hits\n",
    "\n",
    "\n",
    "    def _build_context(self, hits: List[Dict], text_field: str = TEXT_FIELD, max_chars: int = 20000):\n",
    "        \"\"\"Build a compact, numbered context block and also return the selected chunk metadata.\"\"\"\n",
    "        lines = []\n",
    "        total = 0\n",
    "        selected = []  # <- we'll return this\n",
    "\n",
    "        for i, h in enumerate(hits, 1):\n",
    "            title     = h.get(\"title\")\n",
    "            chunk_id  = h.get(\"chunk_id\")\n",
    "            full_text = (h.get(text_field) or \"\")\n",
    "            if not full_text:\n",
    "                continue\n",
    "\n",
    "            preview = textwrap.shorten(full_text, width=700, placeholder=\" ...\")\n",
    "            block = f\"[{i}] title={title!r} | chunk_id={chunk_id} | score={h.get('score'):.4f}\\n{full_text}\"\n",
    "\n",
    "            if total + len(block) > self.max_chars:\n",
    "                break\n",
    "\n",
    "            total += len(block)\n",
    "            lines.append(block)\n",
    "\n",
    "            # keep rich metadata so you can show or log it later\n",
    "            selected.append({\n",
    "                \"i\": i,\n",
    "                \"title\": title,\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"score\": h.get(\"score\"),\n",
    "                \"caption\": h.get(\"caption\"),\n",
    "                \"preview\": preview,\n",
    "                \"text\": full_text,  # full chunk text (not shortened)\n",
    "                # include any other fields you index, if available:\n",
    "                \"metadata_storage_path\": h.get(\"metadata_storage_path\"),\n",
    "                \"page_number\": h.get(\"page_number\"),\n",
    "                \"doc_type\": h.get(\"doc_type\"),\n",
    "            })\n",
    "\n",
    "        return \"\\n\\n---\\n\\n\".join(lines), selected\n",
    "\n",
    "        \n",
    "    def _generate_pdf(self, text: str) -> bytes:\n",
    "\n",
    "        buf = io.BytesIO()\n",
    "        doc = SimpleDocTemplate(buf, pagesize=letter)\n",
    "        styles = getSampleStyleSheet()\n",
    "        body = styles[\"BodyText\"]\n",
    "\n",
    "        story = []\n",
    "        # Treat double newlines as paragraph breaks; keep single newlines as <br/>\n",
    "        for para in (text or \"\").split(\"\\n\\n\"):\n",
    "            safe = escape(para).replace(\"\\n\", \"<br/>\")\n",
    "            story.append(Paragraph(safe if safe.strip() else \"&nbsp;\", body))\n",
    "            story.append(Spacer(1, 8))\n",
    "\n",
    "        doc.build(story)\n",
    "        buf.seek(0)\n",
    "        return buf.getvalue()\n",
    "    \n",
    "    def _extract_cited_idxs(self, answer: str) -> list[int]:\n",
    "        # Matches [#1], [#12], etc. (also tolerates stray [1])\n",
    "        nums = set(int(n) for n in re.findall(r\"\\[#?(\\d+)\\]\", answer))\n",
    "        return sorted(nums)\n",
    "\n",
    "    def _rag_answer(self, rag_nl, question, k: int = 5, temperature: float = 0.2):\n",
    "\n",
    "        # question = f'CREATE A SECTION OF COMPANY PROFILE USING LAST YEARS OF ANNUAL REPORT PRESENT IN THE CONTEXT FOR {self.company_name}. IF ANY INFORMATION IS NOT FOUND STATE AS n.a. .\\n\\n THIS IS THE SECTION TO BE BUILT: \\n {section7}  \\n USE THIS TO GUIDE YOURSELF ON SEMANTIC TERMS AND HOW TO CALCULATE: \\n {finance_calculations}'\n",
    "        \n",
    "        mode, hits = self._retrieve_hybrid_enhanced(\n",
    "            # query=rag_q, \n",
    "            query_nl=rag_nl,\n",
    "            k=25\n",
    "            )\n",
    "        ctx_text, ctx_items = self._build_context(hits)\n",
    "\n",
    "        system_msg = self.profile_prompt + (\n",
    "            \"\\nWhen you use a fact from the context, add citations like [#1], [#2].\"\n",
    "            \"\\nOnly rely on the numbered context; if a value is missing, say 'n.a.'.\"\n",
    "            f\"\\nIF ANY INFORMATION IS NOT FOUND STATE AS n.a. .\\n\\n USE THIS TO GUIDE YOURSELF ON SEMANTIC TERMS AND HOW TO CALCULATE: \\n {finance_calculations}\"\n",
    "        )\n",
    "        user_msg = f\"Question:\\n{question}\\n\\nContext snippets (numbered):\\n{ctx_text}\"\n",
    "\n",
    "        client = self.az_openai\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\",   \"content\": user_msg},\n",
    "        ]\n",
    "\n",
    "        # Try streaming first (SSE). Some networks/proxies block streaming; if so, fall back.\n",
    "        \n",
    "        resp = client.chat.completions.create(\n",
    "            model=AOAI_DEPLOYMENT,\n",
    "            messages=messages,\n",
    "            reasoning_effort=\"high\"\n",
    "        )\n",
    "        answer = resp.choices[0].message.content\n",
    "        mode_model = \"non-streaming (fallback)\"\n",
    "\n",
    "        cited = self._extract_cited_idxs(answer)\n",
    "        used_chunks = [c for c in ctx_items if c[\"i\"] in cited]\n",
    "\n",
    "        # return self._generate_pdf(answer)\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"citations\": cited,          # [1, 3, 7]\n",
    "            \"used_chunks\": used_chunks,  # detailed dicts for each cited snippet\n",
    "            \"all_chunks\": ctx_items,     # everything you sent (optional)\n",
    "            \"mode\": mode                 # retrieval mode info (optional)\n",
    "        }\n",
    "\n",
    "    def _web_search(self, messages):\n",
    "        resp = self.web_openai.responses.create(\n",
    "            model='gpt-5',\n",
    "            input=messages,\n",
    "            tools=[{\"type\": \"web_search\"}],\n",
    "            tool_choice=\"auto\",\n",
    "            # max_output_tokens=self.max_output_tokens,\n",
    "            reasoning={\"effort\": self.reasoning_effort},\n",
    "            text={\"verbosity\": self.verbosity},\n",
    "        )\n",
    "        \n",
    "        return resp.output_text\n",
    "    \n",
    "    def _answer(self, question, ctx_text, k: int = 5, temperature: float = 0.2):\n",
    "\n",
    "        system_msg = self.profile_prompt + (\n",
    "            \"\\nWhen you use a fact from the context, preserve any existing citations like [#1], [#2], [#5, p.41] that are already in the context text.\"\n",
    "            \"\\nOnly rely on the provided context; if a value is missing, say 'n.a.'.\"\n",
    "            \"\\nIMPORTANT: If the formatting instructions request a Sources section, you MUST include it at the end.\"\n",
    "            \"\\nFor the Sources section, list all citation numbers/references that appear in your answer, and describe what document/source each refers to based on information in the context.\"\n",
    "        )\n",
    "        user_msg = f\"Question:\\n{question}\\n\\nContext snippets:\\n{ctx_text}\"\n",
    "\n",
    "        client = self.az_openai\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_msg},\n",
    "            {\"role\": \"user\",   \"content\": user_msg},\n",
    "        ]\n",
    "\n",
    "        # Try streaming first (SSE). Some networks/proxies block streaming; if so, fall back.\n",
    "\n",
    "        resp = client.chat.completions.create(\n",
    "            model=AOAI_DEPLOYMENT,\n",
    "            messages=messages,\n",
    "            reasoning_effort=\"high\"\n",
    "        )\n",
    "        answer = resp.choices[0].message.content\n",
    "\n",
    "        cited = self._extract_cited_idxs(answer)\n",
    "\n",
    "        # return self._generate_pdf(answer)\n",
    "        return {\n",
    "            \"answer\": answer,\n",
    "            \"citations\": cited,          # [1, 3, 7]\n",
    "        }   \n",
    "    \n",
    "    @staticmethod\n",
    "    def has_na(text: str) -> bool:\n",
    "        # match \"n.a.\" or \"n/a\" (case-insensitive)\n",
    "        return bool(re.search(r\"\\b(n\\.a\\.|n/a)\\b\", text, flags=re.I))\n",
    "\n",
    "    def _sections(self, pairs):\n",
    "\n",
    "        answers = []\n",
    "\n",
    "        max_extra_na_retries = 1        # try again at most 2 times (total <= 3 calls per item)\n",
    "        base_delay_seconds = 3.0        # polite delay between attempts\n",
    "\n",
    "\n",
    "        for q, r in pairs:\n",
    "            tries = 0\n",
    "            while True:\n",
    "                if tries > 0:\n",
    "                    # small incremental delay before re-trying\n",
    "                    time.sleep(base_delay_seconds + 0.5 * tries)\n",
    "\n",
    "                resp = self._rag_answer(rag_nl=r[0], question=q[0])\n",
    "                answer_text = resp[\"answer\"]\n",
    "\n",
    "                # stop if good answer OR we've exhausted retries\n",
    "                if not profileAgent.has_na(answer_text) or tries >= max_extra_na_retries:\n",
    "                    answers.append(answer_text)\n",
    "                    break\n",
    "\n",
    "                # otherwise, try again\n",
    "                tries += 1\n",
    "\n",
    "            # optional small gap between different (r,q) items\n",
    "            time.sleep(5.0)\n",
    "        \n",
    "        return answers\n",
    "    \n",
    "    def _generate_section(self, section):\n",
    "\n",
    "        if section == 'GENERATE BUSINESS OVERVIEW':\n",
    "            # =========== GENERATE BUSINESS OVERVIEW\n",
    "            biz_overview_pairs_flat = list(zip(biz_overview_pairs[1], biz_overview_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "            section_built = self._sections(pairs = biz_overview_pairs_flat)\n",
    "\n",
    "            #getting web search sections\n",
    "            new_section = f'All instructions applies to the company: {self.company_name}\\n\\n{biz_overview_web} \\n\\n Mention in the Beggining of the answer that this is WEBSEARCH SOURCE'\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": default_gpt_prompt},\n",
    "                {\"role\": \"user\",   \"content\": new_section},\n",
    "            ]\n",
    "            resp_web = self._web_search(messages)\n",
    "\n",
    "            section_built.append(resp_web)\n",
    "\n",
    "            # Join all context sections - they already contain their own citations\n",
    "            # Just concatenate them so the model can synthesize\n",
    "            ctx_text_formatted = \"\\n\\n\".join(section_built)\n",
    "\n",
    "            resp = self._answer(question=biz_overview_mix_formatting, ctx_text=ctx_text_formatted)\n",
    "            return resp['answer']\n",
    "        elif section == 'GENERATE KEY STAKEHOLDERS':\n",
    "        # =========== GENERATE KEY STAKEHOLDERS\n",
    "            stakeholders_pairs_flat = list(zip(stakeholders_pairs[1], stakeholders_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "            section_built = self._sections(pairs= stakeholders_pairs_flat)\n",
    "            resp = self._answer(question=stakeholders_formatting_2, ctx_text=section_built)\n",
    "            return resp['answer']\n",
    "        elif section == 'GENERATE FINANCIAL HIGHLIGHTS':\n",
    "            # =========== GENERATE FINANCIAL HIGHLIGHTS\n",
    "            finance_pairs_flat = list(zip(finance_pairs[1], finance_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "            section_built = self._sections(pairs=finance_pairs_flat)\n",
    "            resp = self._answer(question=finance_formatting_2, ctx_text=section_built)\n",
    "            return resp['answer']\n",
    "        elif section == 'GENERATE CAPITAL STRUCTURE':\n",
    "            # =========== GENERATE CAPITAL STRUCTURE\n",
    "            capital_pairs_flat = list(zip(capital_pairs[1], capital_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "            section_built = self._sections(pairs= capital_pairs_flat)\n",
    "            resp = self._answer(question=capital_structure_formatting_2, ctx_text=section_built)\n",
    "            return resp['answer']\n",
    "        elif section == 'GENERATE REVENUE SPLIT':\n",
    "            # =========== GENERATE CAPITAL STRUCTURE\n",
    "            revenue_pairs_flat = list(zip(revenue_pairs[1], revenue_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "            section_built = self._sections(pairs= revenue_pairs_flat)\n",
    "            resp = self._answer(question=section3, ctx_text=section_built)\n",
    "            return resp['answer']\n",
    "        elif section == 'GENERATE PRODUCTS SERVICES OVERVIEW':\n",
    "            # =========== GENERATE CAPITAL STRUCTURE\n",
    "            new_section = f'All instructions applies to the company: {self.company_name}\\n\\n{section4a}'\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": default_gpt_prompt},\n",
    "                {\"role\": \"user\",   \"content\": new_section},\n",
    "            ]\n",
    "            resp = self._web_search(messages)\n",
    "            return resp \n",
    "        elif section == 'GENERATE GEO FOOTPRINT':\n",
    "            # =========== GENERATE CAPITAL STRUCTURE\n",
    "            new_section = f'All instructions applies to the company: {self.company_name}\\n\\n{section4b}'\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": default_gpt_prompt},\n",
    "                {\"role\": \"user\",   \"content\": new_section},\n",
    "            ]\n",
    "            resp = self._web_search(messages)\n",
    "            return resp\n",
    "        elif section == 'GENERATE DEVELOPMENTS HIGHLIGHTS':\n",
    "            # =========== GENERATE CAPITAL STRUCTURE\n",
    "            new_section = f'All instructions applies to the company: {self.company_name}\\n\\n{section5}'\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": default_gpt_prompt},\n",
    "                {\"role\": \"user\",   \"content\": new_section},\n",
    "            ]\n",
    "            resp = self._web_search(messages)\n",
    "            return resp\n",
    "\n",
    "\n",
    "    def generate_company_profile(self):\n",
    "\n",
    "        # =========== GENERATE BUSINESS OVERVIEW\n",
    "        biz_overview_pairs_flat = list(zip(biz_overview_pairs[1], biz_overview_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "        section1 = self._sections(pairs = biz_overview_pairs_flat)\n",
    "        resp = self._answer(question=business_overview_formatting, ctx_text=section1)\n",
    "        doc = insert_biz_overview(resp['answer'])\n",
    "\n",
    "        time.sleep(60)\n",
    "        # =========== GENERATE KEY STAKEHOLDERS\n",
    "        stakeholders_pairs_flat = list(zip(stakeholders_pairs[1], stakeholders_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "        section2 = self._sections(pairs= stakeholders_pairs_flat)\n",
    "        resp = self._answer(question=stakeholders_formatting, ctx_text=section2)\n",
    "        doc = insert_stakeholders(resp['answer'], doc=doc)\n",
    "        \n",
    "        time.sleep(60)\n",
    "        # =========== GENERATE FINANCIAL HIGHLIGHTS\n",
    "        finance_pairs_flat = list(zip(finance_pairs[1], finance_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "        section3 = self._sections(pairs=finance_pairs_flat)\n",
    "        resp = self._answer(question=finance_formatting, ctx_text=section3)\n",
    "        doc = insert_finance(resp['answer'], doc=doc)\n",
    "\n",
    "        time.sleep(60)\n",
    "        # =========== GENERATE CAPITAL STRUCTURE\n",
    "        capital_pairs_flat = list(zip(capital_pairs[1], capital_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "        section4 = self._sections(pairs= capital_pairs_flat)\n",
    "        resp = self._answer(question=capital_structure_formatting_2, ctx_text=section4)\n",
    "        doc = insert_capital_structure(resp['answer'], doc=doc)\n",
    "\n",
    "        pdf_bytes = docx_bytes_to_pdf_bytes(doc)\n",
    "\n",
    "        return pdf_bytes\n",
    "        # =========== UNION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31725b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated document written\n",
      "Updated document written\n",
      "Updated document written\n",
      "WARNING  CSV metrics not matched to any row:\n",
      " - Revenue (Turnover)\n",
      " - Revenue growth % (yoy)\n",
      " - Cost of sales\n",
      " - Operating profit\n",
      " - Depreciation\n",
      " - Amortization\n",
      " - Net cash flow from operating activities\n",
      " - Net working capital (cash flow changes)\n",
      " - Cash flow from operating activities excl. working capital\n",
      " - Net cash flow from investing activities\n",
      " - Net cash flow from financing activities\n",
      " - Debt issuance (draw down of bank loans)\n",
      " - Share issuance\n",
      " - Leverage (Net Debt/EBITDA)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'soffice'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 223\u001b[0m\n\u001b[1;32m    220\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mmove(produced, pdf_path)\n\u001b[1;32m    221\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(tmpdir, ignore_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 223\u001b[0m \u001b[43msave_docx_to_pdf_via_libreoffice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreport.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 214\u001b[0m, in \u001b[0;36msave_docx_to_pdf_via_libreoffice\u001b[0;34m(doc, pdf_path)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# Convert using LibreOffice in headless mode\u001b[39;00m\n\u001b[1;32m    209\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoffice\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--headless\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--nologo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--convert-to\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdf:writer_pdf_Export\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--outdir\u001b[39m\u001b[38;5;124m\"\u001b[39m, outdir, docx_path\n\u001b[1;32m    213\u001b[0m ]\n\u001b[0;32m--> 214\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m produced \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(outdir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreport.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(produced):\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstdout\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m    503\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[0;32m--> 505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    507\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[1;32m    947\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/subprocess.py:1821\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1819\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1820\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1821\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1822\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'soffice'"
     ]
    }
   ],
   "source": [
    "\n",
    "import io, tempfile, subprocess, shutil\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_BREAK\n",
    "\n",
    "\n",
    "biz_output = \"\"\"\n",
    "Here are the requested variables for Seaport Topco Limited, with sources and page references:\n",
    "\n",
    "- Primary Activity:\n",
    "  - The principal activity of the Group continues to include the research and development of pharmaceutical instrumentation. Source: Annual Report (FY23), Strategic/Directors Report, p.5 [1][2].\n",
    "\n",
    "- Business Review:\n",
    "  - FY24 Group Strategic Report (Review of the business and future developments):\n",
    "    - Cash and cash equivalents decreased from 11.8m at Dec-23 to 11.8m at Dec-24; cash generated from operating activities was 10.4m (FY23: 15.3m).\n",
    "    - Stock reduced to 13.2m at Dec-24 (Dec-23: 15.4m).\n",
    "    - Trade debtors increased to 17.0m at Dec-24 (Dec-23: 13.2m) due to higher late-year revenue.\n",
    "    - Creditors due within one year increased to 64.7m at Dec-24 (Dec-23: 46.6m), driven by new loans (7.7m) and a net RCF draw (9.2m).\n",
    "    - Deferred tax liability decreased, largely due to decreases on intangible fixed assets (4.7m) and a charge related to losses on consolidation (4.8m).\n",
    "    - Headcount rose to 418 (from 405).\n",
    "    - Source: Annual Report (FY24), Group Strategic Report, Review of the business and future developments (continued), within Group Strategic Report pages 15; exact page n.a. [9]. For section pagination reference, see FY23 contents page indicating Group Strategic Report spans pp.15 [3][4].\n",
    "\n",
    "- Introduction:\n",
    "  - n.a. (No explicit Introduction section text available in the provided excerpts) [3][4][9].\n",
    "\n",
    "- Bank Debt/Borrowings/Creditors:\n",
    "  - Creditors: amounts falling due within one year: 46.6m at Dec-23 (restated Dec-22: 35.4m)  Note 21, Consolidated Statement of Financial Position, p.14 [7][8].\n",
    "  - Creditors: amounts falling due after more than one year: 168.7m at Dec-23 (restated Dec-22: 171.7m)  Note 22, Consolidated Statement of Financial Position, p.14 [7][8].\n",
    "  - FY24 movement: Creditors due within one year increased to 64.7m at Dec-24, driven by 7.7m of new loans and a 9.2m net draw on the revolving credit facility  Group Strategic Report (FY24), Review of the business and future developments (continued), exact page n.a. (within pp.15) [9].\n",
    "\"\"\"\n",
    "\n",
    "cap_output = r\"\"\"\n",
    "Metric,FY24,FY23,FY22\n",
    "\"Facility Name\",\"n.a.\",\"Facility B1 (EUR term loan); Facility B2 (USD term loan); Revolving Credit Facility; Delayed Drawdown Facility [#2][#3]\",\"Revolving Credit Facility; Delayed Drawdown Facility [#3]\"\n",
    "\"Interest Rate\",\"n.a.\",\"Euribor + 6.25%; Term SOFR + 6.25% [#2][#3]\",\"n.a.\"\n",
    "Maturity,\"n.a.\",\"Aug-29 [#2][#3]\",\"n.a.\"\n",
    "\"Adjusted EBITDA\",\"n.a.\",\"17.9m [#2][#3]\",\"10.6m [#2][#3]\"\n",
    "\"Cash (Closing Cash)\",\"n.a.\",\"11.8m [#2][#3]\",\"n.a.\"\n",
    "\"Net Debt\",\"n.a.\",\"171.9m [#2][#3]\",\"n.a.\"\n",
    "Liquidity,\"n.a.\",\"25.8m [#2][#3]\",\"n.a.\"\n",
    "\"Leverage (Net Debt/EBITDA)\",\"n.a.\",\"9.6x [#2][#3]\",\"n.a.\"\n",
    "\"Facility B1 outstanding (GBP)\",\"n.a.\",\"36.0m [#2][#3]\",\"n.a.\"\n",
    "\"Facility B2 outstanding (GBP)\",\"n.a.\",\"135.0m [#2][#3]\",\"n.a.\"\n",
    "\"RCF drawn\",\"n.a.\",\"16.0m [#2][#3]\",\"16.0m [#3]\"\n",
    "\"RCF facility size\",\"n.a.\",\"30.0m [#2][#3]\",\"30.0m [#3]\"\n",
    "\"Delayed Drawdown Facility size\",\"n.a.\",\"75.0m [#2][#3]\",\"75.0m [#3]\"\n",
    "\"Bank loans due after >5 years\",\"n.a.\",\"168.7m [#2][#3]\",\"n.a.\"\n",
    "\"Bank loans due within 1 year\",\"n.a.\",\"14.7m [#2][#3]\",\"n.a.\"\n",
    "\"Bank loans + RCF outstanding (excl. leases)\",\"n.a.\",\"187.0m [#2][#3]\",\"n.a.\"\n",
    "\n",
    "Summary / Interpretation\n",
    "- FY23 leverage is high at 9.6x, based on 171.9m net debt and 17.9m Adjusted EBITDA.\n",
    "- FY23 facility mix is dominated by term loans (Facility B1 ~36.0m and B2 ~135.0m) maturing in Aug-29, plus a 30.0m RCF (of which 16.0m was drawn) and a 75.0m delayed draw facility.\n",
    "- FY23 liquidity appears modest at 25.8m, combining 11.8m closing cash with remaining headroom on the 30.0m RCF (drawn 16.0m).\n",
    "- Maturity profile in FY23 is back-ended: 168.7m due after >5 years versus 14.7m due within 1 year; both term facilities mature in Aug-29.\n",
    "- Total FY23 bank loans + RCF outstanding (excl. leases) sums to 187.0m, indicating a sizeable secured debt stack.\n",
    "- FY24 disclosures are not available in the provided excerpts, and FY22 data is limited beyond RCF details.\n",
    "\n",
    "Sources\n",
    "- [#2] Seaport Topco Limited Annual Report (file date 25-Sep-24), pp. 8, 45, 52  p.8 Adjusted EBITDA (17.9m FY23; 10.6m FY22); p.45 Loans note (Facility B1/B2 amounts, Aug-29 maturities, interest margins; RCF 30.0m and ~16.0m drawn; 75.0m delayed draw facility; bank loans due >5 years 168.7m and within 1 year 14.7m); p.52 Net debt analysis (Net Debt 171.9m; closing cash 11.8m). Link: https://aiprojectteneo.blob.core.windows.net/companieshouselinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_0.pdf\n",
    "- [#3] Seaport Topco Limited Annual Report (file date 25-Sep-24), pp. 8, 36, 45, 52  corroborates Adjusted EBITDA figures; Going concern (p.36) notes RCF drawn 16.0m at Dec-22; Loans note (p.45) for facility sizes/draws and maturities; Net debt analysis (p.52) for Net Debt and closing cash. Link: https://aiprojectteneo.blob.core.windows.net/companieshousinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_1.pdf\n",
    "\"\"\"\n",
    "\n",
    "stakeholders_output = r\"\"\"\n",
    "Metric,Shareholders\n",
    "\"Shareholders\",n.a.\n",
    "\"Management\",\"Directors (FY24): M Bauer; R Diggelmann  resigned Dec-24; P Dowdy  resigned Feb-25; J Feldman; R Friel  resigned Mar-25; K Murphy; D Newble  resigned Jul-24; A Thorburn; R Walton  appointed Jul-24\"\n",
    "\"Lenders\",n.a.\n",
    "\"Auditors\",\"Grant Thornton UK LLP (Statutory Auditor); Stephen Wyborn (Senior Statutory Auditor)\"\n",
    "\"Advisors\",\"Facility agent: Kroll Agency Services Limited; Bankers: n.a.; Solicitors: n.a.; Financial advisor: n.a.\"\n",
    "\n",
    "Summary / Interpretation\n",
    "- Shareholder information is n.a., indicating no disclosed immediate or ultimate parent in the provided filings.\n",
    "- Management is represented by the FY24 directors list; specific Chairman/CEO/CFO titles are not provided.\n",
    "- Lenders are n.a., suggesting no disclosed bank facilities/borrowings in the available excerpts.\n",
    "- Auditors are identified (Grant Thornton UK LLP; Senior Statutory Auditor Stephen Wyborn), while most other advisors are n.a. except the facility agent (Kroll Agency Services Limited).\n",
    "- Advisor disclosure is limited (bankers/solicitors/financial advisor n.a.), constraining visibility into counterparties.\n",
    "\n",
    "SECTION 3 - SOURCES\n",
    "- [#1] Seaport Topco Limited AA Annual Report (published Sep-25), Directors Report for the year ended 31 Dec-24, p.12. Link: https://aiprojectteneo.blob.core.windows.net/companieshousesinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2025-09-30_0.pdf  used for the Management (directors) row.\n",
    "- [#2] Seaport Topco Limited AA Annual Report (2024-09-25)  provided excerpt indicating Company Information page not available  supports n.a. for certain advisor details.\n",
    "- [#3] Seaport Topco Limited annual report (FY24), Notes to the Financial Statements  Accounting policies excerpt (page n.a.)  used to check terminology (bank loans/borrowings); lenders n.a. and facility agent reference noted elsewhere.\n",
    "- [#4] Seaport Topco Limited Annual Report 2024, Independent Auditors Report signature block, file: SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_1.pdf (26 pages), signed Apr-24  used for Auditors identification and to support shareholder n.a.\n",
    "- [#5] Seaport Topco Limited Annual Report (published Sep-24), Notes to the Financial Statements, Note 16: Fixed asset investments  Indirect subsidiary undertakings (page n.a.)  used to support Shareholders n.a. (no parent/ultimate controlling party disclosed).\n",
    "- [#7] Seaport Topco Limited Annual Report 2024, Independent Auditors Report signature block, file: SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_0.pdf (26 pages), signed Apr-24  corroborates Auditors identification.\n",
    "\"\"\"\n",
    "\n",
    "finance_output = \"\"\"\n",
    "Metric,FY24,FY23,FY22\n",
    "\"Revenue (Turnover)\",\"576.8m [#6]\",\"81.435m [#6]\",\"n.a.\"\n",
    "\"Revenue growth % (yoy)\",\"+608.6% [#6]\",\"n.a.\",\"n.a.\"\n",
    "\"Cost of sales\",\"n.a.\",\"33.0m [#3]\",\"18.5m [#3]\"\n",
    "\"Gross profit\",\"43.9m [#6]\",\"48.4m [#3]\",\"14.3m [#3]\"\n",
    "\"Gross margin %\",\"7.6% [#6]\",\"59.5% [#3][#6]\",\"n.a.\"\n",
    "\"EBITDA\",\"n.a.\",\"20.2m [#4]\",\"(1.2)m [#4]\"\n",
    "\"EBITDA margin %\",\"n.a.\",\"24.8% [#4][#6]\",\"n.m. [#4]\"\n",
    "\"Operating profit\",\"n.a.\",\"(273.1)m [#4]\",\"(22.9)m [#4]\"\n",
    "\"Depreciation\",\"n.a.\",\"2.0m [#4]\",\"0.6m [#4]\"\n",
    "\"Amortization\",\"n.a.\",\"60.6m [#4]\",\"21.2m [#4]\"\n",
    "\"Net cash flow from operating activities\",\"9.6m [#11]\",\"15.3m [#1]\",\"(1.8)m [#1]\"\n",
    "\"Net working capital (cash flow changes)\",\"n.a.\",\"3.9m [#7]\",\"(3.0)m [#7]\"\n",
    "\"Cash flow from operating activities excl. working capital\",\"n.a.\",\"11.4m [#1][#7]\",\"1.2m [#1][#7]\"\n",
    "\"Net cash flow from investing activities\",\"(2.7)m [#11]\",\"(8.0)m [#1]\",\"(639.0)m [#1]\"\n",
    "\"Capex\",\"n.a.\",\"7.2m [#9]\",\"0.9m [#9]\"\n",
    "\"Other cash flow from investing activities\",\"n.a.\",\"(15.2)m [#1][#9]\",\"(639.9)m [#1][#9]\"\n",
    "\"CFADS\",\"6.9m [#11]\",\"7.3m [#1]\",\"(640.8)m [#1]\"\n",
    "\"Net cash flow from financing activities\",\"n.a.\",\"(4.2)m [#10]\",\"657.6m [#10]\"\n",
    "\"Debt issuance (draw down of bank loans)\",\"n.a.\",\"12.1m [#10]\",\"187.3m [#10]\"\n",
    "\"Share issuance\",\"n.a.\",\"0.4m [#10]\",\"484.2m [#10]\"\n",
    "\"Opening cash\",\"11.8m [#10]\",\"n.a.\",\"n.a.\"\n",
    "\"Change in cash\",\"n.a.\",\"n.a.\",\"n.a.\"\n",
    "\"Closing cash\",\"n.a.\",\"11.8m [#12]\",\"9.0m [#12]\"\n",
    "\"Total debt\",\"n.a.\",\"183.4m [#13]\",\"n.a.\"\n",
    "\"Net debt\",\"n.a.\",\"171.6m [#13]\",\"n.a.\"\n",
    "\"Leverage (Net Debt/EBITDA)\",\"n.a.\",\"8.5x [#13][#4]\",\"n.m. [#4]\"\n",
    "\n",
    "Summary / Interpretation\n",
    "- FY24 shows a dramatic revenue surge (+608.6% yoy) versus FY23, while gross margin compresses sharply to 7.6% from 59.5%, indicating significant mix/pricing shifts.\n",
    "- Operating performance improved from FY22 to FY23 (EBITDA turning from negative to 20.2m and a 24.8% margin), but FY24 EBITDA is n.a., limiting margin trend analysis for the latest year.\n",
    "- CFADS is positive in both FY24 (6.9m) and FY23 (7.3m), contrasting with the large negative CFADS in FY22 ((640.8)m) driven by heavy investing outflows.\n",
    "- FY23 working-capital movements (3.9m outflow) reduced reported operating cash; excluding working capital, FY23 operating cash was 11.4m versus 1.2m in FY22.\n",
    "- FY23 leverage is high at 8.5x (Net debt 171.6m vs EBITDA 20.2m), highlighting balance sheet pressure despite improved operating earnings.\n",
    "- Several FY24 balance-sheet/cash items (EBITDA, debt, closing cash) are n.a., so liquidity/leverage assessments for FY24 rely mainly on cash flow and top-line signals.\n",
    "\n",
    "SECTION 3 - SOURCES\n",
    "- [#1] Seaport Topco Limited 2024 Annual Report (filed Sep-24), Consolidated Statement of Cash Flows, p.18  FY23 net cash from operating activities (15.3m) and net cash used in investing ((8.0)m); FY22 net cash used in operating ((1.8)m) and investing ((639.0)m). Source reference within context: p.18 [4].\n",
    "- [#3] Seaport Topco Limited 2024 Annual Report (Sep-24), Consolidated Statement of Comprehensive Income, p.13  FY23/FY22 cost of sales (33.0m/18.5m) and gross profit (48.4m/14.3m). Link: https://approjectteneo.blob.core.windows.net/companyhousesinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_0.pdf and duplicate [#4].\n",
    "- [#4] Seaport Topco Limited AA annual report (2024-09-25), p.9  FY23/FY22 operating loss (273.1m/22.9m), depreciation (2.0m/0.6m), amortization (60.6m/21.2m), and EBITDA (20.2m/(1.2)m).\n",
    "- [#6] Seaport Topco Limited Consolidated Statement of Comprehensive Income for the year ended 31 Dec-24 (SEAPORT_TOPCO_LIMITED_AA_annualReport_2025-09-30_0.pdf), p.12  FY24 revenue (576.8m), gross profit (43.9m), and gross margin (7.6%); FY23 revenue referenced at 81.435m.\n",
    "- [#7] Seaport Topco Limited Annual Report (Sep-24), Consolidated Statement of Cash Flows, p.18  Working-capital movement lines (stocks, debtors, creditors) used to compute NWC for FY23 (3.9m) and FY22 ((3.0)m).\n",
    "- [#9] Seaport Topco Limited 2024 Annual Report, Consolidated Statement of Cash Flows, p.18  Capex components: purchase of tangible and intangible fixed assets (FY23: 6.2m and 1.0m; FY22: 0.9m and n.a.). Links: https://aprojectteneo.blob.core.windows.net/companieshousesinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_0.pdf and duplicate [#5].\n",
    "- [#10] Seaport Topco Limited 2024 Annual Report, Consolidated Statement of Cash Flows (continued), p.19  FY23 net cash from financing ((4.2)m), debt issuance (12.1m), share issuance (0.4m); FY22 net financing (657.6m), debt issuance (187.3m), share issuance (484.2m); FY24 opening cash (11.8m).\n",
    "- [#12] Seaport Topco Limited 2024 Annual Report, Consolidated Statement of Cash Flows, p.19  Closing cash: FY23 11.8m and FY22 9.0m.\n",
    "- [#13] Seaport Topco Limited 2024 Annual Report, Note 31 Analysis of net debt, p.52  FY23 total debt (183.4m) and net debt (171.6m).\n",
    "- [#11] Seaport Topco Limited Annual Report 2025 (partial excerpt), Consolidated Statement of Cash Flows, p.17  FY24 net cash from operating activities (9.6m) and net cash used in investing ((2.7)m); Change in cash not shown.\n",
    "\"\"\"\n",
    "\n",
    "def _docx_bytes_to_pdf_bytes_with_docx2pdf(docx_bytes: bytes) -> Optional[bytes]:\n",
    "    try:\n",
    "        from docx2pdf import convert  # requires MS Word (Windows/macOS)\n",
    "    except Exception:\n",
    "        return None\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as td:\n",
    "            in_path  = Path(td) / \"doc.docx\"\n",
    "            out_path = Path(td) / \"doc.pdf\"\n",
    "            in_path.write_bytes(docx_bytes)\n",
    "            convert(str(in_path), str(out_path))  # Word/Automator\n",
    "            return out_path.read_bytes() if out_path.exists() else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _docx_bytes_to_pdf_bytes_with_lo(docx_bytes: bytes) -> Optional[bytes]:\n",
    "    soffice = shutil.which(\"soffice\") or shutil.which(\"libreoffice\")\n",
    "    if not soffice:\n",
    "        return None\n",
    "    try:\n",
    "        with tempfile.TemporaryDirectory() as td:\n",
    "            in_path  = Path(td) / \"doc.docx\"\n",
    "            out_dir  = Path(td) / \"out\"\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            in_path.write_bytes(docx_bytes)\n",
    "            r = subprocess.run(\n",
    "                [soffice, \"--headless\", \"--convert-to\", \"pdf\", \"--outdir\", str(out_dir), str(in_path)],\n",
    "                check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "            )\n",
    "            out_path = out_dir / \"doc.pdf\"\n",
    "            return out_path.read_bytes() if out_path.exists() else None\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def docx_bytes_to_pdf_bytes(docx_bytes: bytes) -> Optional[bytes]:\n",
    "    return (_docx_bytes_to_pdf_bytes_with_docx2pdf(docx_bytes)\n",
    "            or _docx_bytes_to_pdf_bytes_with_lo(docx_bytes))\n",
    "\n",
    "def document_to_docx_bytes(doc: Document) -> bytes:\n",
    "    buf = io.BytesIO()\n",
    "    doc.save(buf)\n",
    "    return buf.getvalue()\n",
    "\n",
    "doc = insert_biz_overview(gpt_output=biz_output)\n",
    "\n",
    "doc = insert_stakeholders(stakeholders_output, doc=doc)\n",
    "\n",
    "doc = insert_finance(finance_output, doc=doc)\n",
    "\n",
    "# doc = insert_capital_structure(cap_output, doc=doc)\n",
    "\n",
    "# doc2 = docx_bytes_to_pdf_bytes(doc)\n",
    "\n",
    "# docx_bytes = document_to_docx_bytes(doc)\n",
    "\n",
    "# pdf_bytes = docx_bytes_to_pdf_bytes(docx_bytes)\n",
    "\n",
    "\n",
    "doc.save(\"report.docx\")\n",
    "\n",
    "def save_docx_to_pdf_via_libreoffice(doc, pdf_path: str):\n",
    "    tmpdir = tempfile.mkdtemp()\n",
    "    docx_path = os.path.join(tmpdir, \"report.docx\")\n",
    "    doc.save(docx_path)\n",
    "\n",
    "    outdir = str(Path(pdf_path).parent)\n",
    "    os.makedirs(outdir, exist_ok=True)\n",
    "\n",
    "    # Convert using LibreOffice in headless mode\n",
    "    cmd = [\n",
    "        \"soffice\", \"--headless\", \"--nologo\",\n",
    "        \"--convert-to\", \"pdf:writer_pdf_Export\",\n",
    "        \"--outdir\", outdir, docx_path\n",
    "    ]\n",
    "    res = subprocess.run(cmd, capture_output=True, text=True, timeout=120)\n",
    "\n",
    "    produced = os.path.join(outdir, \"report.pdf\")\n",
    "    if res.returncode != 0 or not os.path.exists(produced):\n",
    "        raise RuntimeError(f\"LibreOffice failed:\\nSTDOUT:\\n{res.stdout}\\nSTDERR:\\n{res.stderr}\")\n",
    "\n",
    "    shutil.move(produced, pdf_path)\n",
    "    shutil.rmtree(tmpdir, ignore_errors=True)\n",
    "\n",
    "save_docx_to_pdf_via_libreoffice(doc, \"report.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7df938f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k is not a known attribute of class <class 'azure.search.documents._generated.models._models_py3.VectorizableTextQuery'> and will be ignored\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 19\u001b[0m\n\u001b[1;32m      7\u001b[0m calc \u001b[38;5;241m=\u001b[39m finance_calculations\n\u001b[1;32m      9\u001b[0m agent \u001b[38;5;241m=\u001b[39m profileAgent(\n\u001b[1;32m     10\u001b[0m     company_name \u001b[38;5;241m=\u001b[39m company,\n\u001b[1;32m     11\u001b[0m     k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     finance_calculations\u001b[38;5;241m=\u001b[39m calc\n\u001b[1;32m     17\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m pdf \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_company_profile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[88], line 361\u001b[0m, in \u001b[0;36mprofileAgent.generate_company_profile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_company_profile\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    358\u001b[0m \n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# =========== GENERATE BUSINESS OVERVIEW\u001b[39;00m\n\u001b[1;32m    360\u001b[0m     biz_overview_pairs_flat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(biz_overview_pairs[\u001b[38;5;241m1\u001b[39m], biz_overview_pairs[\u001b[38;5;241m0\u001b[39m]))  \u001b[38;5;66;03m# [(r, q), (r, q), ...]\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     section1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpairs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbiz_overview_pairs_flat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_answer(question\u001b[38;5;241m=\u001b[39mbusiness_overview_formatting, ctx_text\u001b[38;5;241m=\u001b[39msection1)\n\u001b[1;32m    363\u001b[0m     doc \u001b[38;5;241m=\u001b[39m insert_biz_overview(resp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Cell \u001b[0;32mIn[88], line 313\u001b[0m, in \u001b[0;36mprofileAgent._sections\u001b[0;34m(self, pairs)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;66;03m# small incremental delay before re-trying\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(base_delay_seconds \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m tries)\n\u001b[0;32m--> 313\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rag_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrag_nl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m answer_text \u001b[38;5;241m=\u001b[39m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# stop if good answer OR we've exhausted retries\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[88], line 242\u001b[0m, in \u001b[0;36mprofileAgent._rag_answer\u001b[0;34m(self, rag_nl, question, k, temperature)\u001b[0m\n\u001b[1;32m    235\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    236\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: system_msg},\n\u001b[1;32m    237\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: user_msg},\n\u001b[1;32m    238\u001b[0m ]\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# Try streaming first (SSE). Some networks/proxies block streaming; if so, fall back.\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAOAI_DEPLOYMENT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhigh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    246\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m answer \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    248\u001b[0m mode_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-streaming (fallback)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/openai/_utils/_utils.py:286\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/openai/resources/chat/completions/completions.py:1147\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m   1145\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m-> 1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1156\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1157\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_cache_key\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msafety_identifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1177\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1178\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1181\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mverbosity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1185\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1186\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/openai/_base_client.py:1259\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1245\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1246\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1247\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1255\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1256\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1257\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1258\u001b[0m     )\n\u001b[0;32m-> 1259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/openai/_base_client.py:982\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 982\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    988\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1226\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1224\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1225\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1226\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ssl.py:1101\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1101\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from prompts4 import section7, finance_calculations, system_mod\n",
    "import time\n",
    "import re, time\n",
    "\n",
    "company = 'SEAPORT_TOPCO_LIMITED'\n",
    "sys = system_mod\n",
    "calc = finance_calculations\n",
    "\n",
    "agent = profileAgent(\n",
    "    company_name = company,\n",
    "    k=50, \n",
    "    max_text_recall_size=35, \n",
    "    max_chars=10000,\n",
    "    model='gpt-5', \n",
    "    profile_prompt= sys, \n",
    "    finance_calculations= calc\n",
    ")\n",
    "\n",
    "pdf = agent.generate_company_profile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf9063b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in ./.venv/lib/python3.9/site-packages (0.6.7)\n",
      "Requirement already satisfied: langchain-core>=0.1 in ./.venv/lib/python3.9/site-packages (from langgraph) (0.3.75)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in ./.venv/lib/python3.9/site-packages (from langgraph) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in ./.venv/lib/python3.9/site-packages (from langgraph) (0.6.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in ./.venv/lib/python3.9/site-packages (from langgraph) (0.2.9)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in ./.venv/lib/python3.9/site-packages (from langgraph) (2.11.7)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in ./.venv/lib/python3.9/site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in ./.venv/lib/python3.9/site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in ./.venv/lib/python3.9/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in ./.venv/lib/python3.9/site-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.9/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.9/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.9/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.9/site-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in ./.venv/lib/python3.9/site-packages (from langchain-core>=0.1->langgraph) (0.4.23)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.9/site-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.9/site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.9/site-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.9/site-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in ./.venv/lib/python3.9/site-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in ./.venv/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./.venv/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in ./.venv/lib/python3.9/site-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.9/site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.9/site-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.9/site-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.26.20)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.9/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.9/site-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a213c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k is not a known attribute of class <class 'azure.search.documents._generated.models._models_py3.VectorizableTextQuery'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"FIND THE VARIABLES 'Net cash from operating activities' and 'Net cash used in investing activities' in the statement of cash flows. FILES FROM 2024.\"]\n",
      "['CFADS (calc. Net cash from operating activities + Net cash used in investing activities). Show me the formula with values and final result.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "k is not a known attribute of class <class 'azure.search.documents._generated.models._models_py3.VectorizableTextQuery'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"FIND THE VARIABLES 'Revenue'/'Turnover'/'Turn Over' in the Income statement. FILES FROM 2024.\"]\n",
      "['Revenue/Turnover/Turn over (Use Income Statement  Always Given)']\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "() Could not complete vectorization action. The vectorization endpoint returned status code '429' (TooManyRequests).\nCode: \nMessage: Could not complete vectorization action. The vectorization endpoint returned status code '429' (TooManyRequests).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(r)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(q)\n\u001b[0;32m---> 49\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rag_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrag_nl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mr\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m answer_text \u001b[38;5;241m=\u001b[39m resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# answer_text = 'oi'\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# stop if good answer OR we've exhausted retries\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# if not has_na(answer_text) or tries >= max_extra_na_retries:\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#     answers.append(answer_text)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#     break\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[88], line 220\u001b[0m, in \u001b[0;36mprofileAgent._rag_answer\u001b[0;34m(self, rag_nl, question, k, temperature)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_rag_answer\u001b[39m(\u001b[38;5;28mself\u001b[39m, rag_nl, question, k: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, temperature: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m):\n\u001b[1;32m    217\u001b[0m \n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# question = f'CREATE A SECTION OF COMPANY PROFILE USING LAST YEARS OF ANNUAL REPORT PRESENT IN THE CONTEXT FOR {self.company_name}. IF ANY INFORMATION IS NOT FOUND STATE AS n.a. .\\n\\n THIS IS THE SECTION TO BE BUILT: \\n {section7}  \\n USE THIS TO GUIDE YOURSELF ON SEMANTIC TERMS AND HOW TO CALCULATE: \\n {finance_calculations}'\u001b[39;00m\n\u001b[0;32m--> 220\u001b[0m     mode, hits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve_hybrid_enhanced\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# query=rag_q, \u001b[39;49;00m\n\u001b[1;32m    222\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_nl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrag_nl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     ctx_text, ctx_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_context(hits)\n\u001b[1;32m    227\u001b[0m     system_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprofile_prompt \u001b[38;5;241m+\u001b[39m (\n\u001b[1;32m    228\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mWhen you use a fact from the context, add citations like [#1], [#2].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOnly rely on the numbered context; if a value is missing, say \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn.a.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIF ANY INFORMATION IS NOT FOUND STATE AS n.a. .\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m USE THIS TO GUIDE YOURSELF ON SEMANTIC TERMS AND HOW TO CALCULATE: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfinance_calculations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[88], line 142\u001b[0m, in \u001b[0;36mprofileAgent._retrieve_hybrid_enhanced\u001b[0;34m(self, query_nl, k, top_n, fields, max_text_recall_size)\u001b[0m\n\u001b[1;32m    139\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlexical (fallback due to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m hits: List[Dict] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m    143\u001b[0m     d \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(r, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m {k2: r[k2] \u001b[38;5;28;01mfor\u001b[39;00m k2 \u001b[38;5;129;01min\u001b[39;00m r}\n\u001b[1;32m    144\u001b[0m     d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@search.reranker_score\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m d\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m@search.score\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/azure/search/documents/_paging.py:58\u001b[0m, in \u001b[0;36mSearchItemPaged.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m     first_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_iterator_instance()\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_page_iterator \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(first_iterator)\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_page_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/azure/core/paging.py:82\u001b[0m, in \u001b[0;36mPageIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnd of paging\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_next\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontinuation_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m AzureError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error\u001b[38;5;241m.\u001b[39mcontinuation_token:\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/azure/search/documents/_paging.py:139\u001b[0m, in \u001b[0;36mSearchPageIterator._get_next_cb\u001b[0;34m(self, continuation_token)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_next_cb\u001b[39m(\u001b[38;5;28mself\u001b[39m, continuation_token):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m continuation_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43msearch_request\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initial_query\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     _next_link, next_page_request \u001b[38;5;241m=\u001b[39m unpack_continuation_token(continuation_token)\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mdocuments\u001b[38;5;241m.\u001b[39msearch_post(search_request\u001b[38;5;241m=\u001b[39mnext_page_request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/azure/core/tracing/decorator.py:119\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/Documents/GitHub/Azure-OnePager/.venv/lib/python3.9/site-packages/azure/search/documents/_generated/operations/_documents_operations.py:823\u001b[0m, in \u001b[0;36mDocumentsOperations.search_post\u001b[0;34m(self, search_request, x_ms_query_source_authorization, request_options, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[1;32m    822\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mErrorResponse, pipeline_response)\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror)\n\u001b[1;32m    825\u001b[0m deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearchDocumentsResult\u001b[39m\u001b[38;5;124m\"\u001b[39m, pipeline_response\u001b[38;5;241m.\u001b[39mhttp_response)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m:\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: () Could not complete vectorization action. The vectorization endpoint returned status code '429' (TooManyRequests).\nCode: \nMessage: Could not complete vectorization action. The vectorization endpoint returned status code '429' (TooManyRequests)."
     ]
    }
   ],
   "source": [
    "from prompts4 import section7, finance_calculations, system_mod\n",
    "import time\n",
    "import re, time\n",
    "\n",
    "\n",
    "company = 'SEAPORT_TOPCO_LIMITED'\n",
    "sys = system_mod\n",
    "calc = finance_calculations\n",
    "\n",
    "agent = profileAgent(\n",
    "    company_name = company,\n",
    "    k=25, \n",
    "    max_text_recall_size=35, \n",
    "    max_chars=10000,\n",
    "    model='gpt-5', \n",
    "    profile_prompt= sys, \n",
    "    finance_calculations= calc\n",
    ")\n",
    "\n",
    "# rag_q = \"FIND THE VARIABLES 'Net cash from operating activities' and 'Net cash used in investing activities' in the statement of cash flows. FILES FROM 2024.\"\n",
    "# q = 'CFADS (calc. Net cash from operating activities + Net cash used in investing activities). Show me the formula with values and final result.'\n",
    "\n",
    "\n",
    "def has_na(text: str) -> bool:\n",
    "    # match \"n.a.\" or \"n/a\" (case-insensitive)\n",
    "    return bool(re.search(r\"\\b(n\\.a\\.|n/a)\\b\", text, flags=re.I))\n",
    "\n",
    "answers = []\n",
    "\n",
    "max_extra_na_retries = 1        # try again at most 2 times (total <= 3 calls per item)\n",
    "base_delay_seconds = 3.0        # polite delay between attempts\n",
    "\n",
    "biz_overview_pairs_flat = list(zip(biz_overview_pairs[1], biz_overview_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "stakeholders_pairs_flat = list(zip(stakeholders_pairs[1], stakeholders_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "capital_pairs_flat = list(zip(capital_pairs[1], capital_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "finance_pairs_flat = list(zip(finance_pairs[1], finance_pairs[0]))  # [(r, q), (r, q), ...]capital_pairs\n",
    "\n",
    "# finance_pairs_flat = list(zip(finance_pairs[1], finance_pairs[0]))  # [(r, q), (r, q), ...]\n",
    "        \n",
    "for q, r in finance_pairs_flat:\n",
    "    tries = 0\n",
    "    while True:\n",
    "        if tries > 0:\n",
    "            # small incremental delay before re-trying\n",
    "            time.sleep(base_delay_seconds + 0.5 * tries)\n",
    "        \n",
    "        print(r)\n",
    "        print(q)\n",
    "        resp = agent._rag_answer(rag_nl=r[0], question=q[0])\n",
    "        answer_text = resp[\"answer\"]\n",
    "        # answer_text = 'oi'\n",
    "\n",
    "        # stop if good answer OR we've exhausted retries\n",
    "        # if not has_na(answer_text) or tries >= max_extra_na_retries:\n",
    "        #     answers.append(answer_text)\n",
    "        #     break\n",
    "        if answer_text:\n",
    "            answers.append(answer_text)\n",
    "            break\n",
    "\n",
    "        # otherwise, try again\n",
    "        tries += 1\n",
    "\n",
    "    # optional small gap between different (r,q) items\n",
    "    time.sleep(5.0)\n",
    "\n",
    "# 11m 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5b152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_processing(prompt):#####new\n",
    "    from io import BytesIO\n",
    "    from typing import Tuple, Annotated, TypedDict\n",
    "    import time\n",
    "    import streamlit as st\n",
    "    import sys, pathlib\n",
    " \n",
    "    # Ensure repo root is importable\n",
    "    repo_root = pathlib.Path(__file__).resolve().parent.parent\n",
    "    if str(repo_root) not in sys.path:\n",
    "        sys.path.insert(0, str(repo_root))\n",
    " \n",
    "    # Engine\n",
    "    from engines.engine import HybridEngine\n",
    " \n",
    "    # LangGraph\n",
    "    from langgraph.graph import StateGraph, START, END\n",
    "    from langgraph.graph.message import add_messages\n",
    "    from langgraph.prebuilt import ToolNode, tools_condition\n",
    "    from langgraph.checkpoint.memory import MemorySaver\n",
    " \n",
    "    # LangChain\n",
    "    from langchain_core.tools import tool\n",
    "    from langchain_openai import ChatOpenAI\n",
    " \n",
    "    # Cache builder\n",
    "    # @st.cache_resource(show_spinner=False)  # disable while debugging\n",
    "    def ocr_engine_cached_multi(files_bytes: Tuple[bytes, ...], files_names: Tuple[str, ...]):\n",
    "        pdf_streams = tuple((BytesIO(b), n) for b, n in zip(files_bytes, files_names))\n",
    "        engine = HybridEngine(pdf_streams)\n",
    "        t0 = time.perf_counter(); engine.main(); build_s = time.perf_counter() - t0\n",
    "        timings = getattr(engine, \"timings\", {})\n",
    "        timings[\"total_build_s\"] = build_s\n",
    "        return engine, timings\n",
    " \n",
    "    # LangGraph builder\n",
    "    memory = MemorySaver()\n",
    "    class State(TypedDict):\n",
    "        messages: Annotated[list, add_messages]\n",
    " \n",
    "    def build_graph(engine: HybridEngine):\n",
    "        @tool\n",
    "        def pdf_search(query: str) -> str:\n",
    "            \"\"\"Retrieve top snippets from the indexed PDFs for a query.\"\"\"\n",
    "            docs = engine.hybrid.get_relevant_documents(query)\n",
    "            if not docs:\n",
    "                return \"NO_MATCH\"\n",
    "            return \"\\n---\\n\".join([d.page_content[:500] for d in docs[:3]])\n",
    "       \n",
    "        @tool\n",
    "        def web_search(query: str) -> str:\n",
    "            \"\"\"Use OpenAI Responses' built-in web_search to fetch up to 3 results.\n",
    "            Format:\n",
    "            [web] <title>  <one-line snippet> <url>\n",
    "            If nothing found or on error, return WEB_NO_RESULTS.\n",
    "            \"\"\"\n",
    "            print(f\"[DEBUG] web_search called with query: {query}\")\n",
    "            try:\n",
    "                client = OpenAI()\n",
    "                resp = client.responses.create(\n",
    "                    model=\"gpt-5\",\n",
    "                    tools=[{\"type\": \"web_search\"}],\n",
    "                    input=(\n",
    "                        f\"Search the web for: {query}\\n\"\n",
    "                        \"Return up to 3 bullets, each exactly as:\\n\"\n",
    "                        \"[web] <title>  <one-line snippet> <url>\\n\"\n",
    "                        \"If nothing is found, return exactly: WEB_NO_RESULTS\"\n",
    "                    ),\n",
    "                )\n",
    "                text = (getattr(resp, \"output_text\", \"\") or \"\").strip()\n",
    "                print(\"[DEBUG] responses output_text len:\", len(text))\n",
    "                if not text:\n",
    "                    return \"WEB_NO_RESULTS\"\n",
    "                bullets = [ln.strip() for ln in text.split(\"\\n\") if ln.strip().startswith(\"[web] \")][:3]\n",
    "                if not bullets:\n",
    "                    return \"WEB_NO_RESULTS\"\n",
    "                print(f\"[DEBUG] web_search returning {len(bullets)} results\")\n",
    "                return \"\\n---\\n\".join(bullets)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] web_search failed: {e}\")\n",
    "                return \"WEB_NO_RESULTS\"\n",
    " \n",
    "        # If you already built a real calc tool elsewhere, import and wrap it here.\n",
    "        # Example: engines/calc_tool.py defines def calc_script(data: str) -> str: ...\n",
    "        try:\n",
    "            from engines.calc_tool import calc_script as _calc_impl  # <-- adjust path if different\n",
    "            @tool\n",
    "            def calc_script(data: str) -> str:\n",
    "                \"\"\"Financial calculations tool.\"\"\"\n",
    "                return _calc_impl(data)\n",
    "        except Exception:\n",
    "            @tool\n",
    "            def calc_script(data: str) -> str:\n",
    "                \"\"\"Financial calculations tool (placeholder if module not found).\"\"\"\n",
    "                print(f\"[DEBUG] calc_script called with data: {data}\")\n",
    "                return \"CALC_NOT_IMPLEMENTED\"\n",
    " \n",
    "        tools = [pdf_search, web_search, calc_script]\n",
    "        llm = ChatOpenAI(model=\"gpt-5\")\n",
    "        llm_with_tools = llm.bind_tools(tools)\n",
    " \n",
    "        def chatbot(state: State) -> State:\n",
    "            ai_msg = llm_with_tools.invoke(state[\"messages\"])\n",
    "            return {\"messages\": [ai_msg]}\n",
    " \n",
    "        builder = StateGraph(State)\n",
    "        builder.add_node(\"chatbot\", chatbot)\n",
    "        builder.add_node(\"tools\", ToolNode(tools))\n",
    "        builder.add_edge(START, \"chatbot\")\n",
    "        builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "        builder.add_edge(\"tools\", \"chatbot\")\n",
    "        builder.add_edge(\"chatbot\", END)\n",
    "        return builder.compile(checkpointer=memory)\n",
    " \n",
    "    def main():\n",
    "        st.set_page_config(page_title=\"Oraculum\")\n",
    "        st.title(\"Oraculum\")\n",
    "        st.write(\" App booted\")  # prove we rendered\n",
    " \n",
    "        # Safe init\n",
    "        defaults = {\n",
    "            \"ocr_mode\": False,\n",
    "            \"text_engine\": False,\n",
    "            \"processed\": False,\n",
    "            \"ocr_engine\": None,\n",
    "            \"graph\": None,\n",
    "            \"ocr_timings\": {},\n",
    "        }\n",
    "        for k, v in defaults.items():\n",
    "            if k not in st.session_state:\n",
    "                st.session_state[k] = v\n",
    " \n",
    "        pdf_files = st.file_uploader(\"Upload your PDF(s)\", type=[\"pdf\"], accept_multiple_files=True)\n",
    "        col1, col2 = st.columns(2)\n",
    "        if col1.button(\"OCR Engine\"):\n",
    "            st.session_state.update({\"ocr_mode\": True, \"text_engine\": False, \"processed\": False})\n",
    " \n",
    "        # --- OCR Engine (multi-file) ---\n",
    "        if st.session_state.get(\"ocr_mode\", False) and pdf_files:\n",
    "            files_bytes: Tuple[bytes, ...] = tuple(f.getvalue() for f in pdf_files)\n",
    "            files_names: Tuple[str, ...] = tuple(f.name for f in pdf_files)\n",
    " \n",
    "            if not st.session_state.get(\"processed\", False):\n",
    "                with st.spinner(\"Building OCR (hybrid) index across all PDFs...\"):\n",
    "                    try:\n",
    "                        engine, timings = ocr_engine_cached_multi(files_bytes, files_names)\n",
    "                        st.session_state.ocr_engine = engine\n",
    "                        st.session_state.ocr_timings = timings\n",
    "                        st.session_state.graph = build_graph(engine)\n",
    "                        if \"thread_id\" not in st.session_state or not st.session_state.thread_id:\n",
    "                            import time\n",
    "                            st.session_state.thread_id = f\"ui-{int(time.time())}\"\n",
    "                        st.success(\"OCR index ready.\")\n",
    "                        st.session_state.processed = True\n",
    "                    except Exception as e:\n",
    "                        st.error(\"Build failed\")\n",
    "                        st.exception(e)\n",
    "                        return\n",
    " \n",
    "            st.subheader(\"Timings\")\n",
    "            st.json(st.session_state.get(\"ocr_timings\", {}))\n",
    " \n",
    "            question = st.text_input(\"Ask a question about your PDFs:\")\n",
    "            if question:\n",
    "                state = {\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a financial assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": question},\n",
    "                    ]\n",
    "                }\n",
    "                out = st.session_state.graph.invoke(\n",
    "                    state,\n",
    "                    {\"configurable\": {\"thread_id\": st.session_state.thread_id}}\n",
    "                    )\n",
    "                st.write(out[\"messages\"][-1].content)\n",
    "    main()######new\n",
    "# Streamlit runs the script top-level, but keeping this is fine\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running test...\")\n",
    "    pdf_processing(\"test prompt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "061298c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.blob_functions import get_companies\n",
    "\n",
    "name_map , names = get_companies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "13ffc761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.storage.blob import BlobClient, ContentSettings\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os \n",
    "import requests\n",
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# === CONFIG ===\n",
    "ACCOUNT_URL   = os.getenv(\"BLOB_ACCOUNT_URL\")\n",
    "AZURE_STORAGE_CONNECTION_STRING=os.getenv(\"BLOB_AZURE_STORAGE_CONNECTION_STRING\")\n",
    "# BLOB_NAME     = \"companieslist/CompaniesHouseList.xlsx\"   # e.g., \"reports/myfile.xlsx\"\n",
    "UK_API_KEY = os.getenv(\"UK_API_KEY\")\n",
    "\n",
    "INVALID_CHARS = '<>:\"/\\\\|?*'\n",
    "def sanitize(s: str) -> str:\n",
    "    s = s.replace(\" \", \"_\")\n",
    "    for ch in INVALID_CHARS:\n",
    "        s = s.replace(ch, \"_\")\n",
    "    return s\n",
    "\n",
    "def companyHouseListAdd(\n",
    "    CONTAINER='companieslist',\n",
    "    BLOB_NAME='CompaniesHouseList.xlsx',\n",
    "    CompanyNumber=None,\n",
    "    sheet_name='IDs'   # change if your sheet is named differently\n",
    "):\n",
    "    if CompanyNumber is None:\n",
    "        raise ValueError(\"CompanyNumber is required\")\n",
    "\n",
    "    # 1) Download the Excel\n",
    "    excel_bytes = get_file_blob(CONTAINER, BLOB_NAME)\n",
    "\n",
    "    # Try reading the sheet; if file/sheet doesn't exist, start a blank DF\n",
    "    try:\n",
    "        df = pd.read_excel(BytesIO(excel_bytes), sheet_name=sheet_name, dtype={'IDS': str, 'NAMES': str})\n",
    "    except Exception:\n",
    "        df = pd.DataFrame(columns=['IDS', 'NAMES'])\n",
    "\n",
    "    # Ensure required columns exist\n",
    "    for col in ('IDS', 'NAMES'):\n",
    "        if col not in df.columns:\n",
    "            df[col] = \"\"\n",
    "\n",
    "    # 2) Get the company display name (human-friendly; don't sanitize for Excel)\n",
    "    url = f\"https://api.company-information.service.gov.uk/company/{CompanyNumber}\"\n",
    "    r = requests.get(url, auth=HTTPBasicAuth(UK_API_KEY, \"\"))\n",
    "    r.raise_for_status()\n",
    "    name = r.json().get(\"company_name\", \"\")\n",
    "    name = sanitize(name)\n",
    "\n",
    "    # 3) Upsert: if ID exists, update its name; else append new row\n",
    "    CompanyNumber = str(CompanyNumber)\n",
    "    mask = (df['IDS'].astype(str) == CompanyNumber)\n",
    "    if mask.any():\n",
    "        df.loc[mask, 'NAMES'] = name\n",
    "    else:\n",
    "        df = pd.concat(\n",
    "            [df, pd.DataFrame({'IDS': [CompanyNumber], 'NAMES': [name]})],\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "    # Optional: dedupe on IDs keeping the last occurrence\n",
    "    df = df.drop_duplicates(subset=['IDS'], keep='last')\n",
    "\n",
    "    # 4) Write back to Excel in-memory\n",
    "    buf = BytesIO()\n",
    "    with pd.ExcelWriter(buf, engine=\"openpyxl\") as xw:\n",
    "        df.to_excel(xw, index=False, sheet_name=sheet_name)\n",
    "    buf.seek(0)\n",
    "\n",
    "    return buf.getvalue()\n",
    "\n",
    "\n",
    "excel_bytes = companyHouseListAdd(CompanyNumber=\"07584487\")\n",
    "\n",
    "save_to = '/Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompaniesHouseListTest.xlsx'\n",
    "with open(save_to, \"wb\") as f:\n",
    "    f.write(excel_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30c498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JAMES_DONALDSON_GROUP_LTD'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.blob_functions import get_companies\n",
    "import difflib\n",
    "\n",
    "\n",
    "def pick_company(user_text):\n",
    "\n",
    "    name_map, names = get_companies()\n",
    "    unique_names = list(dict.fromkeys(names))      # de-dupe while keeping order\n",
    "    reverse_map = {v: k for k, v in name_map.items()}  # clean -> orig\n",
    "    # normalize user input a bit\n",
    "    cleaned = user_text.strip().upper()\n",
    "    \n",
    "    # try fuzzy match against the official list\n",
    "    matches = difflib.get_close_matches(\n",
    "        cleaned,\n",
    "        names,\n",
    "        n=1,          # only want the single best\n",
    "        cutoff=0.6    # 0.01.0; raise this if you want to be stricter\n",
    "    )\n",
    "\n",
    "    if matches:\n",
    "        return reverse_map.get(matches[0], matches[0])  # this is the canonical company name\n",
    "    return None\n",
    "\n",
    "teste = pick_company(' james donaldson')\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74b33a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Seaport Topco Limiteds principal activity continues to include the research and development of pharmaceutical instrumentation. [1][2]\n",
      "- The company is engaged in group-level operations focused on developing pharmaceutical instrumentation through ongoing research and development initiatives. [1][2]\n",
      "- It offers research and development of pharmaceutical instrumentation as its primary product and service offering. [1][2]\n",
      "- The company reported a headcount of 418 at Dec-24, up from 405, indicating ongoing operations across the group. [9]\n",
      "- The company faces near-term liquidity and working capital pressure, with creditors due within one year rising to 64.7m at Dec-24 driven by 7.7m of new loans and a 9.2m net revolving credit facility draw, while cash generated from operating activities declined to 10.4m from 15.3m in FY23. [9]\n",
      "- It carries substantial longer-term obligations, with creditors due after more than one year at 168.7m at Dec-23, alongside rising trade debtors to 17.0m and reduced stock to 13.2m at Dec-24, indicating cash conversion and balance sheet pressures. [7][8][9]\n",
      "\n",
      "Sources:\n",
      "- [1][2] Annual Report (FY23), Strategic/Directors Report, p.5  Principal activity.\n",
      "- [9] Annual Report (FY24), Group Strategic Report (pp.15; exact page n.a.)  Review of the business and future developments, working capital and liquidity movements.\n",
      "- [7][8] Annual Report (FY23), Notes 2122, Consolidated Statement of Financial Position, p.14  Creditors due within one year and after more than one year.\n"
     ]
    }
   ],
   "source": [
    "business_overview_formatting = \"\"\"\n",
    " - This section provides a high-level overview on what the company does, its operations, locations, products, customers and any ongoing debt/financial issues, in a bullet point format consisting of 5-6 bullet points with sentences, using the latest available annual reports/financial statements of the company \n",
    "-- Include 1-2 bullet point sentences on what the company does \n",
    "-- Include 1 bullet point on the products/services the company offers \n",
    "-- Include 1 bullet point on where the company has its operations (e.g. manufacturing facilities, operating plants, offices, customers) \n",
    "-- Include 1 bullet point on who are the customers of the company  \n",
    "-- Include 1 bullet point on stress triggers of the company (e.g., 40% revenue from top 1 customer; high fixed costs; collateral shortfall; aggressive capex; covenant breach; dropping profitability; mass lay-offs etc.) \n",
    "\n",
    "- Each bullet must begin with the company name, \"The company\", or It. Make sure each bullet point is a proper sentence, which do not contain any sub-headings, colon or semi-colons \n",
    "\n",
    "- Sources to be used for this section:  \n",
    "-- The bullet points regarding what the company does, its products/services, operations, customers can be sourced from the Primary Activity, Business Review, Introduction or Strategic Report section of the report \n",
    "-- The bullet point regarding companys stress triggers can be sourced from the Business Review or Ongoing Concern or Bank Debt/Borrowings/Creditors section of the report \n",
    "-- If any of the above source suggestions does not return results for any part, please scan and check other sections of the reports to see if relevant information can be found \n",
    " \n",
    "- Notes for this section: \n",
    "-- If information for any of the bullet point is not available in the report, do not include that specific bullet point as incorrect information is strictly prohibited \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "resp = agent._answer(question=business_overview_formatting, ctx_text=answers)\n",
    "print(resp['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec4db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric,FY24,FY23,FY22\n",
      "\"Revenue (Turnover)\",\"76.8m [#2]\",\"81.4m [#2]\",\"32.8m [#2]\"\n",
      "\"Revenue growth % (yoy)\",\"-5.7% [#5]\",\"+148.1% [#5]\",\"n.a.\"\n",
      "\"Gross profit\",\"43.9m [#3]\",\"48.4m [#3]\",\"14.3m [#3]\"\n",
      "\"Gross margin %\",\"57.2% [#6]\",\"59.5% [#6]\",\"43.7% [#6]\"\n",
      "\"EBITDA\",\"10.7m [#4]\",\"20.2m [#4]\",\"-1.2m [#4]\"\n",
      "\"EBITDA margin %\",\"14.0% [#7]\",\"24.9% [#7]\",\"n.m. [#4][#2]\"\n",
      "\"Net cash from operating activities\",\"9.6m [#8]\",\"15.3m [#8]\",\"-1.8m [#8]\"\n",
      "\"Net working capital (movement)\",\"-1.2m [#9]\",\"3.9m [#9]\",\"-3.0m [#9]\"\n",
      "\"CFO excl. Net working capital\",\"10.8m [#8]\",\"11.4m [#8]\",\"1.2m [#8]\"\n",
      "\"Capex (tangible + intangible)\",\"2.9m [#10]\",\"7.2m [#10]\",\"0.9m [#10]\"\n",
      "\"Other cash flow from investing activities\",\"0.2m [#11]\",\"-0.8m [#11]\",\"-638.1m [#11]\"\n",
      "\"CFADS (CFO + CFI)\",\"6.9m [#1]\",\"7.3m [#8][#11]\",\"-640.8m [#8][#11]\"\n",
      "\"Financing cash flow  Issue of shares\",\"1.5m [#12]\",\"0.4m [#12]\",\"484.2m [#12]\"\n",
      "\"Financing cash flow  Draw down of bank loans\",\"17.9m [#12]\",\"12.1m [#12]\",\"187.3m [#12]\"\n",
      "\"Financing cash flow  Draw down of other loans\",\"7.7m [#12]\",\"n.a.\",\"n.a.\"\n",
      "\"Financing cash flow  Repayment of bank loans\",\"-8.6m [#12]\",\"n.a.\",\"n.a.\"\n",
      "\"Financing cash flow  Interest paid\",\"-25.2m [#12]\",\"-16.6m [#12]\",\"-4.9m [#12]\"\n",
      "\"Net cash from financing activities\",\"-6.7m [#12]\",\"-4.2m [#12]\",\"657.6m [#12]\"\n",
      "\"Opening cash\",\"11.8m [#13]\",\"9.0m [#13]\",\"0.0m [#13]\"\n",
      "\"Change in cash\",\"0.2m [#14]\",\"3.2m [#14]\",\"16.9m [#14]\"\n",
      "\"Closing cash\",\"11.8m [#15]\",\"11.8m [#15]\",\"9.0m [#15]\"\n",
      "\"Total external debt\",\"198.4m [#16]\",\"183.4m [#16]\",\"174.5m [#17]\"\n",
      "\"Net external debt\",\"186.6m [#17]\",\"171.6m [#17]\",\"165.5m [#17]\"\n",
      "\"Leverage (Net debt / EBITDA)\",\"17.4x [#17][#4]\",\"8.5x [#17][#4]\",\"n.m. [#17][#4]\"\n",
      "\n",
      "Summary / Interpretation\n",
      "- Revenue fell -5.7% in FY24 to 76.8m after a +148.1% surge in FY23; gross margin compressed from 59.5% to 57.2% alongside lower gross profit.\n",
      "- EBITDA halved from 20.2m to 10.7m; EBITDA margin dropped from 24.9% to 14.0%. FY22 EBITDA was negative, making the margin n.m.\n",
      "- Net external debt increased from 171.6m to 186.6m; leverage rose materially from 8.5x to 17.4x as EBITDA declined.\n",
      "- CFADS remained positive in FY24 (6.9m) but slightly below FY23 (7.3m); FY22 CFADS was deeply negative (-640.8m), consistent with very large Other CFI (-638.1m).\n",
      "- Capex reduced sharply from 7.2m (FY23) to 2.9m (FY24); closing cash stayed broadly flat around 11.8m across FY24FY23.\n",
      "\n",
      "SECTION 3 - SOURCES\n",
      "- [#1] Seaport Topco Limited Annual Report FY24 (issued 29-Apr-25)  Consolidated Statement of Cash Flows (p.1718): CFADS (FY24), net cash from operating activities, net cash used in investing, financing activities breakdown and totals. Link as provided in context.\n",
      "- [#2] Seaport Topco Limited Annual Report FY23 (issued 25-Sep-24)  Turnover breakdown and FY22 comparison (p.54), Consolidated SOCI (p.13): revenue figures; also balance sheet creditors after more than one year used for debt comparatives. Link as provided in context.\n",
      "- [#3] Seaport Topco Limited Annual Report (file dated 2025-09-30 and 2024-09-25)  Consolidated Statement of Comprehensive Income (p.12/p.13): gross profit figures; narrative confirmation. Links as provided in context.\n",
      "- [#4] Seaport Topco Limited Annual Report (published Sep-25)  KPI section (p.6): EBITDA (FY24, FY23); prior KPI (published Sep-24, p.9) for FY22 EBITDA. Links as provided in context.\n",
      "- [#5] Seaport Topco Limited Annual Report  KPI/revenue growth commentary: FY24 (-5.7%) and FY23 (+148.1%) calculations and discussion (p.6, p.11). Links as provided in context.\n",
      "- [#6] Seaport Topco Limited Annual Reports FY24/FY23  Gross margin calculations and confirmations: FY24 (p.12; KPI p.6), FY23/FY22 (p.13); cross-check notes. Links as provided in context.\n",
      "- [#7] Seaport Topco Limited Annual Report  EBITDA margin (FY24, FY23) derived and disclosed in KPI context (p.6); FY22 margin treated n.m. per rule with EBITDA from [#4] and revenue from [#2]. Links as provided in context.\n",
      "- [#8] Seaport Topco Limited Annual Reports  Consolidated Cash Flow Statement: net cash from operating activities and working capital movements (FY24 p.17; FY23/FY22 p.18); CFO excl. NWC calculations per instruction. Links as provided in context.\n",
      "- [#9] Seaport Topco Limited Annual Reports  Net working capital movement details (debtors, stocks, creditors) and sums: FY24 p.17; FY23/FY22 p.18. Links as provided in context.\n",
      "- [#10] Seaport Topco Limited Annual Reports  Capex from investing activities (purchase of tangible and intangible assets): FY24 p.17; FY23/FY22 p.18. Links as provided in context.\n",
      "- [#11] Seaport Topco Limited Annual Reports  Other cash flow from investing activities and net CFI: FY24 p.17; FY23/FY22 p.18. Links as provided in context.\n",
      "- [#12] Seaport Topco Limited Annual Reports  Cash flows from financing activities breakdown: FY24 p.18; FY23/FY22 p.19. Links as provided in context.\n",
      "- [#13] Seaport Topco Limited Annual Reports  Opening cash (cash and cash equivalents at beginning of year): FY24 p.18; FY23/FY22 p.19. Links as provided in context.\n",
      "- [#14] Seaport Topco Limited Annual Reports  Net increase in cash and cash equivalents (change in cash): FY24 p.18; FY23/FY22 p.19. Links as provided in context.\n",
      "- [#15] Seaport Topco Limited Annual Reports  Closing cash (cash and cash equivalents at end of period): FY24 p.18; FY23 p.19; FY22 p.19. Links as provided in context.\n",
      "- [#16] Seaport Topco Limited Annual Report FY24  Note 30 Analysis of net debt: bank loans current/non-current, other loans current; total external debt calculation; Dec-23 comparatives also referenced. Links as provided in context.\n",
      "- [#17] Seaport Topco Limited Annual Reports FY24/FY23  Net debt calculations (Total debt less closing cash) and leverage derivations; FY22 bank loans (LT and ST) and cash used to compute total debt and net debt; EBITDA from [#4] used for leverage. Links as provided in context.\n"
     ]
    }
   ],
   "source": [
    "finance_formatting_2= \"\"\" \n",
    "Return TWO sections in this exact order:\n",
    "\n",
    "SECTION 1  TABLE\n",
    "- Output a valid Table with header: Metric,FY24,FY23,FY22\n",
    "- One data row per metric.\n",
    "- Use \"n.a.\" / \"n.m.\" exactly when unavailable.\n",
    "- Do NOT add any text before or after the Table in this section.\n",
    "\n",
    "SECTION 2  SUMMARY / INTERPRETATION\n",
    "- After the Table, add a single blank line, then a heading line: Summary / Interpretation\n",
    "- Provide 36 concise bullets explaining the key movements, relationships, and caveats.\n",
    "- Base all points strictly on the Table values; do not invent numbers.\n",
    "\n",
    "SECTION 3 - SOURCES\n",
    "- Point out all the sources used by the original input with the correct number index like [#6], and CITE THE COMPLETE SOURCE like which report it was used, etc.\n",
    "\n",
    "\n",
    "Formatting example (shape only; values are illustrative):\n",
    "\n",
    "Metric                  |   FY24                |   FY23            |   FY22\n",
    "Revenue (Turnover)      |   576.8m [#2]        |   81.4m [#6]     |   32.8m [#5]\n",
    "Revenue growth % (yoy)  |   +608.6% [#2][#6]    |   +148.0% [#5]    |   n.a.\n",
    "Gross profit            |   n.a.                |   48.4m [#3][#6] |   14.3m [#3]\"\n",
    "\n",
    "Summary / Interpretation\n",
    "- Brief point 1\n",
    "- Brief point 2\n",
    "- Brief point 3\n",
    "\"\"\"\n",
    "\n",
    "resp = agent._answer(question=finance_formatting_2, ctx_text=answers)\n",
    "print(resp['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f0a99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metric,Shareholders\\n\"Shareholders\",\"Immediate parent: EQT Jupiter Luxco S.A.R.L (Luxembourg); Ultimate parent: n.a.\"\\n\"Management\",\"Chairman: n.a.; CEO: n.a.; CFO: n.a.; Directors (FY24): M Bauer; R Diggelmann (resigned Dec-24); P Dowdy (resigned Feb-25); J Feldman; R Friel (resigned Mar-25); K Murphy; D Newble (resigned Jul-24); A Thorburn; R Walton (appointed Jul-24)\"\\n\"Lenders\",\"n.a.\"\\n\"Auditors\",\"n.a.\"\\n\"Advisors\",\"Facility agent: Kroll Agency Services Limited; Financial advisor: n.a.; Legal advisor: n.a.; Bankers: n.a.\"\\n\\nSummary / Interpretation\\n- Ownership is clearly identified at the immediate parent level (EQT Jupiter Luxco S.A.R.L), while the ultimate parent is n.a., indicating Seaport Topco Limited is the head of the consolidation group.\\n- Key executive roles (Chairman/CEO/CFO) are n.a., but a detailed FY24 directors list is provided, including multiple resignations and one appointment.\\n- Lender names are n.a., so external creditor identification is not available from the provided materials.\\n- Auditor firm name is n.a., limiting visibility into the audit provider.\\n- The only advisor disclosed is the facility agent (Kroll Agency Services Limited); other advisor roles are n.a.\\n\\nSECTION 3 - SOURCES\\n- [#1] Seaport Topco Limited  Annual Report and Financial Statements for the year ended 31-Dec-23, Note 32 Controlling party, p.52; and other references noted in context (e.g., bank loans/net debt analysis pages). Link: https://aiprojectteneo.blob.core.windows.net/companyseaport/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_1.pdf\\n- [#2] Seaport Topco Limited  Annual Report and Financial Statements (FY24) excerpts noted in context, including Directors Report p.12 and Independent Auditors Report pages referenced. Link: https://aiprojectteneo.blob.core.windows.net/companieshousesinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2025-09-30_0.pdf\\n- [#3] Seaport Topco Limited  Annual Report and Financial Statements for the year ended 31-Dec-24, Note 31 Controlling party confirming immediate parent; Link: https://aiprojectteneo.blob.core.windows.net/companyseaport/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2025-09-30_0.pdf\\n- [#4] Seaport Topco Limited  Annual Report and Financial Statements for the year ended 31-Dec-23, Independent Auditors Report (p.17). Link: https://aiprojectteneo.blob.core.windows.net/companyseaport/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_0.pdf\\n- [#6] Seaport Topco Limited  Annual Report and Financial Statements (FY24), Directors Report approval/signatory, p.16. Link: https://aiprojectteneo.blob.core.windows.net/companieshousesinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2025-09-30_0.pdf\\n- Advisors reference: Note 22 Loans (FY24) and Note 23 Loans (FY23) stating Kroll Agency Services Limited acting as the facility agent. FY24 (p.67) link same as [#2]/[#3]; FY23 links: https://aiprojectteneo.blob.core.windows.net/companyseaport/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_0.pdf and https://aiprojectteneo.blob.core.windows.net/companyseaport/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_1.pdf'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stakeholders_formatting = \"\"\" \n",
    "Return TWO sections in this exact order:\n",
    "\n",
    "SECTION 1  CSV TABLE\n",
    "- Output a valid CSV with header: Metric,Shareholders\n",
    "- One data row per metric.\n",
    "- Use \"n.a.\" / \"n.m.\" exactly when unavailable.\n",
    "- CSV rules:\n",
    "  * Separate fields with commas only (no extra spaces around commas).\n",
    "  * Wrap any field that contains commas, brackets, percent signs, currency symbols, or spaces in double quotes.\n",
    "  * Escape any internal double quotes by doubling them.\n",
    "- Do NOT wrap the CSV in code fences.\n",
    "- Do NOT add any text before or after the CSV in this section.\n",
    "\n",
    "SECTION 2  SUMMARY / INTERPRETATION\n",
    "- After the CSV, add a single blank line, then a heading line: Summary / Interpretation\n",
    "- Provide 36 concise bullets explaining the key movements, relationships, and caveats.\n",
    "- Base all points strictly on the CSV values; do not invent numbers.\n",
    "\n",
    "SECTION 3 - SOURCES\n",
    "- Point out all the sources used by the original input with the correct number index like [#6], and CITE THE COMPLETE SOURCE like which report it was used, etc.\n",
    "\n",
    "\n",
    "Formatting example (shape only; values are illustrative):\n",
    "\n",
    "Metric,Shareholders\n",
    "\"Shareholders\", \"Scott\"\n",
    "\"Management\",\"n.a.\"\n",
    "\"Lenders\",\"Maria\"\n",
    "\"Auditors\",\"James\"\n",
    "\"Advisors\",\"n.a.\"\n",
    "\n",
    "Summary / Interpretation\n",
    "- Brief point 1\n",
    "- Brief point 2\n",
    "- Brief point 3\n",
    "\"\"\"\n",
    "\n",
    "resp = agent._answer(question=stakeholders_formatting, ctx_text=answers)\n",
    "print(resp['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3312b534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric,Shareholders\n",
      "\"Shareholders\",\"Immediate parent: EQT Jupiter Luxco S.A.R.L (Luxembourg); Ultimate parent: n.a.\"\n",
      "\"Management\",\"Chairman: n.a.; CEO: n.a.; CFO: n.a.; Directors (FY24): M Bauer; R Diggelmann (resigned Dec-24); P Dowdy (resigned Feb-25); J Feldman; R Friel (resigned Mar-25); K Murphy; D Newble (resigned Jul-24); A Thorburn; R Walton (appointed Jul-24)\"\n",
      "\"Lenders\",\"n.a.\"\n",
      "\"Auditors\",\"n.a.\"\n",
      "\"Advisors\",\"Facility agent: Kroll Agency Services Limited; Financial advisor: n.a.; Legal advisor: n.a.; Bankers: n.a.\"\n",
      "\n",
      "Summary / Interpretation\n",
      "- Ownership is clearly identified at the immediate parent level (EQT Jupiter Luxco S.A.R.L), while the ultimate parent is n.a., indicating Seaport Topco Limited is the head of the consolidation group.\n",
      "- Key executive roles (Chairman/CEO/CFO) are n.a., but a detailed FY24 directors list is provided, including multiple resignations and one appointment.\n",
      "- Lender names are n.a., so external creditor identification is not available from the provided materials.\n",
      "- Auditor firm name is n.a., limiting visibility into the audit provider.\n",
      "- The only advisor disclosed is the facility agent (Kroll Agency Services Limited); other advisor roles are n.a.\n",
      "\n",
      "SECTION 3 - SOURCES\n",
      "- [#1] Seaport Topco Limited  Annual Report and Financial Statements for the year ended 31-Dec-23, Note 32 Controlling party, p.52; and other references noted in context (e.g., bank loans/net debt analysis pages). Link: https://aiprojectteneo.blob.core.windows.net/companyseaport/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_1.pdf\n",
      "- [#2] Seaport Topco Limited  Annual Report and Financial Statements (FY24) excerpts noted in context, including Directors Report p.12 and Independent Auditors Report pages referenced. Link: https://aiprojectteneo.blob.core.windows.net/companieshousesinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2025-09-30_0.pdf\n",
      "- [#3] Seaport Topco Limited  Annual Report and Financial Statements for the year ended 31-Dec-24, Note 31 Controlling party confirming immediate parent; Link: https://aiprojectteneo.blob.core.windows.net/companyseaport/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2025-09-30_0.pdf\n",
      "- [#4] Seaport Topco Limited  Annual Report and Financial Statements for the year ended 31-Dec-23, Independent Auditors Report (p.17). Link: https://aiprojectteneo.blob.core.windows.net/companyseaport/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_0.pdf\n",
      "- [#6] Seaport Topco Limited  Annual Report and Financial Statements (FY24), Directors Report approval/signatory, p.16. Link: https://aiprojectteneo.blob.core.windows.net/companieshousesinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2025-09-30_0.pdf\n",
      "- Advisors reference: Note 22 Loans (FY24) and Note 23 Loans (FY23) stating Kroll Agency Services Limited acting as the facility agent. FY24 (p.67) link same as [#2]/[#3]; FY23 links: https://aiprojectteneo.blob.core.windows.net/companyseaport/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_0.pdf and https://aiprojectteneo.blob.core.windows.net/companyseaport/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_1.pdf\n"
     ]
    }
   ],
   "source": [
    "print(resp['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8ed4315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated document written to: /Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile2.docx\n"
     ]
    }
   ],
   "source": [
    "import io, re\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_BREAK\n",
    "\n",
    "# =========================\n",
    "# 0) Your full GPT response\n",
    "# =========================\n",
    "gpt_output = r\"\"\"\n",
    "- Seaport Topco Limiteds principal activity continues to include the research and development of pharmaceutical instrumentation. [1][2]\n",
    "- The company is engaged in group-level operations focused on developing pharmaceutical instrumentation through ongoing research and development initiatives. [1][2]\n",
    "- It offers research and development of pharmaceutical instrumentation as its primary product and service offering. [1][2]\n",
    "- The company reported a headcount of 418 at Dec-24, up from 405, indicating ongoing operations across the group. [9]\n",
    "- The company faces near-term liquidity and working capital pressure, with creditors due within one year rising to 64.7m at Dec-24 driven by 7.7m of new loans and a 9.2m net revolving credit facility draw, while cash generated from operating activities declined to 10.4m from 15.3m in FY23. [9]\n",
    "- It carries substantial longer-term obligations, with creditors due after more than one year at 168.7m at Dec-23, alongside rising trade debtors to 17.0m and reduced stock to 13.2m at Dec-24, indicating cash conversion and balance sheet pressures. [7][8][9]\n",
    "\n",
    "Sources:\n",
    "- [1][2] Annual Report (FY23), Strategic/Directors Report, p.5  Principal activity.\n",
    "- [9] Annual Report (FY24), Group Strategic Report (pp.15; exact page n.a.)  Review of the business and future developments, working capital and liquidity movements.\n",
    "- [7][8] Annual Report (FY23), Notes 2122, Consolidated Statement of Financial Position, p.14  Creditors due within one year and after more than one year.\n",
    "\"\"\".strip(\"\\n\")\n",
    "\n",
    "# =========================\n",
    "# 1) Open DOCX\n",
    "# =========================\n",
    "doc_path = \"/Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile2.docx\"\n",
    "doc = Document(doc_path)\n",
    "\n",
    "PLACEHOLDER = \"[INSERT BUSINESS OVERVIEW]\"\n",
    "\n",
    "def set_paragraph_multiline(paragraph, text: str):\n",
    "    \"\"\"Replace a paragraph's text with multi-line content, preserving line breaks.\"\"\"\n",
    "    # clear existing runs\n",
    "    for run in paragraph.runs:\n",
    "        run.text = \"\"\n",
    "    # write lines with explicit line breaks\n",
    "    lines = (text or \"\").splitlines()\n",
    "    if not lines:\n",
    "        return\n",
    "    paragraph.add_run(lines[0])\n",
    "    for ln in lines[1:]:\n",
    "        r = paragraph.add_run()\n",
    "        r.add_break(WD_BREAK.LINE)\n",
    "        paragraph.add_run(ln)\n",
    "\n",
    "def replace_placeholder(document: Document, placeholder: str, new_text: str) -> bool:\n",
    "    \"\"\"Find placeholder in paragraphs/cells and replace it with new_text (multiline).\"\"\"\n",
    "    # plain paragraphs\n",
    "    for p in document.paragraphs:\n",
    "        if placeholder in p.text:\n",
    "            set_paragraph_multiline(p, new_text)\n",
    "            return True\n",
    "    # inside tables\n",
    "    for tbl in document.tables:\n",
    "        for row in tbl.rows:\n",
    "            for cell in row.cells:\n",
    "                for p in cell.paragraphs:\n",
    "                    if placeholder in p.text:\n",
    "                        set_paragraph_multiline(p, new_text)\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "# =========================\n",
    "# 2) Replace the placeholder\n",
    "# =========================\n",
    "ok = replace_placeholder(doc, PLACEHOLDER, gpt_output)\n",
    "if not ok:\n",
    "    print(f\"WARNING: placeholder not found: {PLACEHOLDER}\")\n",
    "\n",
    "# =========================\n",
    "# 3) Save\n",
    "# =========================\n",
    "out_path = \"/Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile2.docx\"\n",
    "doc.save(out_path)\n",
    "print(f\"Updated document written to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "538eebfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated document written to: /Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile2.docx\n",
      "NOTE  CSV metrics that couldn't be matched to any row (check your template labels):\n",
      " - RCF facility size\n",
      " - Delayed Drawdown Facility size\n",
      " - Bank loans due after >5 years\n",
      " - Bank loans due within 1 year\n"
     ]
    }
   ],
   "source": [
    "import io, re\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_BREAK\n",
    "\n",
    "# =========================\n",
    "# 0) Your full GPT response\n",
    "# =========================\n",
    "gpt_output = r\"\"\"\n",
    "Metric,FY24,FY23,FY22\n",
    "\"Facility Name\",\"n.a.\",\"Facility B1 (EUR term loan); Facility B2 (USD term loan); Revolving Credit Facility; Delayed Drawdown Facility [#2][#3]\",\"Revolving Credit Facility; Delayed Drawdown Facility [#3]\"\n",
    "\"Interest Rate\",\"n.a.\",\"Euribor + 6.25%; Term SOFR + 6.25% [#2][#3]\",\"n.a.\"\n",
    "Maturity,\"n.a.\",\"Aug-29 [#2][#3]\",\"n.a.\"\n",
    "\"Adjusted EBITDA\",\"n.a.\",\"17.9m [#2][#3]\",\"10.6m [#2][#3]\"\n",
    "\"Cash (Closing Cash)\",\"n.a.\",\"11.8m [#2][#3]\",\"n.a.\"\n",
    "\"Net Debt\",\"n.a.\",\"171.9m [#2][#3]\",\"n.a.\"\n",
    "Liquidity,\"n.a.\",\"25.8m [#2][#3]\",\"n.a.\"\n",
    "\"Leverage (Net Debt/EBITDA)\",\"n.a.\",\"9.6x [#2][#3]\",\"n.a.\"\n",
    "\"Facility B1 outstanding (GBP)\",\"n.a.\",\"36.0m [#2][#3]\",\"n.a.\"\n",
    "\"Facility B2 outstanding (GBP)\",\"n.a.\",\"135.0m [#2][#3]\",\"n.a.\"\n",
    "\"RCF drawn\",\"n.a.\",\"16.0m [#2][#3]\",\"16.0m [#3]\"\n",
    "\"RCF facility size\",\"n.a.\",\"30.0m [#2][#3]\",\"30.0m [#3]\"\n",
    "\"Delayed Drawdown Facility size\",\"n.a.\",\"75.0m [#2][#3]\",\"75.0m [#3]\"\n",
    "\"Bank loans due after >5 years\",\"n.a.\",\"168.7m [#2][#3]\",\"n.a.\"\n",
    "\"Bank loans due within 1 year\",\"n.a.\",\"14.7m [#2][#3]\",\"n.a.\"\n",
    "\"Bank loans + RCF outstanding (excl. leases)\",\"n.a.\",\"187.0m [#2][#3]\",\"n.a.\"\n",
    "\n",
    "Summary / Interpretation\n",
    "- FY23 leverage is high at 9.6x, based on 171.9m net debt and 17.9m Adjusted EBITDA.\n",
    "- FY23 facility mix is dominated by term loans (Facility B1 ~36.0m and B2 ~135.0m) maturing in Aug-29, plus a 30.0m RCF (of which 16.0m was drawn) and a 75.0m delayed draw facility.\n",
    "- FY23 liquidity appears modest at 25.8m, combining 11.8m closing cash with remaining headroom on the 30.0m RCF (drawn 16.0m).\n",
    "- Maturity profile in FY23 is back-ended: 168.7m due after >5 years versus 14.7m due within 1 year; both term facilities mature in Aug-29.\n",
    "- Total FY23 bank loans + RCF outstanding (excl. leases) sums to 187.0m, indicating a sizeable secured debt stack.\n",
    "- FY24 disclosures are not available in the provided excerpts, and FY22 data is limited beyond RCF details.\n",
    "\n",
    "Sources\n",
    "- [#2] Seaport Topco Limited Annual Report (file date 25-Sep-24), pp. 8, 45, 52  p.8 Adjusted EBITDA (17.9m FY23; 10.6m FY22); p.45 Loans note (Facility B1/B2 amounts, Aug-29 maturities, interest margins; RCF 30.0m and ~16.0m drawn; 75.0m delayed draw facility; bank loans due >5 years 168.7m and within 1 year 14.7m); p.52 Net debt analysis (Net Debt 171.9m; closing cash 11.8m). Link: https://aiprojectteneo.blob.core.windows.net/companieshouselinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_0.pdf\n",
    "- [#3] Seaport Topco Limited Annual Report (file date 25-Sep-24), pp. 8, 36, 45, 52  corroborates Adjusted EBITDA figures; Going concern (p.36) notes RCF drawn 16.0m at Dec-22; Loans note (p.45) for facility sizes/draws and maturities; Net debt analysis (p.52) for Net Debt and closing cash. Link: https://aiprojectteneo.blob.core.windows.net/companieshousinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_1.pdf\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# 1) Extract CSV + SUMMARY  (KEEP sources)\n",
    "# =========================\n",
    "parts = gpt_output.split(\"\\n\\nSummary / Interpretation\", 1)\n",
    "csv_block = parts[0].strip()\n",
    "\n",
    "start = csv_block.find(\"Metric,\")\n",
    "if start == -1:\n",
    "    raise ValueError(\"CSV header 'Metric,' not found in model output.\")\n",
    "csv_block = csv_block[start:]\n",
    "\n",
    "summary_text = \"\"\n",
    "if len(parts) > 1:\n",
    "    summary_text = \"Summary / Interpretation\" + parts[1].rstrip()\n",
    "\n",
    "# =========================\n",
    "# 2) Parse CSV to DataFrame\n",
    "# =========================\n",
    "df = pd.read_csv(io.StringIO(csv_block))\n",
    "expected_cols = {\"Metric\",\"FY24\"}\n",
    "if not expected_cols.issubset(df.columns):\n",
    "    raise ValueError(f\"Capital Structure CSV columns missing. Got: {list(df.columns)}\")\n",
    "\n",
    "csv_rows = {\n",
    "    str(df.at[i, \"Metric\"]).strip(): {\n",
    "        \"FY24\": str(df.at[i, \"FY24\"])\n",
    "    }\n",
    "    for i in range(len(df))\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# 3) Open DOCX, locate the Capital Structure table\n",
    "# =========================\n",
    "doc_path = \"/Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile2.docx\"\n",
    "doc = Document(doc_path)\n",
    "\n",
    "# ----------------- helpers -----------------\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", (s or \"\").lower())\n",
    "\n",
    "def tokens(s: str) -> set:\n",
    "    return set(re.findall(r\"[a-z0-9]+\", (s or \"\").lower()))\n",
    "\n",
    "def jaccard(a: str, b: str) -> float:\n",
    "    ta, tb = tokens(a), tokens(b)\n",
    "    if not ta or not tb:\n",
    "        return 0.0\n",
    "    inter = len(ta & tb)\n",
    "    union = len(ta | tb)\n",
    "    return inter / union if union else 0.0\n",
    "\n",
    "def find_cap_struct_table(document: Document):\n",
    "    # 1) after 'Capital Structure' heading\n",
    "    found_heading = False\n",
    "    body = document._element.body\n",
    "    for child in body.iterchildren():\n",
    "        tag = child.tag.rsplit(\"}\", 1)[-1]\n",
    "        if tag == \"p\":\n",
    "            p_text = \"\".join(t.text for t in child.iter()\n",
    "                             if t.tag.rsplit(\"}\",1)[-1] == \"t\").strip()\n",
    "            if norm(p_text) == \"capitalstructure\":\n",
    "                found_heading = True\n",
    "        elif tag == \"tbl\" and found_heading:\n",
    "            from docx.table import Table\n",
    "            return Table(child, document)\n",
    "\n",
    "    # 2) heuristic by content\n",
    "    for tbl in document.tables:\n",
    "        row_texts = [\" \".join(c.text for c in r.cells) for r in tbl.rows]\n",
    "        joined = \" \".join(row_texts)\n",
    "        if all(x in norm(joined) for x in [\"ebitda\",\"leverage\"]):\n",
    "            return tbl\n",
    "    return None\n",
    "\n",
    "table = find_cap_struct_table(doc)\n",
    "if table is None:\n",
    "    raise RuntimeError(\"Could not locate the 'Capital Structure' table.\")\n",
    "\n",
    "# Identify FY columns\n",
    "def find_fy_cols(tbl):\n",
    "    for r_i in range(min(2, len(tbl.rows))):\n",
    "        labels = [norm(c.text) for c in tbl.rows[r_i].cells]\n",
    "        loc = {}\n",
    "        for idx, txt in enumerate(labels):\n",
    "            if txt == \"fy24\": loc[\"FY24\"] = idx\n",
    "        if {\"FY24\"}.issubset(loc.keys()):\n",
    "            return loc[\"FY24\"]\n",
    "    if len(tbl.rows[0].cells) >= 4:\n",
    "        return 1, 2, 3\n",
    "    raise RuntimeError(\"Could not determine FY columns in Capital Structure table.\")\n",
    "\n",
    "col_FY24 = find_fy_cols(table)\n",
    "\n",
    "# Build row index from first column (labels)\n",
    "doc_row_index = {}\n",
    "doc_row_labels = {}  # norm_label -> raw label (for debug)\n",
    "for r_idx, row in enumerate(table.rows):\n",
    "    if not row.cells:\n",
    "        continue\n",
    "    label_raw = row.cells[0].text.strip()\n",
    "    if label_raw:\n",
    "        key = norm(label_raw)\n",
    "        doc_row_index[key] = r_idx\n",
    "        doc_row_labels[key] = label_raw\n",
    "\n",
    "# =========================\n",
    "# 4) Mapping (CSV -> DOC label), with synonyms & typo tolerance\n",
    "# =========================\n",
    "def keynorm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", (s or \"\").lower())\n",
    "\n",
    "# Add broad synonyms, incl. likely template wordings\n",
    "metric_to_doc_syns = {\n",
    "    keynorm(\"Facility Name\"): [\n",
    "        \"Facility Name\", \"Name of the Facility\", \"Facility\", \"Facilities\", \"Facility Names\",\n",
    "        \"Name of Facility\"\n",
    "    ],\n",
    "    keynorm(\"Interest Rate\"): [\"Interest Rate\", \"Interst Rate\", \"Rate\", \"Interest\"],\n",
    "    keynorm(\"Interst Rate\"):  [\"Interest Rate\", \"Interst Rate\", \"Rate\", \"Interest\"],\n",
    "    keynorm(\"Maturity\"): [\"Maturity\", \"Final Maturity\", \"Maturities\", \"Maturity Date\"],\n",
    "    keynorm(\"Adjusted EBITDA\"): [\"EBITDA\", \"Adjusted EBITDA\"],\n",
    "    keynorm(\"Cash (Closing Cash)\"): [\n",
    "        \"Cash (Closing Cash)\", \"Cash (Closing cash)\", \"Closing Cash\",\n",
    "        \"Cash\", \"Cash and cash equivalents\", \"Cash & cash equivalents\"\n",
    "    ],\n",
    "    keynorm(\"Net Debt\"): [\"Net External Debt\", \"Net Debt\"],\n",
    "    keynorm(\"Liquidity\"): [\"Liquidity\"],\n",
    "    keynorm(\"Leverage (Net Debt/EBITDA)\"): [\"Leverage\"],\n",
    "    keynorm(\"Leverage (Net Debt / EBITDA)\"): [\"Leverage\"],\n",
    "    keynorm(\"Bank loans + RCF outstanding (excl. leases)\"): [\"Gross External Debt\", \"Total External Debt\"],\n",
    "\n",
    "    keynorm(\"Facility B1 outstanding (GBP)\"): [\"Amount Outstanding\"],\n",
    "    keynorm(\"Facility B2 outstanding (GBP)\"): [\"Amount Outstanding\"],\n",
    "    keynorm(\"RCF drawn\"): [\"Amount Outstanding\"],\n",
    "\n",
    "    keynorm(\"RCF facility size\"): [None],\n",
    "    keynorm(\"Delayed Drawdown Facility size\"): [None],\n",
    "    keynorm(\"Bank loans due after >5 years\"): [None],\n",
    "    keynorm(\"Bank loans due within 1 year\"): [None],\n",
    "}\n",
    "\n",
    "def smart_lookup_row_index(label_candidates):\n",
    "    \"\"\"\n",
    "    Resolve to the best row index by:\n",
    "      1) Exact normalized match\n",
    "      2) Contains match (both directions)\n",
    "      3) Token Jaccard similarity >= 0.5\n",
    "    Returns row_index or None.\n",
    "    \"\"\"\n",
    "    cand_norms = [norm(c) for c in label_candidates if c]\n",
    "\n",
    "    # 1) exact\n",
    "    for cn in cand_norms:\n",
    "        if cn in doc_row_index:\n",
    "            return doc_row_index[cn]\n",
    "\n",
    "    # 2) contains (prefer the longest doc label match)\n",
    "    best_idx = None\n",
    "    best_len = -1\n",
    "    for cn in cand_norms:\n",
    "        for dl_norm, idx in doc_row_index.items():\n",
    "            if cn and (cn in dl_norm or dl_norm in cn):\n",
    "                if len(dl_norm) > best_len:\n",
    "                    best_idx, best_len = idx, len(dl_norm)\n",
    "    if best_idx is not None:\n",
    "        return best_idx\n",
    "\n",
    "    # 3) token overlap\n",
    "    best_idx = None\n",
    "    best_score = 0.0\n",
    "    for cn in cand_norms:\n",
    "        for dl_norm, idx in doc_row_index.items():\n",
    "            score = jaccard(cn, dl_norm)\n",
    "            if score >= 0.5 and score > best_score:\n",
    "                best_idx, best_score = idx, score\n",
    "    return best_idx\n",
    "\n",
    "# =========================\n",
    "# 5) Populate the table (incl. Facility Name / Interest Rate / Maturity)\n",
    "#    and aggregate facility amounts into 'Amount Outstanding'\n",
    "# =========================\n",
    "agg_amount = {\"FY24\": []}\n",
    "\n",
    "def maybe_append(prefix, v):\n",
    "    v = (v or \"\").strip()\n",
    "    if not v or v.lower() == \"n.a.\":\n",
    "        return None\n",
    "    return f\"{prefix}: {v}\"\n",
    "\n",
    "unmapped_metrics = []\n",
    "\n",
    "for csv_metric, years in csv_rows.items():\n",
    "    mkey = keynorm(csv_metric)\n",
    "    syns = metric_to_doc_syns.get(mkey, [csv_metric])\n",
    "\n",
    "    # aggregated targets\n",
    "    if any((s and norm(s) == norm(\"Amount Outstanding\")) for s in syns if s):\n",
    "        if mkey == keynorm(\"Facility B1 outstanding (GBP)\"):\n",
    "            for fy in (\"FY24\",):\n",
    "                s = maybe_append(\"B1\", years[fy]);  agg_amount[fy].append(s) if s else None\n",
    "        elif mkey == keynorm(\"Facility B2 outstanding (GBP)\"):\n",
    "            for fy in (\"FY24\",):\n",
    "                s = maybe_append(\"B2\", years[fy]);  agg_amount[fy].append(s) if s else None\n",
    "        elif mkey == keynorm(\"RCF drawn\"):\n",
    "            for fy in (\"FY24\",):\n",
    "                s = maybe_append(\"RCF drawn\", years[fy]);  agg_amount[fy].append(s) if s else None\n",
    "        continue\n",
    "\n",
    "    r_idx = smart_lookup_row_index(syns)\n",
    "    if r_idx is None:\n",
    "        unmapped_metrics.append(csv_metric)\n",
    "        continue\n",
    "\n",
    "    row = table.rows[r_idx]\n",
    "    row.cells[col_FY24].text = years[\"FY24\"]\n",
    "\n",
    "# Aggregated 'Amount Outstanding'\n",
    "amount_row_idx = smart_lookup_row_index([\"Amount Outstanding\"])\n",
    "if amount_row_idx is not None:\n",
    "    row = table.rows[amount_row_idx]\n",
    "    row.cells[col_FY24].text = \"; \".join(agg_amount[\"FY24\"]) if agg_amount[\"FY24\"] else \"n.a.\"\n",
    "\n",
    "# =========================\n",
    "# 6) Insert the full SUMMARY (including Sources)  no duplicates\n",
    "# =========================\n",
    "PLACEHOLDER = \"[INSERT CAPITAL STRUCTURE SUMMARY]\"\n",
    "HEADING_TEXT = \"Summary / Interpretation\"\n",
    "\n",
    "def set_paragraph_multiline(paragraph, text: str):\n",
    "    for run in paragraph.runs:  # clear\n",
    "        run.text = \"\"\n",
    "    lines = (text or \"\").splitlines()\n",
    "    if not lines:\n",
    "        return\n",
    "    paragraph.add_run(lines[0])\n",
    "    for ln in lines[1:]:\n",
    "        paragraph.add_run().add_break(WD_BREAK.LINE)\n",
    "        paragraph.add_run(ln)\n",
    "\n",
    "def replace_placeholder(document: Document, placeholder: str, new_text: str) -> bool:\n",
    "    # paragraphs\n",
    "    for p in document.paragraphs:\n",
    "        if placeholder in p.text:\n",
    "            set_paragraph_multiline(p, new_text)\n",
    "            return True\n",
    "    # tables\n",
    "    for tbl in document.tables:\n",
    "        for row in tbl.rows:\n",
    "            for cell in row.cells:\n",
    "                for p in cell.paragraphs:\n",
    "                    if placeholder in p.text:\n",
    "                        set_paragraph_multiline(p, new_text)\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "def find_all_summary_paragraphs(document: Document, heading_text: str):\n",
    "    anchors = []\n",
    "    for p in document.paragraphs:\n",
    "        if heading_text in p.text:\n",
    "            anchors.append(p)\n",
    "    for tbl in document.tables:\n",
    "        for row in tbl.rows:\n",
    "            for cell in row.cells:\n",
    "                for p in cell.paragraphs:\n",
    "                    if heading_text in p.text:\n",
    "                        anchors.append(p)\n",
    "    return anchors\n",
    "\n",
    "insert_done = False\n",
    "if summary_text:\n",
    "    insert_done = replace_placeholder(doc, PLACEHOLDER, summary_text)\n",
    "\n",
    "if summary_text and not insert_done:\n",
    "    anchors = find_all_summary_paragraphs(doc, HEADING_TEXT)\n",
    "    if anchors:\n",
    "        # overwrite first and remove extras\n",
    "        set_paragraph_multiline(anchors[0], summary_text)\n",
    "        for dup in anchors[1:]:\n",
    "            dup._element.getparent().remove(dup._element)\n",
    "    else:\n",
    "        p = doc.add_paragraph()\n",
    "        set_paragraph_multiline(p, summary_text)\n",
    "        # ensure no accidental multiples\n",
    "        anchors = find_all_summary_paragraphs(doc, HEADING_TEXT)\n",
    "        for dup in anchors[1:]:\n",
    "            dup._element.getparent().remove(dup._element)\n",
    "\n",
    "# =========================\n",
    "# 7) Save + (optional) debug\n",
    "# =========================\n",
    "out_path = \"/Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile2.docx\"\n",
    "doc.save(out_path)\n",
    "print(f\"Updated document written to: {out_path}\")\n",
    "\n",
    "if unmapped_metrics:\n",
    "    print(\"NOTE  CSV metrics that couldn't be matched to any row (check your template labels):\")\n",
    "    for m in unmapped_metrics:\n",
    "        print(\" -\", m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a66aaad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated document written to: /Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile2.docx\n"
     ]
    }
   ],
   "source": [
    "import io, re\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_BREAK\n",
    "\n",
    "# =========================\n",
    "# 0) Your full GPT response\n",
    "# =========================\n",
    "gpt_output = r\"\"\"\n",
    "Metric,Shareholders\n",
    "\"Shareholders\",n.a.\n",
    "\"Management\",\"Directors (FY24): M Bauer; R Diggelmann  resigned Dec-24; P Dowdy  resigned Feb-25; J Feldman; R Friel  resigned Mar-25; K Murphy; D Newble  resigned Jul-24; A Thorburn; R Walton  appointed Jul-24\"\n",
    "\"Lenders\",n.a.\n",
    "\"Auditors\",\"Grant Thornton UK LLP (Statutory Auditor); Stephen Wyborn (Senior Statutory Auditor)\"\n",
    "\"Advisors\",\"Facility agent: Kroll Agency Services Limited; Bankers: n.a.; Solicitors: n.a.; Financial advisor: n.a.\"\n",
    "\n",
    "Summary / Interpretation\n",
    "- Shareholder information is n.a., indicating no disclosed immediate or ultimate parent in the provided filings.\n",
    "- Management is represented by the FY24 directors list; specific Chairman/CEO/CFO titles are not provided.\n",
    "- Lenders are n.a., suggesting no disclosed bank facilities/borrowings in the available excerpts.\n",
    "- Auditors are identified (Grant Thornton UK LLP; Senior Statutory Auditor Stephen Wyborn), while most other advisors are n.a. except the facility agent (Kroll Agency Services Limited).\n",
    "- Advisor disclosure is limited (bankers/solicitors/financial advisor n.a.), constraining visibility into counterparties.\n",
    "\n",
    "SECTION 3 - SOURCES\n",
    "- [#1] Seaport Topco Limited AA Annual Report (published Sep-25), Directors Report for the year ended 31 Dec-24, p.12. Link: https://aiprojectteneo.blob.core.windows.net/companieshousesinglefile/14171962/SEAPORT_TOPCO_LIMITED_AA_annualReport_2025-09-30_0.pdf  used for the Management (directors) row.\n",
    "- [#2] Seaport Topco Limited AA Annual Report (2024-09-25)  provided excerpt indicating Company Information page not available  supports n.a. for certain advisor details.\n",
    "- [#3] Seaport Topco Limited annual report (FY24), Notes to the Financial Statements  Accounting policies excerpt (page n.a.)  used to check terminology (bank loans/borrowings); lenders n.a. and facility agent reference noted elsewhere.\n",
    "- [#4] Seaport Topco Limited Annual Report 2024, Independent Auditors Report signature block, file: SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_1.pdf (26 pages), signed Apr-24  used for Auditors identification and to support shareholder n.a.\n",
    "- [#5] Seaport Topco Limited Annual Report (published Sep-24), Notes to the Financial Statements, Note 16: Fixed asset investments  Indirect subsidiary undertakings (page n.a.)  used to support Shareholders n.a. (no parent/ultimate controlling party disclosed).\n",
    "- [#7] Seaport Topco Limited Annual Report 2024, Independent Auditors Report signature block, file: SEAPORT_TOPCO_LIMITED_AA_annualReport_2024-09-25_0.pdf (26 pages), signed Apr-24  corroborates Auditors identification.\n",
    "\"\"\"\n",
    "\n",
    "# =========================\n",
    "# 1) Extract CSV + SUMMARY\n",
    "# =========================\n",
    "parts = gpt_output.split(\"\\n\\nSummary / Interpretation\", 1)\n",
    "csv_block = parts[0].strip()\n",
    "\n",
    "start = csv_block.find(\"Metric,\")\n",
    "if start == -1:\n",
    "    raise ValueError(\"CSV header 'Metric,' not found in model output.\")\n",
    "csv_block = csv_block[start:]\n",
    "\n",
    "summary_text = \"\"\n",
    "if len(parts) > 1:\n",
    "    summary_text = \"Summary / Interpretation\" + parts[1].rstrip()\n",
    "\n",
    "# =========================\n",
    "# 2) Parse CSV to DataFrame\n",
    "# =========================\n",
    "df = pd.read_csv(io.StringIO(csv_block))\n",
    "expected_cols = {\"Metric\", \"Shareholders\"}\n",
    "if not expected_cols.issubset(df.columns):\n",
    "    raise ValueError(f\"Key Stakeholders CSV columns missing. Got: {list(df.columns)}\")\n",
    "\n",
    "# Dict: metric -> value (right column)\n",
    "ks_rows = {\n",
    "    str(df.at[i, \"Metric\"]).strip(): str(df.at[i, \"Shareholders\"]).strip()\n",
    "    for i in range(len(df))\n",
    "}\n",
    "\n",
    "# ==============================================\n",
    "# 3) Open DOCX, find the \"Key Stakeholders\" table\n",
    "# ==============================================\n",
    "doc_path = \"/Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile (1).docx\"\n",
    "doc = Document(doc_path)\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", (s or \"\").lower())\n",
    "\n",
    "def find_ks_table(document: Document):\n",
    "    # Prefer a table whose header has both \"Title\" and \"Occupants\"\n",
    "    for tbl in document.tables:\n",
    "        if not tbl.rows:\n",
    "            continue\n",
    "        header = [norm(c.text) for c in tbl.rows[0].cells]\n",
    "        if \"title\" in header and \"occupants\" in header:\n",
    "            return tbl\n",
    "\n",
    "    # Fallback: first table after the \"Key Stakeholders\" heading\n",
    "    found_heading = False\n",
    "    body = document._element.body\n",
    "    for child in body.iterchildren():\n",
    "        tag = child.tag.rsplit(\"}\", 1)[-1]\n",
    "        if tag == \"p\":\n",
    "            p_text = \"\".join(t.text for t in child.iter()\n",
    "                             if t.tag.rsplit(\"}\",1)[-1] == \"t\").strip()\n",
    "            if norm(p_text) == \"keystakeholders\":\n",
    "                found_heading = True\n",
    "        elif tag == \"tbl\" and found_heading:\n",
    "            from docx.table import Table\n",
    "            return Table(child, document)\n",
    "    return None\n",
    "\n",
    "ks_table = find_ks_table(doc)\n",
    "if ks_table is None:\n",
    "    raise RuntimeError(\"Could not locate the 'Key Stakeholders' table (Title | Occupants).\")\n",
    "\n",
    "# ==============================================\n",
    "# 4) Detect columns: label = \"Title\", value = \"Occupants\"\n",
    "# ==============================================\n",
    "def get_title_and_occupants_cols(tbl):\n",
    "    # Defaults for a 2-col layout\n",
    "    label_col, value_col = 0, 1\n",
    "\n",
    "    if tbl.rows:\n",
    "        header_norm = [norm(c.text) for c in tbl.rows[0].cells]\n",
    "        if \"title\" in header_norm:\n",
    "            label_col = header_norm.index(\"title\")\n",
    "        if \"occupants\" in header_norm:\n",
    "            value_col = header_norm.index(\"occupants\")\n",
    "\n",
    "    # Ensure they are different; if not, force value_col to the other col\n",
    "    if value_col == label_col and len(tbl.rows[0].cells) >= 2:\n",
    "        value_col = 1 if label_col == 0 else 0\n",
    "    return label_col, value_col\n",
    "\n",
    "label_col, value_col = get_title_and_occupants_cols(ks_table)\n",
    "\n",
    "# ==============================================\n",
    "# 5) Build row index using the Title (label) column\n",
    "# ==============================================\n",
    "row_index = {}\n",
    "for r_idx, row in enumerate(ks_table.rows):\n",
    "    if not row.cells:\n",
    "        continue\n",
    "    # Skip header\n",
    "    if r_idx == 0:\n",
    "        continue\n",
    "    label_text = row.cells[label_col].text.strip()\n",
    "    if label_text:\n",
    "        row_index[norm(label_text)] = r_idx\n",
    "\n",
    "# ==============================================\n",
    "# 6) Map CSV metric names  Title labels\n",
    "# ==============================================\n",
    "def keynorm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", (s or \"\").lower())\n",
    "\n",
    "metric_to_title = {\n",
    "    keynorm(\"Shareholders\"): \"Shareholders\",\n",
    "    keynorm(\"Management\"):  \"Management\",\n",
    "    keynorm(\"Lenders\"):     \"Lenders\",\n",
    "    keynorm(\"Auditors\"):    \"Auditors\",\n",
    "    keynorm(\"Advisors\"):    \"Advisors\",\n",
    "}\n",
    "\n",
    "# ==============================================\n",
    "# 7) Populate the Occupants column ONLY\n",
    "# ==============================================\n",
    "not_found = []\n",
    "for metric, value in ks_rows.items():\n",
    "    title_label = metric_to_title.get(keynorm(metric), metric)\n",
    "    r_idx = row_index.get(norm(title_label))\n",
    "    if r_idx is None:\n",
    "        not_found.append(metric)\n",
    "        continue\n",
    "    # write into Occupants cell\n",
    "    ks_table.rows[r_idx].cells[value_col].text = value\n",
    "\n",
    "if not_found:\n",
    "    print(\"WARNING  missing rows for:\", \", \".join(not_found))\n",
    "\n",
    "# ==============================================\n",
    "# 8) Replace the placeholder with the KS SUMMARY text (optional)\n",
    "#     (placeholder: [INSERT KEY STAKEHOLDERS SUMMARY])\n",
    "# ==============================================\n",
    "KS_PLACEHOLDER = \"[INSERT KEY STAKEHOLDERS SUMMARY]\"\n",
    "\n",
    "def set_paragraph_multiline(paragraph, text: str):\n",
    "    for run in paragraph.runs:\n",
    "        run.text = \"\"\n",
    "    lines = (text or \"\").splitlines()\n",
    "    if not lines:\n",
    "        return\n",
    "    paragraph.add_run(lines[0])\n",
    "    for ln in lines[1:]:\n",
    "        paragraph.add_run().add_break(WD_BREAK.LINE)\n",
    "        paragraph.add_run(ln)\n",
    "\n",
    "def replace_placeholder(document: Document, placeholder: str, new_text: str) -> bool:\n",
    "    # paragraphs\n",
    "    for p in document.paragraphs:\n",
    "        if placeholder in p.text:\n",
    "            set_paragraph_multiline(p, new_text)\n",
    "            return True\n",
    "    # cells\n",
    "    for tbl in document.tables:\n",
    "        for row in tbl.rows:\n",
    "            for cell in row.cells:\n",
    "                for p in cell.paragraphs:\n",
    "                    if placeholder in p.text:\n",
    "                        set_paragraph_multiline(p, new_text)\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "if summary_text:\n",
    "    ok = replace_placeholder(doc, KS_PLACEHOLDER, summary_text)\n",
    "    if not ok:\n",
    "        print(\"NOTE: placeholder not found:\", KS_PLACEHOLDER)\n",
    "\n",
    "# ==============================================\n",
    "# 9) Save\n",
    "# ==============================================\n",
    "out_path = \"/Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile2.docx\"\n",
    "doc.save(out_path)\n",
    "print(f\"Updated document written to: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7220bf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated document written to: /Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile2.docx\n",
      "WARNING  CSV metrics not matched to any row:\n",
      " - Revenue (Turnover)\n",
      " - Revenue growth % (yoy)\n",
      " - Cost of sales\n",
      " - Operating profit\n",
      " - Depreciation\n",
      " - Amortization\n",
      " - Net cash flow from operating activities\n",
      " - Net working capital (cash flow changes)\n",
      " - Cash flow from operating activities excl. working capital\n",
      " - Net cash flow from investing activities\n",
      " - Net cash flow from financing activities\n",
      " - Debt issuance (draw down of bank loans)\n",
      " - Share issuance\n",
      " - Leverage (Net Debt/EBITDA)\n"
     ]
    }
   ],
   "source": [
    "import io, re\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_BREAK\n",
    "\n",
    "# =========================\n",
    "# 0) Your full GPT response\n",
    "# =========================\n",
    "gpt_output = finance_output\n",
    "\n",
    "# =========================\n",
    "# 1) Extract CSV + SUMMARY\n",
    "# =========================\n",
    "# Split off the summary block (everything after the blank line + heading)\n",
    "parts = gpt_output.split(\"\\n\\nSummary / Interpretation\", 1)\n",
    "csv_block = parts[0].strip()\n",
    "\n",
    "# Ensure we start at the CSV header\n",
    "start = csv_block.find(\"Metric,\")\n",
    "if start == -1:\n",
    "    raise ValueError(\"CSV header 'Metric,' not found in model output.\")\n",
    "csv_block = csv_block[start:]\n",
    "\n",
    "# Summary text (keep heading + bullets if present)\n",
    "summary_text = \"\"\n",
    "if len(parts) > 1:\n",
    "    summary_text = \"Summary / Interpretation\" + parts[1].rstrip()\n",
    "\n",
    "# =========================\n",
    "# 2) Parse CSV to DataFrame\n",
    "# =========================\n",
    "df = pd.read_csv(io.StringIO(csv_block))\n",
    "expected_cols = {\"Metric\",\"FY24\",\"FY23\",\"FY22\"}\n",
    "if not expected_cols.issubset(df.columns):\n",
    "    raise ValueError(f\"CSV columns missing. Got: {list(df.columns)}\")\n",
    "\n",
    "# Dict: metric -> {FY24, FY23, FY22}\n",
    "csv_rows = {\n",
    "    str(df.at[i, \"Metric\"]).strip(): {\n",
    "        \"FY24\": df.at[i, \"FY24\"],\n",
    "        \"FY23\": df.at[i, \"FY23\"],\n",
    "        \"FY22\": df.at[i, \"FY22\"],\n",
    "    }\n",
    "    for i in range(len(df))\n",
    "}\n",
    "\n",
    "# ==============================================\n",
    "# 3) Open DOCX, find the Financial Performance table\n",
    "# ==============================================\n",
    "doc_path = \"/Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile (1).docx\"\n",
    "doc = Document(doc_path)\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", (s or \"\").lower())\n",
    "\n",
    "def find_fin_perf_table(document: Document):\n",
    "    # Heuristic 1: find a table whose header row contains FY24/FY23/FY22\n",
    "    for tbl in document.tables:\n",
    "        if len(tbl.rows):\n",
    "            header = \" \".join(c.text for c in tbl.rows[0].cells)\n",
    "            if all(x in norm(header) for x in [\"fy24\",\"fy23\",\"fy22\"]):\n",
    "                return tbl\n",
    "    # Heuristic 2: first table after a paragraph exactly \"Financial Performance\"\n",
    "    found_heading = False\n",
    "    body = document._element.body\n",
    "    for child in body.iterchildren():\n",
    "        tag = child.tag.rsplit(\"}\", 1)[-1]\n",
    "        if tag == \"p\":\n",
    "            p_text = \"\".join(t.text for t in child.iter() if t.tag.rsplit(\"}\",1)[-1] == \"t\").strip()\n",
    "            if norm(p_text) == \"financialperformance\":\n",
    "                found_heading = True\n",
    "        elif tag == \"tbl\" and found_heading:\n",
    "            from docx.table import Table\n",
    "            return Table(child, document)\n",
    "    return None\n",
    "\n",
    "table = find_fin_perf_table(doc)\n",
    "if table is None:\n",
    "    raise RuntimeError(\"Could not locate the 'Financial Performance' table.\")\n",
    "\n",
    "# ==============================================\n",
    "# 4) Map CSV metric names  rows in the template\n",
    "# ==============================================\n",
    "# --- Normalizers (use same rule for CSV and map keys) ---\n",
    "def keynorm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", (s or \"\").lower())\n",
    "\n",
    "# Map CSV metric -> DOC row label (left column text in your template)\n",
    "# Use normalized keys on the left so variations in spaces/slashes/plus signs won't break it.\n",
    "metric_map_norm = {\n",
    "    keynorm(\"Revenue (Turnover)\"): \"Revenue\",\n",
    "    keynorm(\"Revenue growth % (yoy)\"): \"Revenue Growth\",\n",
    "    keynorm(\"Gross profit\"): \"Gross Profit\",\n",
    "    keynorm(\"Gross margin %\"): \"Gross Margin\",\n",
    "    keynorm(\"EBITDA\"): \"EBITDA\",\n",
    "    keynorm(\"EBITDA margin %\"): \"EBITDA Margin\",\n",
    "    keynorm(\"Adjusted EBITDA\"): \"Adjusted EBITDA\",\n",
    "\n",
    "    # >>> The ones you said aren't populating <<<\n",
    "    keynorm(\"Capex (tangible+intangible)\"): \"CAPEX\",  # DOC label\n",
    "    keynorm(\"Capex (tangible + intangible)\"): \"CAPEX\",  # alt form (spaces)\n",
    "    keynorm(\"Net Working Capital (change)\"): \"NET_WORK\",\n",
    "    keynorm(\"Cash Flow from Financing Activities (net)\"): \"Cash Flow from Financing Activities\",\n",
    "    keynorm(\"Net cash from financing activities\"): \"CASH_FINAN\",  # alt wording\n",
    "    keynorm(\"Total Debt (external)\"): \"TOTAL_DEBT\",\n",
    "    keynorm(\"Total debt (bank + lease liabilities)\"): \"TOTAL_DEBT\",  # alt wording\n",
    "    keynorm(\"Leverage (Net Debt/EBITDA)\"): \"LEVERAGE\",\n",
    "    keynorm(\"Leverage (Net Debt / EBITDA)\"): \"LEVERAGE\",\n",
    "\n",
    "    # Other cash flow items you have\n",
    "    keynorm(\"Net cash from operating activities\"): \"Cash Flow from Operating Activities\",\n",
    "    keynorm(\"Net Working Capital (change)\"): \"Net Working Capital\",  # duplicate on purpose (case variant)\n",
    "    keynorm(\"Operating cash flow excl. NWC\"): \"Cash Flow from Operating Activities excl. Net Working Capital\",\n",
    "    keynorm(\"Other Cash Flow from Investing Activities\"): \"Other Cash Flow from Investing Activities\",\n",
    "    keynorm(\"Net cash from investing activities\"): \"Net Cash Flow from Investing Activities\",\n",
    "    keynorm(\"CFADS\"): \"CFADS\",\n",
    "    keynorm(\"Opening Cash\"): \"Opening Cash\",\n",
    "    keynorm(\"Change in Cash\"): \"Change in Cash\",\n",
    "    keynorm(\"Closing Cash\"): \"Closing Cash\",\n",
    "    keynorm(\"Bank loans outstanding\"): \"Total Debt\",  # if your template has separate row, adjust\n",
    "    keynorm(\"Net Debt\"): \"Net Debt\",\n",
    "}\n",
    "\n",
    "# Build lookup of row labels in the DOCX (first column). You already did:\n",
    "doc_row_index = {}\n",
    "for r_idx, row in enumerate(table.rows):\n",
    "    label = row.cells[0].text.strip()\n",
    "    if label:\n",
    "        doc_row_index[norm(label)] = r_idx  # norm = your doc normalizer (same idea as keynorm)\n",
    "\n",
    "# Identify FY columns in header row (handles \"FY 24\" vs \"FY24\")\n",
    "header_norm = [norm(c.text) for c in table.rows[0].cells]\n",
    "try:\n",
    "    col_FY24 = header_norm.index(\"fy24\")\n",
    "    col_FY23 = header_norm.index(\"fy23\")\n",
    "    col_FY22 = header_norm.index(\"fy22\")\n",
    "except ValueError:\n",
    "    # If header is the second row in your template, try that\n",
    "    header_norm = [norm(c.text) for c in table.rows[1].cells]\n",
    "    col_FY24 = header_norm.index(\"fy24\")\n",
    "    col_FY23 = header_norm.index(\"fy23\")\n",
    "    col_FY22 = header_norm.index(\"fy22\")\n",
    "\n",
    "\n",
    "# Populate table\n",
    "not_found = []\n",
    "\n",
    "for csv_metric, years in csv_rows.items():\n",
    "    # Find the DOC row label using normalized CSV metric text\n",
    "    target_label = metric_map_norm.get(keynorm(csv_metric), csv_metric)  # fall back to same text\n",
    "    r_idx = doc_row_index.get(norm(target_label))  # norm() is your existing doc normalizer\n",
    "    if r_idx is None:\n",
    "        not_found.append(csv_metric)\n",
    "        continue\n",
    "\n",
    "    row = table.rows[r_idx]\n",
    "    row.cells[col_FY24].text = str(years[\"FY24\"])\n",
    "    row.cells[col_FY23].text = str(years[\"FY23\"])\n",
    "    row.cells[col_FY22].text = str(years[\"FY22\"])\n",
    "\n",
    "# ==============================================\n",
    "# 5) Populate the table from CSV\n",
    "# ==============================================\n",
    "not_found = []\n",
    "\n",
    "for csv_metric, years in csv_rows.items():\n",
    "    target_label = metric_map_norm.get(csv_metric, csv_metric)\n",
    "    r_idx = doc_row_index.get(norm(target_label))\n",
    "    if r_idx is None:\n",
    "        not_found.append(csv_metric)\n",
    "        continue\n",
    "\n",
    "    row = table.rows[r_idx]\n",
    "    row.cells[col_FY24].text = str(years[\"FY24\"])\n",
    "    row.cells[col_FY23].text = str(years[\"FY23\"])\n",
    "    row.cells[col_FY22].text = str(years[\"FY22\"])\n",
    "\n",
    "# ==============================================\n",
    "# 6) Replace the placeholder with the SUMMARY text\n",
    "#     (placeholder: [INSERT FINANCIAL PERFORMANCE SUMMARY])\n",
    "# ==============================================\n",
    "PLACEHOLDER = \"[INSERT FINANCIAL PERFORMANCE SUMMARY]\"\n",
    "\n",
    "def set_paragraph_multiline(paragraph, text: str):\n",
    "    # clear runs\n",
    "    for run in paragraph.runs:\n",
    "        run.text = \"\"\n",
    "    # add lines with explicit line breaks\n",
    "    lines = text.splitlines()\n",
    "    if not lines:\n",
    "        return\n",
    "    paragraph.add_run(lines[0])\n",
    "    for ln in lines[1:]:\n",
    "        paragraph.add_run().add_break(WD_BREAK.LINE)\n",
    "        paragraph.add_run(ln)\n",
    "\n",
    "def replace_placeholder(document: Document, placeholder: str, new_text: str) -> bool:\n",
    "    # search in paragraphs\n",
    "    for p in document.paragraphs:\n",
    "        if placeholder in p.text:\n",
    "            set_paragraph_multiline(p, new_text)\n",
    "            return True\n",
    "    # search inside tables (cells contain their own paragraphs)\n",
    "    for tbl in document.tables:\n",
    "        for row in tbl.rows:\n",
    "            for cell in row.cells:\n",
    "                for p in cell.paragraphs:\n",
    "                    if placeholder in p.text:\n",
    "                        set_paragraph_multiline(p, new_text)\n",
    "                        return True\n",
    "    return False\n",
    "\n",
    "if summary_text:\n",
    "    ok = replace_placeholder(doc, PLACEHOLDER, summary_text)\n",
    "    if not ok:\n",
    "        print(\"WARNING: placeholder not found:\", PLACEHOLDER)\n",
    "else:\n",
    "    print(\"NOTE: No summary text found in GPT output (no 'Summary / Interpretation' section).\")\n",
    "\n",
    "# ==============================================\n",
    "# 7) Save\n",
    "# ==============================================\n",
    "out_path = \"/Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile2.docx\"\n",
    "doc.save(out_path)\n",
    "print(f\"Updated document written to: {out_path}\")\n",
    "\n",
    "if not_found:\n",
    "    print(\"WARNING  CSV metrics not matched to any row:\")\n",
    "    for m in not_found:\n",
    "        print(\" -\", m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c882b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, re\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from docx.enum.text import WD_BREAK\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "def insert_table_data_generic(\n",
    "    gpt_output: str,\n",
    "    doc_path: str,\n",
    "    table_type: str,\n",
    "    metric_mapping: Optional[Dict[str, str]] = None,\n",
    "    doc: Optional[Document] = None\n",
    ") -> Document:\n",
    "    \"\"\"\n",
    "    Generic function to insert GPT-generated data into docx tables.\n",
    "    \n",
    "    Args:\n",
    "        gpt_output: The GPT response containing CSV/Table data and summary\n",
    "        doc_path: Path to the docx file\n",
    "        table_type: Type of table - 'capital_structure', 'financial_performance', or 'key_stakeholders'\n",
    "        metric_mapping: Optional dict to map CSV metric names to template row labels\n",
    "                       Keys should be normalized (lowercase, no special chars)\n",
    "        doc: Optional existing Document object. If None, will load from doc_path\n",
    "    \n",
    "    Returns:\n",
    "        Updated Document object\n",
    "    \"\"\"\n",
    "    \n",
    "    # =========================\n",
    "    # Helper functions\n",
    "    # =========================\n",
    "    def norm(s: str) -> str:\n",
    "        \"\"\"Normalize string for comparison (lowercase, alphanumeric only)\"\"\"\n",
    "        return re.sub(r\"[^a-z0-9]+\", \"\", (s or \"\").lower())\n",
    "    \n",
    "    def keynorm(s: str) -> str:\n",
    "        \"\"\"Normalize string for dictionary keys\"\"\"\n",
    "        return re.sub(r\"[^a-z0-9]+\", \"\", (s or \"\").lower())\n",
    "    \n",
    "    def tokens(s: str) -> set:\n",
    "        return set(re.findall(r\"[a-z0-9]+\", (s or \"\").lower()))\n",
    "    \n",
    "    def jaccard(a: str, b: str) -> float:\n",
    "        \"\"\"Calculate Jaccard similarity between two strings\"\"\"\n",
    "        ta, tb = tokens(a), tokens(b)\n",
    "        if not ta or not tb:\n",
    "            return 0.0\n",
    "        inter = len(ta & tb)\n",
    "        union = len(ta | tb)\n",
    "        return inter / union if union else 0.0\n",
    "    \n",
    "    def set_cell_text(cell, text: str):\n",
    "        \"\"\"Set cell text preserving formatting\"\"\"\n",
    "        if not cell.paragraphs:\n",
    "            cell.add_paragraph(text)\n",
    "            return\n",
    "        p = cell.paragraphs[0]\n",
    "        for run in p.runs:\n",
    "            run.text = \"\"\n",
    "        p.add_run(text)\n",
    "    \n",
    "    def set_paragraph_multiline(paragraph, text: str):\n",
    "        \"\"\"Replace a paragraph's text with multi-line content, preserving line breaks.\"\"\"\n",
    "        for run in paragraph.runs:\n",
    "            run.text = \"\"\n",
    "        lines = (text or \"\").splitlines()\n",
    "        if not lines:\n",
    "            return\n",
    "        paragraph.add_run(lines[0])\n",
    "        for ln in lines[1:]:\n",
    "            r = paragraph.add_run()\n",
    "            r.add_break(WD_BREAK.LINE)\n",
    "            paragraph.add_run(ln)\n",
    "    \n",
    "    # =========================\n",
    "    # 1) Extract CSV/Table + Summary from GPT output\n",
    "    # =========================\n",
    "    parts = gpt_output.split(\"\\n\\nSummary / Interpretation\", 1)\n",
    "    csv_block = parts[0].strip()\n",
    "    \n",
    "    # Find where the table/CSV starts\n",
    "    start = csv_block.find(\"Metric,\")\n",
    "    if start == -1:\n",
    "        # Try to find markdown table format\n",
    "        start = csv_block.find(\"| Metric |\")\n",
    "        if start != -1:\n",
    "            # Convert markdown table to CSV\n",
    "            lines = csv_block[start:].split(\"\\n\")\n",
    "            csv_lines = []\n",
    "            for line in lines:\n",
    "                line = line.strip()\n",
    "                if line.startswith(\"|\") and \"---\" not in line:\n",
    "                    # Remove leading/trailing pipes and split\n",
    "                    cells = [c.strip() for c in line.strip(\"|\").split(\"|\")]\n",
    "                    csv_lines.append(\",\".join(f'\"{c}\"' if \",\" in c else c for c in cells))\n",
    "                elif not line.startswith(\"|\"):\n",
    "                    break\n",
    "            csv_block = \"\\n\".join(csv_lines)\n",
    "        else:\n",
    "            raise ValueError(\"CSV/Table header 'Metric,' not found in model output.\")\n",
    "    else:\n",
    "        csv_block = csv_block[start:]\n",
    "    \n",
    "    summary_text = \"\"\n",
    "    if len(parts) > 1:\n",
    "        summary_text = \"Summary / Interpretation\" + parts[1].rstrip()\n",
    "    \n",
    "    # =========================\n",
    "    # 2) Parse CSV to DataFrame\n",
    "    # =========================\n",
    "    df = pd.read_csv(io.StringIO(csv_block))\n",
    "    \n",
    "    # Determine expected columns based on table type\n",
    "    if table_type == \"financial_performance\":\n",
    "        expected_cols = {\"Metric\", \"FY24\", \"FY23\", \"FY22\"}\n",
    "        year_cols = [\"FY24\", \"FY23\", \"FY22\"]\n",
    "    elif table_type == \"capital_structure\":\n",
    "        expected_cols = {\"Metric\", \"FY24\"}\n",
    "        year_cols = [\"FY24\"]\n",
    "    elif table_type == \"key_stakeholders\":\n",
    "        expected_cols = {\"Metric\", \"Shareholders\"}\n",
    "        year_cols = [\"Shareholders\"]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown table_type: {table_type}\")\n",
    "    \n",
    "    if not expected_cols.issubset(df.columns):\n",
    "        raise ValueError(f\"{table_type} CSV columns missing. Expected {expected_cols}, Got: {list(df.columns)}\")\n",
    "    \n",
    "    # Create dict: normalized metric name -> values\n",
    "    if table_type in [\"financial_performance\", \"capital_structure\"]:\n",
    "        csv_rows = {\n",
    "            keynorm(str(df.at[i, \"Metric\"]).strip()): {\n",
    "                col: str(df.at[i, col]) for col in year_cols\n",
    "            }\n",
    "            for i in range(len(df))\n",
    "        }\n",
    "    else:  # key_stakeholders\n",
    "        csv_rows = {\n",
    "            keynorm(str(df.at[i, \"Metric\"]).strip()): str(df.at[i, \"Shareholders\"]).strip()\n",
    "            for i in range(len(df))\n",
    "        }\n",
    "    \n",
    "    # =========================\n",
    "    # 3) Open DOCX and find the target table\n",
    "    # =========================\n",
    "    if doc is None:\n",
    "        doc = Document(doc_path)\n",
    "    \n",
    "    def find_table_by_type(document: Document, ttype: str):\n",
    "        \"\"\"Find table based on type\"\"\"\n",
    "        if ttype == \"financial_performance\":\n",
    "            # Look for table with FY24/FY23/FY22 headers\n",
    "            for tbl in document.tables:\n",
    "                if len(tbl.rows):\n",
    "                    header = \" \".join(c.text for c in tbl.rows[0].cells)\n",
    "                    if all(x in norm(header) for x in [\"fy24\", \"fy23\", \"fy22\"]):\n",
    "                        return tbl\n",
    "            # Fallback: after \"Financial Performance\" heading\n",
    "            return find_table_after_heading(document, \"financialperformance\")\n",
    "        \n",
    "        elif ttype == \"capital_structure\":\n",
    "            # Look for table after \"Capital Structure\" heading\n",
    "            return find_table_after_heading(document, \"capitalstructure\")\n",
    "        \n",
    "        elif ttype == \"key_stakeholders\":\n",
    "            # Look for table with \"Title\" and \"Occupants\" columns\n",
    "            for tbl in document.tables:\n",
    "                if not tbl.rows:\n",
    "                    continue\n",
    "                header = [norm(c.text) for c in tbl.rows[0].cells]\n",
    "                if \"title\" in header and \"occupants\" in header:\n",
    "                    return tbl\n",
    "            # Fallback: after \"Key Stakeholders\" heading\n",
    "            return find_table_after_heading(document, \"keystakeholders\")\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def find_table_after_heading(document: Document, heading_normalized: str):\n",
    "        \"\"\"Find first table after a specific heading\"\"\"\n",
    "        found_heading = False\n",
    "        body = document._element.body\n",
    "        for child in body.iterchildren():\n",
    "            tag = child.tag.rsplit(\"}\", 1)[-1]\n",
    "            if tag == \"p\":\n",
    "                p_text = \"\".join(\n",
    "                    t.text for t in child.iter() if t.tag.rsplit(\"}\", 1)[-1] == \"t\"\n",
    "                ).strip()\n",
    "                if norm(p_text) == heading_normalized:\n",
    "                    found_heading = True\n",
    "            elif tag == \"tbl\" and found_heading:\n",
    "                from docx.table import Table\n",
    "                return Table(child, document)\n",
    "        return None\n",
    "    \n",
    "    table = find_table_by_type(doc, table_type)\n",
    "    if table is None:\n",
    "        raise RuntimeError(f\"Could not locate the '{table_type}' table.\")\n",
    "    \n",
    "    # =========================\n",
    "    # 4) Populate the table\n",
    "    # =========================\n",
    "    \n",
    "    # Detect column indices from header row\n",
    "    header_row = table.rows[0]\n",
    "    col_map = {}  # normalized header -> column index\n",
    "    for idx, cell in enumerate(header_row.cells):\n",
    "        col_map[norm(cell.text)] = idx\n",
    "    \n",
    "    # Build mapping for year columns\n",
    "    year_col_indices = {}\n",
    "    if table_type in [\"financial_performance\", \"capital_structure\"]:\n",
    "        for year in year_cols:\n",
    "            year_norm = norm(year)\n",
    "            if year_norm in col_map:\n",
    "                year_col_indices[year] = col_map[year_norm]\n",
    "    else:  # key_stakeholders\n",
    "        # Value column could be \"Shareholders\" or \"Occupants\"\n",
    "        value_col_idx = col_map.get(\"shareholders\") or col_map.get(\"occupants\")\n",
    "        if value_col_idx is None:\n",
    "            value_col_idx = 1  # Default to second column\n",
    "    \n",
    "    # Populate data rows\n",
    "    for row_idx in range(1, len(table.rows)):\n",
    "        row = table.rows[row_idx]\n",
    "        label_cell = row.cells[0]\n",
    "        label_text = label_cell.text.strip()\n",
    "        label_norm = keynorm(label_text)\n",
    "        \n",
    "        # Try direct match first\n",
    "        matched_key = None\n",
    "        if label_norm in csv_rows:\n",
    "            matched_key = label_norm\n",
    "        elif metric_mapping and label_norm in metric_mapping:\n",
    "            # Use provided mapping\n",
    "            mapped_key = keynorm(metric_mapping[label_norm])\n",
    "            if mapped_key in csv_rows:\n",
    "                matched_key = mapped_key\n",
    "        else:\n",
    "            # Try fuzzy matching with Jaccard similarity\n",
    "            best_score = 0.0\n",
    "            for csv_key in csv_rows.keys():\n",
    "                score = jaccard(label_norm, csv_key)\n",
    "                if score > best_score and score >= 0.6:  # Threshold\n",
    "                    best_score = score\n",
    "                    matched_key = csv_key\n",
    "        \n",
    "        # Populate cells if we found a match\n",
    "        if matched_key:\n",
    "            if table_type in [\"financial_performance\", \"capital_structure\"]:\n",
    "                for year, col_idx in year_col_indices.items():\n",
    "                    if col_idx < len(row.cells):\n",
    "                        value = csv_rows[matched_key].get(year, \"\")\n",
    "                        set_cell_text(row.cells[col_idx], str(value))\n",
    "            else:  # key_stakeholders\n",
    "                if value_col_idx < len(row.cells):\n",
    "                    value = csv_rows[matched_key]\n",
    "                    set_cell_text(row.cells[value_col_idx], str(value))\n",
    "    \n",
    "    # =========================\n",
    "    # 5) Insert Summary below the table (if present)\n",
    "    # =========================\n",
    "    if summary_text:\n",
    "        # Find the table in the document body and add summary after it\n",
    "        table_elem = table._element\n",
    "        parent = table_elem.getparent()\n",
    "        table_idx = list(parent).index(table_elem)\n",
    "        \n",
    "        # Look for existing summary paragraph after the table\n",
    "        summary_inserted = False\n",
    "        for i in range(table_idx + 1, len(parent)):\n",
    "            child = parent[i]\n",
    "            tag = child.tag.rsplit(\"}\", 1)[-1]\n",
    "            if tag == \"p\":\n",
    "                p_text = \"\".join(\n",
    "                    t.text for t in child.iter() if t.tag.rsplit(\"}\", 1)[-1] == \"t\"\n",
    "                ).strip()\n",
    "                if \"summary\" in norm(p_text) or \"interpretation\" in norm(p_text):\n",
    "                    # Found summary section - update it\n",
    "                    from docx.text.paragraph import Paragraph\n",
    "                    para = Paragraph(child, doc)\n",
    "                    set_paragraph_multiline(para, summary_text)\n",
    "                    summary_inserted = True\n",
    "                    break\n",
    "            elif tag == \"tbl\":\n",
    "                # Hit another table, stop looking\n",
    "                break\n",
    "        \n",
    "        # If no existing summary found, add new paragraph\n",
    "        if not summary_inserted:\n",
    "            # Add paragraph after table\n",
    "            new_para = doc.add_paragraph()\n",
    "            set_paragraph_multiline(new_para, summary_text)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Convenience wrapper functions\n",
    "# =========================\n",
    "\n",
    "def insert_capital_structure(gpt_output: str, doc_path: str = None, doc: Document = None) -> Document:\n",
    "    \"\"\"Insert capital structure data into docx table.\"\"\"\n",
    "    return insert_table_data_generic(\n",
    "        gpt_output=gpt_output,\n",
    "        doc_path=doc_path,\n",
    "        table_type=\"capital_structure\",\n",
    "        doc=doc\n",
    "    )\n",
    "\n",
    "\n",
    "def insert_finance(gpt_output: str, doc_path: str = None, doc: Document = None,\n",
    "                   metric_mapping: Optional[Dict[str, str]] = None) -> Document:\n",
    "    \"\"\"Insert financial performance data into docx table.\"\"\"\n",
    "    # Default metric mapping for financial performance\n",
    "    if metric_mapping is None:\n",
    "        metric_mapping = {\n",
    "            keynorm(\"Revenue (Turnover)\"): \"Revenue\",\n",
    "            keynorm(\"Revenue growth % (yoy)\"): \"Revenue Growth\",\n",
    "            keynorm(\"Gross profit\"): \"Gross Profit\",\n",
    "            keynorm(\"Gross margin %\"): \"Gross Margin\",\n",
    "            keynorm(\"EBITDA\"): \"EBITDA\",\n",
    "            keynorm(\"EBITDA margin %\"): \"EBITDA Margin\",\n",
    "            keynorm(\"Adjusted EBITDA\"): \"Adjusted EBITDA\",\n",
    "            keynorm(\"Capex (tangible+intangible)\"): \"CAPEX\",\n",
    "            keynorm(\"CFADS\"): \"CFADS\",\n",
    "            keynorm(\"Net working capital change\"): \"Net Working Capital Change\",\n",
    "            keynorm(\"Total debt\"): \"Total Debt\",\n",
    "            keynorm(\"Net debt\"): \"Net Debt\",\n",
    "            keynorm(\"Leverage (Net Debt/EBITDA)\"): \"Leverage\",\n",
    "        }\n",
    "    \n",
    "    return insert_table_data_generic(\n",
    "        gpt_output=gpt_output,\n",
    "        doc_path=doc_path,\n",
    "        table_type=\"financial_performance\",\n",
    "        metric_mapping=metric_mapping,\n",
    "        doc=doc\n",
    "    )\n",
    "\n",
    "\n",
    "def insert_stakeholders(gpt_output: str, doc_path: str = None, doc: Document = None) -> Document:\n",
    "    \"\"\"Insert key stakeholders data into docx table.\"\"\"\n",
    "    return insert_table_data_generic(\n",
    "        gpt_output=gpt_output,\n",
    "        doc_path=doc_path,\n",
    "        table_type=\"key_stakeholders\",\n",
    "        doc=doc\n",
    "    )\n",
    "\n",
    "\n",
    "# Helper to ensure keynorm is available\n",
    "def keynorm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", (s or \"\").lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "063b554f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing insert_stakeholders...\n",
      " Success! Open the file to check: /Users/felipesilverio/Documents/GitHub/Azure-OnePager/test_stakeholders.docx\n"
     ]
    }
   ],
   "source": [
    "insert_stakeholders\n",
    "# =========================\n",
    "# TEST: insert_stakeholders\n",
    "# =========================\n",
    "\n",
    "# Sample GPT output (this is what your agent would return)\n",
    "stakeholders_test_output = \"\"\"\n",
    "Metric,Shareholders\n",
    "\"Shareholders\",\"Seaport Holdings Ltd (Immediate Parent); Ultimate Parent: Private Equity Group XYZ\"\n",
    "\"Management\",\"CEO: John Smith; CFO: Jane Doe; Chairman: Robert Brown\"\n",
    "\"Lenders\",\"Bank of America (Term Loan A); JPMorgan Chase (RCF)\"\n",
    "\"Auditors\",\"Grant Thornton UK LLP\"\n",
    "\"Advisors\",\"Financial Advisor: Goldman Sachs; Legal: Clifford Chance\"\n",
    "\n",
    "Summary / Interpretation\n",
    "- The company is owned by Private Equity Group XYZ through Seaport Holdings Ltd.\n",
    "- Management team includes experienced executives with John Smith as CEO.\n",
    "- Primary lenders are Bank of America and JPMorgan Chase.\n",
    "- Grant Thornton serves as the statutory auditor.\n",
    "- Goldman Sachs and Clifford Chance provide financial and legal advisory services.\n",
    "\n",
    "Sources\n",
    "- [#1] Annual Report FY24, Directors' Report, p.12\n",
    "- [#2] Annual Report FY24, Notes to Financial Statements\n",
    "\"\"\"\n",
    "\n",
    "# Test the function\n",
    "print(\"Testing insert_stakeholders...\")\n",
    "try:\n",
    "    # Load your template document\n",
    "    doc_path = \"/Users/felipesilverio/Documents/GitHub/Azure-OnePager/CompanyProfile (1).docx\"\n",
    "    \n",
    "    # Call the function\n",
    "    doc = insert_stakeholders(stakeholders_test_output, doc_path=doc_path)\n",
    "    \n",
    "    # Save to a test output file\n",
    "    output_path = \"/Users/felipesilverio/Documents/GitHub/Azure-OnePager/test_stakeholders.docx\"\n",
    "    doc.save(output_path)\n",
    "    \n",
    "    print(f\" Success! Open the file to check: {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\" Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
